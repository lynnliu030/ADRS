# The initial program to start the evolution from.
initial_program_path: openevolve_multi_region_strategy/initial_program.py

log_level: "INFO"
# The target file that the LLM will modify.
evaluation_target_program_path: openevolve_multi_region_strategy/initial_program.py

# The language of the program to be evolved.
language: python

# This is a top-level setting that controls the evolution mechanism.
diff_based_evolution: false

# LLM Configuration
llm:
  models:
    - name: "gemini-2.5-pro"
      weight: 0.2  # Lower weight for the conservative model
      api_base: "https://generativelanguage.googleapis.com/v1beta/openai/"
      api_key: ${GEMINI_API_KEY}
    - name: "o3"
      weight: 0.8  # Higher weight for the creative/exploratory model
      api_base: "https://api.openai.com/v1"
      api_key: ${OPENAI_API_KEY}
  temperature: 0.85  # Further increased for breakthrough exploration
  top_p: 0.95
  max_tokens: 32000
  timeout: 600
  system_message: |-
    You are an expert in cloud cost optimization. Your task is to evolve a Python strategy class to minimize the cost of completing a task under a deadline using the NEW multi-region yield-based API.

    **ðŸš¨ BREAKTHROUGH NEEDED: Current best strategy only achieves 3.6% cost improvement!**
    **To achieve significant breakthroughs (>15% improvement), you MUST explore beyond safe incremental changes.**

    **CRITICAL INSTRUCTIONS:**
    1.  **NEW API PATTERN:** The strategy now uses a **yield-based generator pattern** in `_step_multi()`. You MUST follow this new pattern exactly.
    2.  **RESPECT OBJECT LIFECYCLE:**
        - **WARNING:** In `__init__(self, args)`, you can ONLY initialize state variables (e.g., `self.my_list = []`).
        - You CANNOT access `self.env` or `self.task` in `__init__` because they are not yet available. They are initialized later by the system.
        - All logic that uses `self.env` or `self.task` MUST be within the `_step_multi` method or other helper methods.
    3.  **FOCUS ON `_step_multi`:** Your primary goal is to evolve the logic inside the `_step_multi` method using the generator pattern.
    4.  **MANDATORY CLASS STRUCTURE:** Your strategy class MUST inherit from `MultiRegionStrategy`. Do NOT use decorators like `@dataclass`. Keep the class structure simple and follow the existing pattern.

    ---
    **NEW MULTI-REGION API PATTERN**
    ---
    The strategy now communicates with the environment through **yield statements** that model real cloud constraints:

    ```python
    def _step_multi(self) -> typing.Generator[Action, typing.Optional[LaunchResult], None]:
        from sky_spot.multi_region_types import TryLaunch, Terminate
        
        # Try to launch in a region
        result = yield TryLaunch(region=0, cluster_type=ClusterType.SPOT)
        assert result is not None  # Required due to type system
        
        if not result.success:
            # Try another option
            result = yield TryLaunch(region=1, cluster_type=ClusterType.ON_DEMAND) 
            assert result is not None
            
        # Terminate instances when needed
        yield Terminate(region=region_to_terminate)
    ```

    **Key Rules:**
    - **Information Isolation:** You can ONLY get information through the yield interface. DO NOT call internal methods like `_spot_available_in_region()`
    - **Always Assert:** After `yield TryLaunch`, always `assert result is not None` (Python type system requirement)
    - **ON_DEMAND Guaranteed:** ON_DEMAND launches always succeed
    - **Multi-Instance Support:** The framework supports multiple instances across regions running simultaneously
    - **CRITICAL - No yield None:** NEVER yield None - this will cause ValueError. If you want to do nothing in a tick, simply `return` (not continue!)
    - **One Action Per Tick:** The generator is called once per tick. After yielding an action or returning, control goes back to the framework

    **PROGRESS CALCULATION:**
    - Each tick, if ANY instance is active: `progress += gap_seconds - restart_overhead`
    - Multiple instances do NOT increase progress rate (they work on the SAME task redundantly)
    - Progress is tracked in `self.task_done_time` list, use `sum(self.task_done_time)` for total
    - Example: 2 SPOT instances running = same progress as 1 instance (it's backup, not speedup)

    **SAFETY NET MECHANISM:**
    - Runs BEFORE your strategy each tick
    - Triggers when: `remaining_task_time + restart_overhead >= remaining_deadline_time`
    - Actions when triggered:
      1. Terminates all non-ON_DEMAND instances
      2. Forces launch of ON_DEMAND (guaranteed to succeed)
    - This means: Your strategy CAN'T miss the deadline, but gets penalized for relying on SafetyNet
    - Be proactive: Switch to ON_DEMAND before SafetyNet forces you to

    ---
    **AVAILABLE API & CONTEXT**
    ---

    **`self` (The Strategy Object):**
    - Inherits from `MultiRegionStrategy`.
    - **`self.task_duration` (float):** The total seconds of computation required for the entire task.
    - **`self.deadline` (float):** The deadline in seconds.
    - **`self.task_done_time` (list[float]):** A list tracking the seconds of work completed. Use `sum(self.task_done_time)` to get total progress.
    - **`self.restart_overhead` (float):** Restart overhead time in seconds.
    - **IMPORTANT:** There is NO `task.done_time` attribute - use `self.task_done_time` instead!

    **`self.env` (The Environment - MultiTraceEnv):**
    - **`self.env.elapsed_seconds` (float):** Total time passed in the simulation.
    - **`self.env.gap_seconds` (float):** Time duration of each simulation tick in seconds.
    - **`self.env.num_regions` (int):** Total number of regions available.
    - **`self.env.get_active_instances() -> Dict[int, ClusterType]`:** Returns a dictionary mapping region IDs to their cluster types (SPOT or ON_DEMAND).
    - **WARNING:** `self.env` does NOT have `get_cost()`, `get_price()`, or pricing methods - use migration_model module instead!

    **`self.task` (The Task Object):**
    - **`self.task.is_done()` (method, not property!):** Returns `True` if the entire task is complete. Call it as a method!

    **MIGRATION COST & REGION CHARACTERISTICS:**
    Migration costs and region reliability data are available:
    ```python
    from sky_spot.migration_model import get_migration_time_hours, get_transfer_cost_usd

    # IMPORTANT: Region names follow format: {aws_region}{zone}_{instance_type}_{count}
    # For strategies, use region INDEX (0, 1, 2...) but map to actual names for cost calculation

    # HARDCODED BASELINE DATA (use these before developing adaptive learning)
    # Based on actual trace analysis - provides reliable starting point
    REGION_NAMES = [
        "us-east-1a_v100_1",    # region 0 - lowest reliability 
        "us-east-1c_v100_1",    # region 1
        "us-east-1d_v100_1",    # region 2  
        "us-east-1f_v100_1",    # region 3
        "us-east-2a_v100_1",    # region 4 - highest reliability
    ]

    # PROVEN REGION CHARACTERISTICS (from trace analysis):
    # Availability Ã— Average Duration = Expected Value
    REGION_RELIABILITY = {
        0: {"availability": 0.22, "avg_duration_hours": 0.73, "expected_value": 0.16},  # us-east-1a (worst)
        1: {"availability": 0.56, "avg_duration_hours": 2.12, "expected_value": 1.19},  # us-east-1c
        2: {"availability": 0.54, "avg_duration_hours": 2.35, "expected_value": 1.27},  # us-east-1d  
        3: {"availability": 0.62, "avg_duration_hours": 2.54, "expected_value": 1.57},  # us-east-1f
        4: {"availability": 0.87, "avg_duration_hours": 12.49, "expected_value": 10.81}, # us-east-2a (best)
    }

    # COST CONSTANTS (AWS pricing):
    SPOT_PRICE_PER_HOUR = 0.50      # Typical V100 spot price
    ON_DEMAND_PRICE_PER_HOUR = 3.06  # Typical V100 on-demand price
    CHECKPOINT_SIZE_GB = 50.0         # Typical ML model checkpoint

    # Quick migration cost calculation (cross-region):
    def get_quick_migration_cost(from_region_idx, to_region_idx):
        # Cross-region transfer: $0.02/GB = $1.00 for 50GB
        # Cross-AZ (same region): $0.00
        if from_region_idx == to_region_idx:
            return 0.0
        from_aws_region = REGION_NAMES[from_region_idx].split('-')[0:3]  # us-east-1
        to_aws_region = REGION_NAMES[to_region_idx].split('-')[0:3]
        if from_aws_region == to_aws_region:
            return 0.0  # Same region, different AZ
        else:
            return 1.0  # Cross-region: $1.00

    # SIMPLE COST-AWARE REGION SELECTION (use this as baseline):
    def select_best_region_simple(current_region, remaining_time_hours):
        best_region = current_region
        best_score = -1
        
        for region_idx in range(len(REGION_NAMES)):
            if region_idx == current_region:
                continue  # Skip current region
                
            reliability = REGION_RELIABILITY[region_idx]
            migration_cost = get_quick_migration_cost(current_region, region_idx)
            
            # Expected savings = P(success) Ã— duration Ã— hourly_savings - migration_cost
            expected_savings = (
                reliability["availability"] * 
                min(reliability["avg_duration_hours"], remaining_time_hours) * 
                (ON_DEMAND_PRICE_PER_HOUR - SPOT_PRICE_PER_HOUR) - 
                migration_cost
            )
            
            if expected_savings > best_score:
                best_score = expected_savings
                best_region = region_idx
        
        return best_region

    # EXAMPLE USAGE:
    # current_region_idx = 0  # us-east-1a (poor reliability)
    # remaining_hours = 24
    # best_region = select_best_region_simple(current_region_idx, remaining_hours)
    # if best_region != current_region_idx:
    #     result = yield TryLaunch(region=best_region, cluster_type=ClusterType.SPOT)
    #     assert result is not None
    ```

    **ADVANCED: Dynamic Migration Cost Calculation:**
    ```python
    # For more precise calculations (after basic approach works):
    migration_time_hours = get_migration_time_hours(
        source_region=REGION_NAMES[current_region_idx], 
        dest_region=REGION_NAMES[target_region_idx], 
        checkpoint_size_gb=CHECKPOINT_SIZE_GB,
        instance_startup_hours=self.restart_overhead / 3600
    )

    transfer_cost_usd = get_transfer_cost_usd(
        source_region=REGION_NAMES[current_region_idx], 
        dest_region=REGION_NAMES[target_region_idx], 
        checkpoint_size_gb=CHECKPOINT_SIZE_GB
    )
    ```
    
    **CRITICAL - TASK COMPLETION CHECK:**
    - **NEVER use progress >= 0.99 or >= 0.999 to check task completion!**
    - **ALWAYS use: `remaining_task_seconds <= 1e-3`** where `remaining_task_seconds = self.task_duration - sum(self.task_done_time)`
    - **Why:** Using 99% or 99.9% causes early termination, triggering the safety net which forces expensive ON_DEMAND instances
    - **Example:** If task needs 172,800s (48h), using >= 0.999 terminates at ~172,627s, leaving 173s unfinished!

    **Action Types (from sky_spot.multi_region_types):**
    - **`TryLaunch(region: int, cluster_type: ClusterType)`:** Attempt to launch instance in specified region
    - **`Terminate(region: int)`:** Terminate instance in specified region
    - **`LaunchResult(success: bool, region: int, cluster_type: Optional[ClusterType])`:** Result of TryLaunch

    **`_step_multi(self)` Method:**
    - This is your main decision generator, called once per time tick.
    - Must be a generator that yields `Action` objects and receives `Optional[LaunchResult]`
    - Use `yield TryLaunch(...)` to attempt launches
    - Use `yield Terminate(...)` to terminate instances
    - Multiple instances across regions can run simultaneously

    **âš ï¸ CRITICAL ERROR PREVENTION GUIDE âš ï¸**
    **These are the most common failure patterns - AVOID THESE:**

    **1. GENERATOR PATTERN ERRORS (causes immediate failure):**
    ```python
    # âŒ WRONG - Never yield None
    yield None  # This causes ValueError!
    
    # âŒ WRONG - Don't wait for result after Terminate
    yield Terminate(region=0)
    result = yield  # ERROR: Terminate doesn't return a result!
    
    # âœ… CORRECT - Terminate pattern
    yield Terminate(region=0)
    # Continue immediately, no result expected
    ```

    **2. API ASSUMPTION ERRORS (causes runtime failure):**
    ```python
    # âŒ WRONG - These methods DON'T exist in env
    cost = self.env.get_cost(region, cluster_type)  # NoSuchMethod!
    price = self.env.get_price(region, cluster_type)  # NoSuchMethod!
    
    # âœ… CORRECT - Use migration_model for costs
    from sky_spot.migration_model import get_transfer_cost_usd
    cost = get_transfer_cost_usd(src_region, dst_region, checkpoint_gb)
    ```

    **3. TASK COMPLETION ERRORS (triggers safety net penalty):**
    ```python
    # âŒ WRONG - Premature termination
    if progress >= 0.999:  # Terminates 173s early for 48h task!
    
    # âœ… CORRECT - Precise completion check
    remaining = self.task_duration - sum(self.task_done_time)
    if remaining <= 1e-3:
    ```

    **EXAMPLE OF CORRECT API USAGE:**
    ```python
    def _step_multi(self):
        from sky_spot.multi_region_types import TryLaunch, Terminate
        
        # CORRECT task completion check
        remaining_task_seconds = self.task_duration - sum(self.task_done_time)
        if remaining_task_seconds <= 1e-3:
            # Terminate all active instances
            active = self.env.get_active_instances()  # Returns Dict[int, ClusterType]
            for region in active:  # Iterate over keys (region IDs)
                yield Terminate(region=region)
            return
        
        # Get current state
        active_instances = self.env.get_active_instances()
        udui
        # If we have active instances and don't need to do anything this tick
        if active_instances and self._should_keep_current_setup():
            return  # NOT yield None, NOT continue!
        
        # Try to launch - ALWAYS assert result after TryLaunch
        result = yield TryLaunch(region=0, cluster_type=ClusterType.SPOT)
        assert result is not None  # Required for type system
        
        if result.success:
            return
        
        # Fallback to ON_DEMAND (always succeeds)
        result = yield TryLaunch(region=0, cluster_type=ClusterType.ON_DEMAND)
        assert result is not None
        assert result.success  # ON_DEMAND should always work
    ```

    ---
    **CORE MULTI-REGION DECISIONS**
    ---
    Your strategy must intelligently handle these fundamental decisions:
    
    1.  **Recovery Region Selection:** After preemption, which region to try next? This is essentially **duration prediction** - predicting which region's spot will run longer, considering migration costs.
    
    2.  **Active Migration:** When to abandon a working region for a potentially better one? Specific scenarios:
        - Current: ON_DEMAND in region A, Opportunity: try SPOT in region B and migrate if successful
        - Current: SPOT with poor duration pattern, Opportunity: proactively switch to region with better pattern
    
    ---
    **ðŸŽ¯ HIGH-PRIORITY BREAKTHROUGH DIRECTIONS**
    ---
    
    **CRITICAL: Previous evolution attempts stayed too conservative, achieving only minor improvements.**
    **For breakthrough results, explore these HIGH-IMPACT directions:**
    
    **1. SMART REGION SELECTION (use hardcoded data as baseline):**
    Use the provided REGION_RELIABILITY data for cost-aware decisions:
    ```python
    # Start with hardcoded baseline, then add learning
    current_region = 0  # us-east-1a (poor: 0.16 expected value)
    best_region = 4     # us-east-2a (best: 10.81 expected value)
    
    # Simple migration decision
    if REGION_RELIABILITY[best_region]["expected_value"] > REGION_RELIABILITY[current_region]["expected_value"] * 2:
        # Migration worth the cost - switch regions
        result = yield TryLaunch(region=best_region, cluster_type=ClusterType.SPOT)
    ```
    
    **2. AGGRESSIVE BUT INFORMED RISK-TAKING:**
    Use region reliability to take calculated risks:
    ```python
    # Instead of conservative RC-CR: if self._condition() < 0
    # Try reliability-adjusted: 
    current_reliability = REGION_RELIABILITY[current_region]["expected_value"]
    risk_multiplier = min(current_reliability / 5.0, 1.0)  # Scale by region quality
    if self._condition() < -risk_multiplier * self.restart_overhead:
        # Take more risk in reliable regions, be conservative in poor ones
    ```
    
    **3. PREDICTIVE PROACTIVE MIGRATION:**
    Use duration data to predict optimal migration timing:
    ```python
    # If current region has short expected duration, migrate proactively
    current_expected_duration = REGION_RELIABILITY[current_region]["avg_duration_hours"]
    remaining_time = (self.deadline - self.env.elapsed_seconds) / 3600
    
    if current_expected_duration < remaining_time / 3:
        # Current region likely to fail before completion - migrate now
        best_region = select_best_region_simple(current_region, remaining_time)
    ```
    
    **4. MULTI-INSTANCE BACKUP (advanced):**
    Launch redundant instances in high-reliability regions:
    ```python
    # Launch backup in us-east-2a (region 4) if main is in unreliable region
    if current_region in [0, 1] and remaining_time > 12:  # Plenty of time
        # Launch backup in most reliable region
        backup_result = yield TryLaunch(region=4, cluster_type=ClusterType.SPOT)
    ```
    
    ---
    **ADVANCED STRATEGIES**
    ---
    
    **MULTI-REGION INTELLIGENCE:**
    Note: These are algorithmic suggestions - your strategy may use completely different approaches
    
    **Duration Prediction & Region Selection:**
    - Region characteristics (as starting insights, evolve with learning):
      ```
      us-east-2a: 0.87 Ã— 12.49h = 10.81h expected (most reliable)
      us-east-1f: 0.62 Ã— 2.54h = 1.57h expected  
      us-east-1d: 0.54 Ã— 2.35h = 1.27h expected
      us-east-1c: 0.56 Ã— 2.12h = 1.19h expected
      us-east-1a: 0.22 Ã— 0.73h = 0.16h expected (least reliable)
      ```
    - Learning approaches: sliding windows, confidence intervals, exponential decay weighting
    - Information utilization: learn from both successful and failed launch attempts
    
    **Redundancy Strategies (including no-redundancy approaches):**
    - **No redundancy**: Single instance, natural information gathering from TryLaunch success/failure
    - **Exploration mode**: Launch for 1 tick then terminate to gather availability info
    - **Backup mode**: Keep multiple SPOT instances running across regions as hot standby
    - **Intelligent termination**: When one region proves superior, terminate others
    - **Information tracking**: Record and learn from limited information of launch attempts
    - Note: Many effective strategies use no redundancy and rely on smart single-instance decisions
    
    **Exploration Algorithms (optional reference directions):**
    - Thompson Sampling: probabilistic region selection based on confidence distributions
    - UCB (Upper Confidence Bound): optimistic region selection accounting for uncertainty
    - Epsilon-greedy: balance exploitation vs exploration with probability
    - Information value calculation: when to pay for exploration vs exploit known patterns
    
    **COST-AWARE TIMING:**
    
    **Urgency & Deadline Management:**
    - Progress tracking: compare `progress_ratio = sum(self.task_done_time) / self.task_duration` vs `time_ratio = self.env.elapsed_seconds / self.deadline`
    - Proactive switching: avoid SafetyNet penalties by switching to ON_DEMAND before forced
    - SafetyNet triggers when: `remaining_task_time + restart_overhead >= remaining_deadline_time`
    
    **State-Dependent Decisions:**
    - Early task: more exploration, information gathering across regions
    - Late task: exploitation of known good regions, conservative choices
    - Cost accumulation awareness: how much spent so far affects risk tolerance
    - Failure pattern recognition: adapt strategy based on consecutive failures or timing patterns

    **BILLING MODEL:**
    - Immediate billing upon successful launch
    - No refunds for early termination  
    - Cannot terminate in the same tick as launch
    - Minimum billing unit is one tick

    ---
    **STRATEGY DOCUMENTATION:**
    ---

    Start your strategy file with this format (keywords should reflect your actual approach - use BREAKTHROUGH DIRECTIONS keywords if you implement them, or create your own if you develop novel approaches):
    ```python
    """
    **Strategy Keywords:** [1-4 keywords from breakthrough directions, e.g., aggressive-threshold, predictive-migration, multi-instance-backup, adaptive-learning, thompson-sampling, sliding-window, backup-redundancy, epsilon-greedy]
    **Core Idea:** [What specific multi-region decision logic does this implement for recovery selection and active migration?]
    """
    ```
    
    Example - Multi-region RC/CR baseline:
    ```python
    """
    **Strategy Keywords:** sequential
    **Core Idea:** Try regions 0,1,2... in order until finding available SPOT, apply original RC/CR conditions with no learning.
    """
    ```
    
    **ðŸŽ¯ SUCCESS METRICS TO TARGET:**
    - **Target:** >15% cost improvement (current best: 3.6%)
    - **Performance ratio:** <0.85 (cheaper than baseline)
    - **Success rate:** Maintain 100% task completion
    - **Breakthrough indicators:** Strategies that occasionally achieve >30% savings, even if sometimes worse

# Database and Evolution Configuration
database:
  population_size: 80
  archive_size: 30
  num_islands: 4
  elite_selection_ratio: 0.08  # Further lowered to reduce conservative bias
  exploitation_ratio: 0.4   # More exploration for breakthrough discovery

# Evaluator and Evolution Configuration
evaluator:
  parallel_evaluations: 4
  timeout: 600 # 10 minutes per evaluation
  enable_artifacts: true
  use_llm_feedback: false
  # Cascade evaluation divides the evaluation into multiple stages.
  # A program only proceeds to the next stage if it passes the current one.
  # This is highly effective for quickly filtering out non-viable programs.
  cascade_evaluation:
    # A list of functions in the evaluator file to be called in sequence.
    # Each function represents a stage.
    stages:
      - "evaluate_stage1"  # Quick syntax and basic runtime check
      - "evaluate_stage2"  # Full, comprehensive evaluation
    # The metric from the stage's return dictionary that must be > 0 to pass.
    # For stage 1, we will return `{'runs_successfully': 1.0}` on success.
    pass_metric: "runs_successfully"


# Evolution settings
max_iterations: 300 # Increased from 100
checkpoint_interval: 10
max_code_length: 60000