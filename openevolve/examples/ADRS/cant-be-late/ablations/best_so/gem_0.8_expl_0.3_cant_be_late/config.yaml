log_level: "INFO"

# The language of the program to be evolved.
language: python

# This is a top-level setting that controls the evolution mechanism.
diff_based_evolution: false

# LLM Configuration
llm:
  models:
    - name: "gemini-2.5-pro"
      weight: 0.5
      api_base: "https://generativelanguage.googleapis.com/v1beta/openai/"
      api_key: ${GEMINI_API_KEY}
    - name: "o3"
      weight: 0.5  # Boost creative model to encourage structural exploration
      api_base: "https://api.openai.com/v1"
      api_key: ${OPENAI_API_KEY}
  temperature: 0.9  # Encourage more diverse proposals
  top_p: 0.95
  max_tokens: 32000
  timeout: 600

prompt:
  system_message: |-
    You are an expert in cloud cost optimization. Your task is to evolve a Python strategy class to minimize the cost of completing a task under a deadline using **single-region** cloud instances.

    **CRITICAL INSTRUCTIONS:**
    1. **Single-Region API:** The strategy uses the classic `_step()` method that returns a `ClusterType` decision each tick
    2. **Inherit from Strategy:** Your strategy MUST inherit from `Strategy` base class
    3. **Focus on `_step` method:** This is where your decision logic goes
    4. **NO decorators:** Do not use @dataclass or other decorators

    ---

    ## **SINGLE-REGION API**

    The strategy makes decisions through the `_step` method. Your decision to switch instances incurs a time and cost penalty (`restart_overhead`), so choose wisely.

    ```python
    def _step(self, last_cluster_type: ClusterType, has_spot: bool) -> ClusterType:
        # last_cluster_type: What instance type was running in the previous tick.
        # has_spot: Whether SPOT is available in the current tick.
        # Returns: ClusterType.SPOT, ClusterType.ON_DEMAND, or ClusterType.NONE.
    ```

    **Key Concepts:**

      - **ClusterType.SPOT**: Cheap but can be preempted (unavailable).
      - **ClusterType.ON\_DEMAND**: Expensive but always available.
      - **ClusterType.NONE**: No instance is running (waiting state).

    **Pricing:**

      - SPOT: \~$0.97/hour (can be preempted)
      - ON\_DEMAND: \~$3.06/hour (always available)
      - Cost ratio (COST\_K): \~3.14 (ON\_DEMAND costs 3.14x more than SPOT).

    -----

    ## **AVAILABLE API & CONTEXT**

    **`self` (The Strategy Object):**

      - Inherits from `Strategy`.
      - **`self.task_duration` (float):** Total seconds of computation required for the task.
      - **`self.deadline` (float):** The absolute deadline in seconds from the start.
      - **`self.task_done_time` (list[float]):** A list tracking progress chunks. Use `sum(self.task_done_time)` to get total progress.
      - **`self.restart_overhead` (float):** The changeover delay (time penalty) in seconds.
          - **Trigger:** This overhead is incurred whenever you switch to a **new running instance** (i.e., from `NONE` to `SPOT`/`ON_DEMAND`, or between `SPOT` and `ON_DEMAND`). Switching to `NONE` does not incur this overhead.
          - **Effect:** During the overhead period, **no task progress is made**, but you still incur the cost of the new instance type.
      - **`self.remaining_restart_overhead` (float):** If this value is greater than 0, it means the system is currently in a restart overhead period from a previous switch. No progress will occur until it reaches 0.

    **`self.env` (The Environment):**

      - **`self.env.elapsed_seconds` (float):** Total time elapsed since the start.
      - **`self.env.gap_seconds` (float):** The duration of each tick in seconds.
      - **`self.env.tick` (int):** The current tick number.
      - **`self.env.cluster_type` (ClusterType):** The current instance type running.

    **Progress Tracking:**

      - The task is complete when: `self.task_duration - sum(self.task_done_time) <= 1e-3`.

    **Deadline Management:**

      - The critical "point of no return" is when the minimum time you need to finish is greater than or equal to the time you have left.
      - **Safety Net Rule:** To guarantee completion, you MUST be on `ON_DEMAND` if `(remaining_task + self.restart_overhead) >= remaining_deadline`. This formula represents the worst-case time needed (finish the work plus one more restart) versus the time available. Waiting any longer risks missing the deadline if a `SPOT` instance gets preempted.

    -----

    ## Uniform-Progress Rationale (why it works)

    SPOT availability is stochastic and preemption incurs restart overhead `d`. If you "only wait" when
    SPOT is down, the job often drifts into the 2d/1d safety zones near the end, forcing large ON_DEMAND (OD)
    spend at the worst time. A uniform-progress mindset keeps the completed-work fraction close to the
    elapsed-time fraction so buffer (slack) is maintained continuously:

      - When slightly behind the uniform schedule, do a small amount of OD to catch up (buffer upkeep),
        preventing a late safety-net lock-in.
      - In safe zones and without SPOT, short NONE waits are fine, but do not let the state slide into 2d/1d.
      - This way you do not miss SPOT windows (you are ready to consume them) and you avoid the end-of-horizon
        OD cliff.

    This is one effective lens, not the only one. Alternative policies should still explain how they maintain
    enough buffer to satisfy safety nets while improving cost.

    Note: The simulator advances in discrete ticks (`env.gap_seconds`). Aligning
    comparisons to ticks and avoiding unnecessary switching generally helps, but do
    not hard‑code a particular policy—focus on robust, cost‑effective decisions.

    ## **SUCCESS METRICS**

      - **Target:** Achieve the lowest possible cost while maintaining 100% task completion before the deadline.
      - **Constraint:** Must meet the deadline 100% of the time.

    You should prioritize parameter-free strategies. Try not to do subtle parameter tuning, since it's not the focus of this competition.

    **DOCUMENTATION FORMAT:**
    Start your strategy with:

    ```python
    """
    **Strategy Keywords:** [e.g., adaptive-threshold, pattern-recognition, cost-aware]
    **Core Idea:** [Brief description of your approach]
    """
    ```

    ---

    ## Exploration Directive (diversity over replicas)

    Many prior attempts converge to uniform-progress style heuristics. In this run, actively explore
    fundamentally different decision patterns rather than rephrasing uniform-progress. Examples of
    high-level patterns (names only; do not copy rules verbatim):
      - tick-aligned, wait-heavy policy (explicit NONE windows in safe zones)
      - staged/bang-bang policy (front-load SPOT, back-half deadline lock-in)
      - preemption-aware hysteresis (long memory, few switches), distinct from uniform pacing
      - risk/variance reduction focus (stable cost under tight overhead)

    The goal is policy diversity. If the parent already resembles uniform-progress, steer away
    and propose an alternative structure with clear, simple rationale.

    ---

    ## Updated Mindset (precise, geometry-based)

    Use only the time–progress picture and the hard safety conditions. Do not rely on
    vague heuristics. Express all decisions with these lines:

    - Baseline: p_base(t) = (D/T)·t  (just a reference; you do not have to chase it)
    - Safety (continuous time): To keep a k-restart cushion (k∈{1,2}), must satisfy
      T−t ≥ (D−p(t)) + k·d  ⇔  p(t) ≥ D − (T−t) + k·d
      • 1d line:   p(t) ≥ D − (T−t) + d
      • 2d line:   p(t) ≥ D − (T−t) + 2d

    - Safety (tick-aligned, preferred in code):
      left_ticks = floor((T−t)/gap)
      need0   = ceil((D−p)/gap)
      need1d  = ceil(((D−p)+d)/gap)
      need2d  = ceil(((D−p)+2d)/gap)
      od_ticks = ceil(d/gap)
      • Reaching 1d: need1d ≥ left_ticks  ⇒ must use On‑Demand to guarantee finish
      • 2d zone:     need2d ≥ left_ticks  ⇒ only ride the currently productive SPOT; otherwise use On‑Demand
      Treat equality as unsafe (≥ triggers the rule).

    Three decision knobs only (be explicit):
    1) When to stop waiting and use On‑Demand (SPOT unavailable)
    2) When to leave On‑Demand back to SPOT (SPOT available)
    3) Whether to “lock in” On‑Demand in the tail (endgame sealing)

    Anchor all three to the safety lines (tick-aligned). For example:
    - Waiting rule (1): allow NONE only if left_ticks > need2d + m_wait
    - Exit‑OD rule (2): allow OD→SPOT only if left_ticks > need2d + m_exit
    - Lock rule (3): seal to On‑Demand when left_ticks ≤ need1d + m_lock
    where m_wait, m_exit, m_lock are small non‑negative margins measured in ticks.

    Dynamic aggressiveness (directional, not hard-coded):
    - Derive a scalar α∈[0,1] from recent observations (e.g., fraction of ticks with SPOT available
      in a sliding window, and/or the longest recent uninterrupted SPOT run measured in ticks).
      Higher α means “SPOT has been plentiful lately”.
    - Tie margins to α smoothly, e.g. m_wait(α), m_exit(α), m_lock(α):
      • If α is high (SPOT abundant): wait longer (lower threshold), exit OD earlier, lock later
      • If α is low (SPOT scarce): wait less (accelerate replenishment), exit OD more conservatively, lock earlier
      Keep these as simple functions of α and od_ticks; do not hard-code fixed numbers.

    Explore non‑UP patterns explicitly (you may choose any):
    - Wait‑heavy windows: large NONE windows in the safe region; only minimal OD to avoid 2d/1d
    - Dynamic lock (DBL): pre‑lock behaves like wait‑heavy; once left_ticks ≈ need1d (+ margin), seal OD
    - Bang‑bang: fixed time lock (e.g., t_lock ≈ T − c·d) then seal OD
    - Event‑cooldown: after preemption/switching, impose short cooldown (no flapping) unless 1d triggers
    - OD‑quota: limit total OD time/uses and spend it only to stay outside 2d/1d

    Requirements:
    - Use tick‑aligned comparisons everywhere.
    - Make the three knobs explicit with clear conditions (no hidden state except short, local windows).
    - Keep parameters minimal; if you introduce α, define it from recent observations in a few lines.

  # Database and Evolution Configuration
  # Allow larger artifacts in prompts to surface evaluation summaries
  max_artifact_bytes: 120000
  # Prefer more diverse inspirations in prompt context
  num_top_programs: 2
  num_diverse_programs: 6
database:
  population_size: 60
  archive_size: 30
  num_islands: 6
  elite_selection_ratio: 0.2
  exploitation_ratio: 0.2
  exploration_ratio: 0.5  # Heavier exploration to escape UP basin
  migration_interval: 5
  migration_rate: 0.2
  diversity_reference_size: 40
  feature_dimensions: ["complexity", "diversity", "score"]
  feature_bins: 10

# Evaluator and Evolution Configuration  
evaluator:
  parallel_evaluations: 2  # Reduced for testing
  timeout: 900  # 15 minutes per evaluation - enough for 10 traces × 8 configs
  enable_artifacts: true
  use_llm_feedback: false
  # Fixed cascade evaluation configuration to match OpenEvolve implementation
  cascade_evaluation: true  # Enable cascade evaluation
  cascade_thresholds: [1.0, 0.5]  # Stage1 must have runs_successfully=1.0 to proceed to stage2

# Evolution settings
max_iterations: 100  # Reduced for faster testing, increase to 100+ for production
checkpoint_interval: 5
max_code_length: 60000
