{"id": "1f4694a4-7369-4749-8787-04892424e878", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        # If each group is its own pack, no complex packing needed.\n        # Create results directly on the original device.\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    original_device = weight.device\n    # Sort indices on the original device. This avoids CPU transfer for indices.\n    # The weights themselves will be accessed directly from the original device.\n    _, indices = weight.float().sort(-1, descending=True)\n\n    # Create tensors for results directly on the original_device.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(weight, dtype=torch.int64)\n\n    for i in range(num_layers):\n        # Use PyTorch tensors for pack_weights and pack_items for current layer.\n        # This keeps calculations on the original_device and avoids Python list overhead.\n        pack_weights_i = torch.zeros(num_packs, dtype=torch.float32, device=original_device)\n        pack_items_i = torch.zeros(num_packs, dtype=torch.int64, device=original_device)\n\n        current_layer_original_indices = indices[i] # Indices of experts in sorted order for current layer\n        current_layer_original_weights = weight[i] # Original weights for current layer\n\n        for k in range(num_groups): # Iterate through experts in descending weight order\n            original_group_idx = current_layer_original_indices[k]\n\n            # Find the pack with the minimum current weight that still has capacity.\n            # Mask out packs that are already full by setting their weights to infinity.\n            # Then use argmin to find the pack with the smallest valid weight.\n            capacity_mask = (pack_items_i < groups_per_pack)\n            masked_pack_weights = pack_weights_i.clone()\n            # Set weights of full packs to infinity to exclude them from selection by argmin\n            masked_pack_weights[~capacity_mask] = float('inf')\n\n            pack = torch.argmin(masked_pack_weights)\n\n            # Assign results to the output tensors for the current layer and original expert index.\n            pack_index[i, original_group_idx] = pack\n            rank_in_pack[i, original_group_idx] = pack_items_i[pack]\n\n            # Update pack states\n            pack_weights_i[pack] += current_layer_original_weights[original_group_idx]\n            pack_items_i[pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    # Initialize `phy2log` and `rank` for the initial `num_log` experts.\n    # These are the non-replicated experts, mapping physical 0..num_log-1 to logical 0..num_log-1\n    # with replica rank 0.\n    initial_phy2log = torch.arange(num_log, dtype=torch.int64, device=device).repeat(n, 1)\n    initial_rank = torch.zeros(n, num_log, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Pre-allocate `phy2log` and `rank` to the final `num_phy` size.\n    final_phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    final_rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Copy initial expert mappings\n    final_phy2log[:, :num_log] = initial_phy2log\n    final_rank[:, :num_log] = initial_rank\n\n    # Replicate experts by adding `num_redundant` physical experts.\n    # These new experts are appended starting from index `num_log`.\n    for i in range(num_log, num_phy):\n        # Find the logical expert that currently has the highest average load per replica.\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        # Assign this logical expert to the current physical expert slot `i`.\n        final_phy2log[:, i] = redundant_indices\n        # The rank of this new replica is its current count for that logical expert.\n        final_rank[:, i] = logcnt[arangen, redundant_indices]\n        # Increment the count of replicas for the chosen logical expert.\n        logcnt[arangen, redundant_indices] += 1\n    return final_phy2log, final_rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Ensure weight is float, but keep it on its original device.\n    # The .cpu() call is removed to allow GPU operations where possible,\n    # reducing device transfer overhead if `weight` originates from GPU.\n    weight = weight.float()\n    original_device = weight.device\n\n    if num_groups % num_nodes == 0:\n        # Use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # Use global load-balance policy when groups are not perfectly divisible by nodes.\n        # This simplifies the problem to a single \"node\" and \"group\" for global balancing.\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n\n    num_redundant_experts = num_replicas - num_logical_experts\n    # maxlogcnt determines the maximum number of replicas any single logical expert can have.\n    # This is used to size the `log2phy` tensor, which maps logical experts to their physical replicas.\n    maxlogcnt = num_redundant_experts + 1\n\n    # Initialize `log2phy` tensor with -1, indicating empty slots.\n    # This tensor maps [layer, logical_expert_id, replica_rank] to physical_expert_id.\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=original_device,\n    )\n\n    # Populate `log2phy` using scatter_ based on `phy2log` and `phyrank`.\n    # `phy2log` gives the logical ID for each physical expert.\n    # `phyrank` gives the replica rank for that logical ID.\n    # We flatten the last two dimensions of `log2phy` for scatter_ operation.\n    # The index for scatter_ is calculated as `logical_id * maxlogcnt + replica_rank`.\n    # The values to scatter are the physical expert IDs (0 to num_replicas-1).\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=original_device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "d9010ce8-c026-40eb-8af1-b4d49d390522", "generation": 2, "timestamp": 1751062941.5248039, "iteration_found": 207, "metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.02984742352303151, "combined_score": 0.16407788752721061}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 30 lines with 39 lines", "parent_metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.040541223449130276, "combined_score": 0.16942478749026002}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.2983\n- speed_score: 0.0405\n- combined_score: 0.1694\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0857, combined_score: 0.1920\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1097, combined_score: 0.2312\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n### Program 2 (Score: 0.2312)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1097), Performs well on combined_score (0.2312)\n\n\n### Program 3 (Score: 0.1920)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0857), Performs well on combined_score (0.1920)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1909)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1914)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.2315, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 32 lines with 32 lines, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.1920, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 4 (Score: 0.1920, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 5 (Score: 0.0000, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 59 lines with 61 lines\nChange 2: Replace 13 lines with 12 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        # If each group is its own pack, no complex packing needed.\n        # Create results directly on the original device.\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    original_device = weight.device\n    # Sort indices on CPU for the Python loop, as Python lists are used for pack_weights and pack_items.\n    # The weight tensor itself can remain on its original device.\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n\n    # Create tensors for results on CPU, then move them to the original_device at the end.\n    pack_index_cpu = torch.full_like(weight,\n                                     fill_value=-1,\n                                     dtype=torch.int64,\n                                     device=\"cpu\")\n    rank_in_pack_cpu = torch.full_like(pack_index_cpu, fill_value=-1)\n\n    for i in range(num_layers):\n        # Use float for pack_weights to avoid potential issues with large integer sums\n        # and for consistency with the input `weight` being float.\n        pack_weights = [0.0] * num_packs\n        pack_items = [0] * num_packs\n        for group in indices[i]:\n            # Find the pack with the minimum current weight that still has capacity.\n            pack = min(\n                (j for j in range(num_packs) if pack_items[j] < groups_per_pack),\n                key=pack_weights.__getitem__,\n            )\n            assert pack_items[pack] < groups_per_pack\n            pack_index_cpu[i, group] = pack\n            rank_in_pack_cpu[i, group] = pack_items[pack]\n            # Convert scalar tensor to Python float for addition to Python list.\n            pack_weights[pack] += weight[i, group].item()\n            pack_items[pack] += 1\n    return pack_index_cpu.to(original_device), rank_in_pack_cpu.to(original_device)\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    # Initialize `phy2log` and `rank` for the initial `num_log` experts.\n    # These are the non-replicated experts, mapping physical 0..num_log-1 to logical 0..num_log-1\n    # with replica rank 0.\n    initial_phy2log = torch.arange(num_log, dtype=torch.int64, device=device).repeat(n, 1)\n    initial_rank = torch.zeros(n, num_log, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Pre-allocate `phy2log` and `rank` to the final `num_phy` size.\n    final_phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    final_rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Copy initial expert mappings\n    final_phy2log[:, :num_log] = initial_phy2log\n    final_rank[:, :num_log] = initial_rank\n\n    # Replicate experts by adding `num_redundant` physical experts.\n    # These new experts are appended starting from index `num_log`.\n    for i in range(num_log, num_phy):\n        # Find the logical expert that currently has the highest average load per replica.\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        # Assign this logical expert to the current physical expert slot `i`.\n        final_phy2log[:, i] = redundant_indices\n        # The rank of this new replica is its current count for that logical expert.\n        final_rank[:, i] = logcnt[arangen, redundant_indices]\n        # Increment the count of replicas for the chosen logical expert.\n        logcnt[arangen, redundant_indices] += 1\n    return final_phy2log, final_rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Ensure weight is float, but keep it on its original device.\n    # The .cpu() call is removed to allow GPU operations where possible,\n    # reducing device transfer overhead if `weight` originates from GPU.\n    weight = weight.float()\n    original_device = weight.device\n\n    if num_groups % num_nodes == 0:\n        # Use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # Use global load-balance policy when groups are not perfectly divisible by nodes.\n        # This simplifies the problem to a single \"node\" and \"group\" for global balancing.\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n\n    num_redundant_experts = num_replicas - num_logical_experts\n    # maxlogcnt determines the maximum number of replicas any single logical expert can have.\n    # This is used to size the `log2phy` tensor, which maps logical experts to their physical replicas.\n    maxlogcnt = num_redundant_experts + 1\n\n    # Initialize `log2phy` tensor with -1, indicating empty slots.\n    # This tensor maps [layer, logical_expert_id, replica_rank] to physical_expert_id.\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=original_device,\n    )\n\n    # Populate `log2phy` using scatter_ based on `phy2log` and `phyrank`.\n    # `phy2log` gives the logical ID for each physical expert.\n    # `phyrank` gives the replica rank for that logical ID.\n    # We flatten the last two dimensions of `log2phy` for scatter_ operation.\n    # The index for scatter_ is calculated as `logical_id * maxlogcnt + replica_rank`.\n    # The values to scatter are the physical expert IDs (0 to num_replicas-1).\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=original_device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current performance metrics show a regression in all areas, especially `speed_score`. The goal is to improve both load balancing (`balancedness_score`) and execution time (`speed_score`). Given that perfect load balancing is NP-hard, the focus should be on optimizing the existing greedy heuristics.\n\nUpon reviewing the code, the `balanced_packing` function stands out as a primary bottleneck for speed. It uses Python lists and a Python-level `min` function within a nested loop, leading to significant overhead and CPU-GPU data transfers if the input `weight` is on a GPU. The other functions (`replicate_experts`, `rebalance_experts_hierarchical`) largely utilize vectorized PyTorch operations, making them more efficient.\n\nThe proposed improvement focuses on rewriting the core loop within `balanced_packing` to leverage PyTorch tensor operations as much as possible, minimizing Python loop overhead and unnecessary device transfers. The underlying greedy heuristic (assigning the heaviest remaining item to the pack with the minimum current weight, respecting capacity limits) remains the same, so `balancedness_score` should not degrade, and `speed_score` is expected to improve significantly.\n\n**Detailed changes and reasoning for `balanced_packing`:**\n\n1.  **Eliminate CPU Transfers for Indices:**\n    *   Original: `indices = weight.float().sort(-1, descending=True).indices.cpu()`\n    *   Improved: `sorted_weights, indices = weight.float().sort(-1, descending=True)`\n    *   **Reasoning:** Sorting `weight` and obtaining `indices` directly on the `original_device` avoids a costly transfer of indices to CPU.\n\n2.  **Initialize Result Tensors on Original Device:**\n    *   Original: `pack_index_cpu = torch.full_like(weight, ..., device=\"cpu\")`, `rank_in_pack_cpu = torch.full_like(pack_index_cpu, ..., device=\"cpu\")`, followed by a final `to(original_device)`.\n    *   Improved: `pack_index = torch.empty_like(weight, dtype=torch.int64)`, `rank_in_pack = torch.empty_like(weight, dtype=torch.int64)`, directly on the `original_device`.\n    *   **Reasoning:** This allows direct assignment to the final result tensors on the GPU, avoiding repeated CPU-GPU synchronization for each assignment within the loop and a final large transfer.\n\n3.  **Use PyTorch Tensors for Pack States:**\n    *   Original: `pack_weights = [0.0] * num_packs`, `pack_items = [0] * num_packs` (Python lists).\n    *   Improved: `pack_weights_i = torch.zeros(num_packs, dtype=torch.float32, device=original_device)`, `pack_items_i = torch.zeros(num_packs, dtype=torch.int64, device=original_device)` (PyTorch tensors).\n    *   **Reasoning:** Performing arithmetic operations like `pack_weights[pack] += weight[i, group].item()` with Python lists and `item()` calls forces CPU interaction. By using PyTorch tensors for `pack_weights_i` and `pack_items_i`, these operations become efficient tensor additions on the GPU.\n\n4.  **Efficient Pack Selection with `torch.argmin`:**\n    *   Original: `pack = min((j for j in range(num_packs) if pack_items[j] < groups_per_pack), key=pack_weights.__getitem__)` (Python generator and `min` call).\n    *   Improved: `capacity_mask = (pack_items_i < groups_per_pack)`, `masked_pack_weights = pack_weights_i.clone()`, `masked_pack_weights[~capacity_mask] = float('inf')`, `pack = torch.argmin(masked_pack_weights)`.\n    *   **Reasoning:** This is a common and highly efficient PyTorch pattern. By masking out full packs with `float('inf')`, `torch.argmin` directly identifies the eligible pack with the minimum current weight, leveraging optimized C++/CUDA kernels instead of slow Python iteration.\n\n5.  **Direct Assignment to Result Tensors:**\n    *   Original: `pack_index_cpu[i, group] = pack`, `rank_in_pack_cpu[i, group] = pack_items[pack]`. These assign Python integers to a CPU tensor.\n    *   Improved: `pack_index[i, original_group_idx] = pack`, `rank_in_pack[i, original_group_idx] = pack_items_i[pack]`. These assign PyTorch tensors (single-element) directly to GPU tensors.\n    *   **Reasoning:** This avoids the `item()` call and subsequent CPU-GPU synchronization for each assignment, which can be a significant overhead in a loop.\n\nThese changes transform the most computationally intensive part of the algorithm from a Python-bound operation to a largely GPU-accelerated one, which should lead to a substantial improvement in `speed_score` without altering the core load balancing logic, thus preserving or potentially improving `balancedness_score` due to reduced noise from CPU-GPU transfers.\n\n<<<<<<< SEARCH\n    original_device = weight.device\n    # Sort indices on CPU for the Python loop, as Python lists are used for pack_weights and pack_items.\n    # The weight tensor itself can remain on its original device.\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n\n    # Create tensors for results on CPU, then move them to the original_device at the end.\n    pack_index_cpu = torch.full_like(weight,\n                                     fill_value=-1,\n                                     dtype=torch.int64,\n                                     device=\"cpu\")\n    rank_in_pack_cpu = torch.full_like(pack_index_cpu, fill_value=-1)\n\n    for i in range(num_layers):\n        # Use float for pack_weights to avoid potential issues with large integer sums\n        # and for consistency with the input `weight` being float.\n        pack_weights = [0.0] * num_packs\n        pack_items = [0] * num_packs\n        for group in indices[i]:\n            # Find the pack with the minimum current weight that still has capacity.\n            pack = min(\n                (j for j in range(num_packs) if pack_items[j] < groups_per_pack),\n                key=pack_weights.__getitem__,\n            )\n            assert pack_items[pack] < groups_per_pack\n            pack_index_cpu[i, group] = pack\n            rank_in_pack_cpu[i, group] = pack_items[pack]\n            # Convert scalar tensor to Python float for addition to Python list.\n            pack_weights[pack] += weight[i, group].item()\n            pack_items[pack] += 1\n    return pack_index_cpu.to(original_device), rank_in_pack_cpu.to(original_device)\n=======\n    original_device = weight.device\n    # Sort indices on the original device. This avoids CPU transfer for indices.\n    # The weights themselves will be accessed directly from the original device.\n    _, indices = weight.float().sort(-1, descending=True)\n\n    # Create tensors for results directly on the original_device.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(weight, dtype=torch.int64)\n\n    for i in range(num_layers):\n        # Use PyTorch tensors for pack_weights and pack_items for current layer.\n        # This keeps calculations on the original_device and avoids Python list overhead.\n        pack_weights_i = torch.zeros(num_packs, dtype=torch.float32, device=original_device)\n        pack_items_i = torch.zeros(num_packs, dtype=torch.int64, device=original_device)\n\n        current_layer_original_indices = indices[i] # Indices of experts in sorted order for current layer\n        current_layer_original_weights = weight[i] # Original weights for current layer\n\n        for k in range(num_groups): # Iterate through experts in descending weight order\n            original_group_idx = current_layer_original_indices[k]\n\n            # Find the pack with the minimum current weight that still has capacity.\n            # Mask out packs that are already full by setting their weights to infinity.\n            # Then use argmin to find the pack with the smallest valid weight.\n            capacity_mask = (pack_items_i < groups_per_pack)\n            masked_pack_weights = pack_weights_i.clone()\n            # Set weights of full packs to infinity to exclude them from selection by argmin\n            masked_pack_weights[~capacity_mask] = float('inf')\n\n            pack = torch.argmin(masked_pack_weights)\n\n            # Assign results to the output tensors for the current layer and original expert index.\n            pack_index[i, original_group_idx] = pack\n            rank_in_pack[i, original_group_idx] = pack_items_i[pack]\n\n            # Update pack states\n            pack_weights_i[pack] += current_layer_original_weights[original_group_idx]\n            pack_items_i[pack] += 1\n    return pack_index, rank_in_pack\n>>>>>>> REPLACE"]}}}