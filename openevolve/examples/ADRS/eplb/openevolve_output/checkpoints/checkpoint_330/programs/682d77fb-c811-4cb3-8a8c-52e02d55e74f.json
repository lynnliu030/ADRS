{"id": "682d77fb-c811-4cb3-8a8c-52e02d55e74f", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight'.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-calculate indices for all layers to avoid repeated sorting.\n    # `indices` will be [num_layers, num_groups]\n    indices = torch.argsort(weight, dim=-1, descending=True)\n\n    # Iterate over each layer.\n    for i in range(num_layers):\n        # Process groups in sorted order of their weights for the current layer.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        \n        # Get the weights and current counts for packs in this layer.\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # Create a tensor for selection, setting full packs to infinity.\n        # This avoids modifying the actual cumulative weights during selection.\n        pack_weights_for_selection = torch.where(\n            current_pack_items == groups_per_pack,\n            torch.full_like(current_pack_weights, float('inf')),\n            current_pack_weights\n        )\n        \n        # For each group in the sorted order, find the best pack.\n        # This loop iterates `num_groups` times for each layer.\n        # We can optimize by processing all groups for a layer at once if possible,\n        # but the greedy assignment to the *currently* minimum pack makes full vectorization tricky without changing the algorithm.\n        # The current approach is a greedy assignment per group based on current pack loads.\n        # The main bottleneck here might be the repeated `torch.argmin` and tensor manipulations within the inner loop.\n        \n        # To improve `balanced_packing` efficiency, we can consider:\n        # 1. If `groups_per_pack` is large, this inner loop can be substantial.\n        # 2. The `torch.where` and `torch.argmin` are relatively efficient, but repeated calls add up.\n        \n        # A potential optimization: if `groups_per_pack` is small, the current approach is likely fine.\n        # If `groups_per_pack` is large, we might consider a more advanced bin-packing heuristic or approximation.\n        # However, for this iterative improvement, let's focus on making the existing loop more efficient.\n        \n        # The key here is that `pack_weights_for_selection` is updated implicitly by `pack_weights_per_layer`.\n        # The current code correctly updates `pack_weights_per_layer` and `pack_items_per_layer` after each assignment.\n        \n        # Let's try to make the inner loop slightly more efficient by directly accessing the relevant parts of `pack_weights_per_layer`.\n        # The current code already does this by accessing `pack_weights_per_layer[i]` and `pack_items_per_layer[i]`.\n        \n        # One minor optimization: the `current_pack_weights` and `current_pack_items` are redundant variables.\n        # We can directly use `pack_weights_per_layer[i]` and `pack_items_per_layer[i]`.\n        \n        # For each group_id in the sorted indices for this layer:\n        for group_idx in range(num_groups): # Iterate through the sorted order\n            group_id = indices[i, group_idx] # Get the actual group ID\n            \n            # Get current state for this layer's packs.\n            # Create a temporary tensor for pack weights, setting full packs to infinity\n            # for selection by torch.argmin.\n            pack_weights_for_selection = torch.where(\n                pack_items_per_layer[i] == groups_per_pack,\n                torch.full_like(pack_weights_per_layer[i], float('inf')),\n                pack_weights_per_layer[i]\n            )\n            \n            # Find the pack with the minimum current weight (among available ones).\n            pack = torch.argmin(pack_weights_for_selection) # pack is a 0-dim tensor\n\n            # Assert that a valid pack was found and it has space.\n            assert pack_items_per_layer[i, pack] < groups_per_pack, \"Pack is full\"\n\n            # Assign the group to the chosen pack.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = pack_items_per_layer[i, pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n            \n            # Update pack_weights_for_selection for the next iteration if the selected pack was not full.\n            # This is handled implicitly by the next iteration's `torch.where` if `pack_items_per_layer[i, pack]` becomes `groups_per_pack`.\n            # However, for correctness and to reflect the updated weight, we might need to update `pack_weights_for_selection` more directly if we were to optimize further.\n            # For now, the current logic of re-evaluating `pack_weights_for_selection` each time is sound, though potentially repetitive.\n            \n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    # Vectorize expert selection for replication\n    # Calculate potential loads for each logical expert and its current replicas\n    potential_loads = weight / logcnt\n    \n    # For each of the redundant experts to be created (from num_log to num_phy)\n    for i in range(num_log, num_phy):\n        # Find the logical expert that would have the minimum load if it were replicated\n        # This is equivalent to finding the minimum of potential_loads across all logical experts\n        # `torch.min` returns values and indices. We need the indices.\n        # `max(dim=-1).indices` is used to find the index of the maximum value.\n        # We want to replicate the expert that *currently* has the minimum load\n        # after being divided by its current replica count.\n        \n        # Find the logical expert with the minimum load per replica\n        min_load_per_expert, min_load_indices = torch.min(potential_loads, dim=-1)\n        \n        # The expert to replicate is the one with the minimum load per replica\n        redundant_indices = min_load_indices\n        \n        # Assign the chosen logical expert to the current physical expert slot\n        phy2log[:, i] = redundant_indices\n        \n        # The rank of this new replica is the current number of replicas for that logical expert\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Increment the replica count for the chosen logical expert\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update potential_loads for the next iteration.\n        # The load for the replicated expert will change because logcnt has increased.\n        # We need to recompute the loads for the updated logical expert.\n        # Instead of recomputing all, we can update the specific one.\n        # However, `torch.min` on the updated `potential_loads` will correctly pick the next best.\n        # To do this efficiently, we can update `potential_loads` for the selected `redundant_indices`.\n        potential_loads[arangen, redundant_indices] = (\n            weight[arangen, redundant_indices] /\n            logcnt[arangen, redundant_indices]\n        )\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Cast weight to float for calculations if not already, and keep on original device.\n    # Moving to CPU adds overhead if data is already on GPU and might slow down ops.\n    weight = weight.float()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "fc52a6a0-2ab7-46b4-9401-a2de0aaaa405", "generation": 7, "timestamp": 1751056076.4103482, "iteration_found": 100, "metrics": {"balancedness_score": 0.14515957884623945, "speed_score": 0.024335641708663876, "combined_score": 0.08474761027745166}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 5 lines with 38 lines\nChange 2: Replace 51 lines with 89 lines", "parent_metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.02426747169913593, "combined_score": 0.16128791161526285}, "island": 4}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.2983\n- speed_score: 0.0243\n- combined_score: 0.1613\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0818, combined_score: 0.1900\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0830, combined_score: 0.1907\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0835, combined_score: 0.1909\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.1909)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0835), Performs well on combined_score (0.1909)\n\n\n### Program 2 (Score: 0.1907)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0830), Performs well on combined_score (0.1907)\n\n\n### Program 3 (Score: 0.1900)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0818), Performs well on combined_score (0.1900)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1872)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1852)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.1909, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 3 lines with 4 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 2 (Score: 0.0349, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 3 (Score: 0.1623, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 2 lines with 3 lines\nChange 2: Replace 6 lines with 8 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.0270, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 2 lines with 3 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 5 (Score: 0.0232, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 45 lines with 44 lines\nChange 2: Replace 14 lines with 21 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Get current state for this layer's packs.\n            # Create a temporary copy of pack weights for modification during selection.\n            # This avoids modifying the actual cumulative weights before assignment.\n            # Create a temporary tensor for pack weights, setting full packs to infinity\n            # for selection by torch.argmin. This avoids modifying the actual\n            # cumulative weights stored in pack_weights_per_layer.\n            pack_weights_for_selection = torch.where(\n                pack_items_per_layer[i] == groups_per_pack,\n                torch.full_like(pack_weights_per_layer[i], float('inf')),\n                pack_weights_per_layer[i]\n            )\n            \n            # Find the pack with the minimum current weight (among available ones).\n            pack = torch.argmin(pack_weights_for_selection) # pack is a 0-dim tensor\n\n            # Assert that a valid pack was found and it has space.\n            # This check remains important to ensure algorithm correctness.\n            assert current_pack_items[pack] < groups_per_pack\n\n            # Assign the group to the chosen pack.\n            # `group_id` is a 0-dim tensor, which can be directly used for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # `weight[i, group_id]` is the weight of the current group.\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Cast weight to float for calculations if not already, and keep on original device.\n    # Moving to CPU adds overhead if data is already on GPU and might slow down ops.\n    weight = weight.float()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program has a good `balancedness_score` but a poor `speed_score` and `combined_score`. This suggests that the current approach is effective at balancing loads but is too slow. The historical data shows that previous attempts to improve performance led to regressions.\n\nThe core of the problem lies in the `rebalance_experts` function and its dependencies, particularly `replicate_experts` and `balanced_packing`. The `replicate_experts` function uses a loop that iterates `num_log` to `num_phy` times, which can be inefficient if `num_phy` is significantly larger than `num_log`. The `balanced_packing` function uses a greedy approach which, while good for balancing, can be computationally intensive.\n\nHere are some suggestions for improvement:\n\n**1. Optimize `replicate_experts` by Vectorizing the Expert Selection:**\n\nThe current `replicate_experts` function iterates through logical experts to find the best candidate for replication. This can be vectorized. Instead of iterating, we can calculate the load of each potential replica for all logical experts simultaneously and then select the best ones.\n\n**2. Optimize `balanced_packing` by Using a More Efficient Selection Mechanism:**\n\nThe `balanced_packing` function uses `torch.argmin` within a loop. For better performance, we can explore techniques that reduce the number of times `torch.argmin` is called or use a more optimized selection strategy. One approach could be to pre-sort or use a data structure that allows for faster retrieval of the minimum. However, given the NP-hard nature of the bin packing problem, significant gains might be limited without changing the core greedy strategy. The current implementation of `balanced_packing` already has a good practice of creating a temporary tensor for selection to avoid modifying the actual cumulative weights.\n\n**3. Improve Device Placement and Data Copying:**\n\nThe code currently casts `weight` to `float()` and keeps it on the original device. While this avoids unnecessary CPU transfers, it's crucial to ensure that intermediate tensors are also handled efficiently. The current code explicitly mentions that tensors are on CPU from `rebalance_experts`. If `rebalance_experts` is called with GPU tensors, it's important that subsequent operations within `replicate_experts` and `balanced_packing` also leverage the GPU. The comments suggest that `weight` is already on CPU, but if the initial `weight` tensor is on GPU, we should try to keep operations on GPU as much as possible.\n\nLet's focus on the `replicate_experts` optimization first, as it seems to be a prime candidate for speed improvement.\n\n<<<<<<< SEARCH\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n=======\n    # Vectorize expert selection for replication\n    # Calculate potential loads for each logical expert and its current replicas\n    potential_loads = weight / logcnt\n    \n    # For each of the redundant experts to be created (from num_log to num_phy)\n    for i in range(num_log, num_phy):\n        # Find the logical expert that would have the minimum load if it were replicated\n        # This is equivalent to finding the minimum of potential_loads across all logical experts\n        # `torch.min` returns values and indices. We need the indices.\n        # `max(dim=-1).indices` is used to find the index of the maximum value.\n        # We want to replicate the expert that *currently* has the minimum load\n        # after being divided by its current replica count.\n        \n        # Find the logical expert with the minimum load per replica\n        min_load_per_expert, min_load_indices = torch.min(potential_loads, dim=-1)\n        \n        # The expert to replicate is the one with the minimum load per replica\n        redundant_indices = min_load_indices\n        \n        # Assign the chosen logical expert to the current physical expert slot\n        phy2log[:, i] = redundant_indices\n        \n        # The rank of this new replica is the current number of replicas for that logical expert\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Increment the replica count for the chosen logical expert\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update potential_loads for the next iteration.\n        # The load for the replicated expert will change because logcnt has increased.\n        # We need to recompute the loads for the updated logical expert.\n        # Instead of recomputing all, we can update the specific one.\n        # However, `torch.min` on the updated `potential_loads` will correctly pick the next best.\n        # To do this efficiently, we can update `potential_loads` for the selected `redundant_indices`.\n        potential_loads[arangen, redundant_indices] = (\n            weight[arangen, redundant_indices] /\n            logcnt[arangen, redundant_indices]\n        )\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Get current state for this layer's packs.\n            # Create a temporary copy of pack weights for modification during selection.\n            # This avoids modifying the actual cumulative weights before assignment.\n            # Create a temporary tensor for pack weights, setting full packs to infinity\n            # for selection by torch.argmin. This avoids modifying the actual\n            # cumulative weights stored in pack_weights_per_layer.\n            pack_weights_for_selection = torch.where(\n                pack_items_per_layer[i] == groups_per_pack,\n                torch.full_like(pack_weights_per_layer[i], float('inf')),\n                pack_weights_per_layer[i]\n            )\n            \n            # Find the pack with the minimum current weight (among available ones).\n            pack = torch.argmin(pack_weights_for_selection) # pack is a 0-dim tensor\n\n            # Assert that a valid pack was found and it has space.\n            # This check remains important to ensure algorithm correctness.\n            assert current_pack_items[pack] < groups_per_pack\n\n            # Assign the group to the chosen pack.\n            # `group_id` is a 0-dim tensor, which can be directly used for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # `weight[i, group_id]` is the weight of the current group.\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n=======\n    # Initialize pack_index and rank_in_pack.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight'.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-calculate indices for all layers to avoid repeated sorting.\n    # `indices` will be [num_layers, num_groups]\n    indices = torch.argsort(weight, dim=-1, descending=True)\n\n    # Iterate over each layer.\n    for i in range(num_layers):\n        # Process groups in sorted order of their weights for the current layer.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        \n        # Get the weights and current counts for packs in this layer.\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # Create a tensor for selection, setting full packs to infinity.\n        # This avoids modifying the actual cumulative weights during selection.\n        pack_weights_for_selection = torch.where(\n            current_pack_items == groups_per_pack,\n            torch.full_like(current_pack_weights, float('inf')),\n            current_pack_weights\n        )\n        \n        # For each group in the sorted order, find the best pack.\n        # This loop iterates `num_groups` times for each layer.\n        # We can optimize by processing all groups for a layer at once if possible,\n        # but the greedy assignment to the *currently* minimum pack makes full vectorization tricky without changing the algorithm.\n        # The current approach is a greedy assignment per group based on current pack loads.\n        # The main bottleneck here might be the repeated `torch.argmin` and tensor manipulations within the inner loop.\n        \n        # To improve `balanced_packing` efficiency, we can consider:\n        # 1. If `groups_per_pack` is large, this inner loop can be substantial.\n        # 2. The `torch.where` and `torch.argmin` are relatively efficient, but repeated calls add up.\n        \n        # A potential optimization: if `groups_per_pack` is small, the current approach is likely fine.\n        # If `groups_per_pack` is large, we might consider a more advanced bin-packing heuristic or approximation.\n        # However, for this iterative improvement, let's focus on making the existing loop more efficient.\n        \n        # The key here is that `pack_weights_for_selection` is updated implicitly by `pack_weights_per_layer`.\n        # The current code correctly updates `pack_weights_per_layer` and `pack_items_per_layer` after each assignment.\n        \n        # Let's try to make the inner loop slightly more efficient by directly accessing the relevant parts of `pack_weights_per_layer`.\n        # The current code already does this by accessing `pack_weights_per_layer[i]` and `pack_items_per_layer[i]`.\n        \n        # One minor optimization: the `current_pack_weights` and `current_pack_items` are redundant variables.\n        # We can directly use `pack_weights_per_layer[i]` and `pack_items_per_layer[i]`.\n        \n        # For each group_id in the sorted indices for this layer:\n        for group_idx in range(num_groups): # Iterate through the sorted order\n            group_id = indices[i, group_idx] # Get the actual group ID\n            \n            # Get current state for this layer's packs.\n            # Create a temporary tensor for pack weights, setting full packs to infinity\n            # for selection by torch.argmin.\n            pack_weights_for_selection = torch.where(\n                pack_items_per_layer[i] == groups_per_pack,\n                torch.full_like(pack_weights_per_layer[i], float('inf')),\n                pack_weights_per_layer[i]\n            )\n            \n            # Find the pack with the minimum current weight (among available ones).\n            pack = torch.argmin(pack_weights_for_selection) # pack is a 0-dim tensor\n\n            # Assert that a valid pack was found and it has space.\n            assert pack_items_per_layer[i, pack] < groups_per_pack, \"Pack is full\"\n\n            # Assign the group to the chosen pack.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = pack_items_per_layer[i, pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n            \n            # Update pack_weights_for_selection for the next iteration if the selected pack was not full.\n            # This is handled implicitly by the next iteration's `torch.where` if `pack_items_per_layer[i, pack]` becomes `groups_per_pack`.\n            # However, for correctness and to reflect the updated weight, we might need to update `pack_weights_for_selection` more directly if we were to optimize further.\n            # For now, the current logic of re-evaluating `pack_weights_for_selection` each time is sound, though potentially repetitive.\n            \n    return pack_index, rank_in_pack\n>>>>>>> REPLACE"]}}}