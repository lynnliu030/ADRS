{"id": "7b4eb902-aa66-4bff-9f11-2c43bbd6a1e9", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight'.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-allocate a tensor for float('inf') to avoid repeated creation.\n    # This tensor will be used in torch.where to mask full packs.\n    infinity_mask_filler = torch.full((num_packs,), float('inf'), dtype=weight.dtype, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        current_layer_indices = indices[i] # Cache for performance\n        current_layer_weights = weight[i] # Cache for performance\n\n        for group_id_tensor in current_layer_indices: # group_id is a 0-dim tensor\n            group_id = group_id_tensor.item() # Convert to scalar for direct indexing\n\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find the pack with the minimum current weight among available ones.\n            # Use torch.where to conditionally set weights to infinity for full packs.\n            pack = torch.argmin(\n                torch.where(current_pack_items < groups_per_pack,\n                            current_pack_weights,\n                            infinity_mask_filler))\n\n            # Assert that a valid pack was found and it has space.\n            assert current_pack_items[pack] < groups_per_pack, \\\n                f\"No available packs found, but expected to find one. Pack {pack} is full.\"\n\n            # Assign the group to the chosen pack.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            pack_weights_per_layer[i, pack] += current_layer_weights[group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas using a proportional\n    assignment strategy. This is a faster approximation to the greedy LPT.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n    device = weight.device\n\n    # Calculate desired total weight per replica for each layer\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n\n    # Calculate target logcnt (float) for each expert based on its proportion of total weight.\n    # Handle layers with zero total weight by distributing evenly.\n    target_logcnt_float = torch.where(\n        total_weight_per_layer > 0,\n        weight / total_weight_per_layer * num_phy,\n        torch.full_like(weight, num_phy / num_log)  # Distribute evenly if total_weight is 0\n    )\n\n    # Initial integer counts: floor of target_logcnt_float, ensuring at least 1 replica.\n    # Using floor ensures sum(logcnt) <= num_phy initially (due to rounding down).\n    logcnt = torch.max(torch.ones_like(target_logcnt_float, dtype=torch.int64),\n                       target_logcnt_float.floor().long())\n\n    # Calculate remaining replicas to distribute for each layer.\n    # This difference should be non-negative.\n    remaining_replicas = num_phy - logcnt.sum(dim=-1)\n\n    # Distribute remaining replicas greedily based on the fractional parts.\n    # This ensures the total count for each layer sums exactly to num_phy.\n    fractional_parts = target_logcnt_float - logcnt.float()\n\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Each expert gets at least `base_add` additional replicas.\n            # This handles cases where `num_to_add` is greater than `num_log`.\n            base_add = num_to_add // num_log\n            logcnt[i] += base_add\n\n            # Distribute the remaining `remainder_add` replicas based on fractional parts.\n            remainder_add = num_to_add % num_log\n            if remainder_add > 0:\n                # Get the top `remainder_add` indices by fractional part for this layer\n                _, top_indices = fractional_parts[i].topk(remainder_add)\n                # Increment logcnt for these chosen experts by 1\n                logcnt[i].scatter_add_(0, top_indices, torch.ones(remainder_add, dtype=torch.int64, device=device))\n\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count.\n    # Pre-allocate tensors for phy2log and rank.\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Iterate over each layer to populate phy2log and rank.\n    # The inner loops are vectorized for efficiency.\n    for i in range(n):\n        # Generate logical expert IDs for replication using repeat_interleave.\n        # Example: if logcnt[i] = [2, 1, 3] for num_log=3, this creates [0, 0, 1, 2, 2, 2].\n        layer_log_expert_ids = torch.repeat_interleave(\n            torch.arange(num_log, device=device), logcnt[i])\n\n        # Generate replica ranks for each repeated expert.\n        # Example: For logcnt[i] = [2, 1, 3], this creates [0, 1, 0, 0, 1, 2].\n        # This uses a list comprehension with torch.cat, which is efficient for typical num_log.\n        layer_ranks = torch.cat(\n            [torch.arange(count, device=device) for count in logcnt[i]])\n\n        # Safety check: Ensure the total generated physical experts match num_phy.\n        # This should always hold if remaining_replicas distribution was correct.\n        assert layer_log_expert_ids.size(0) == num_phy, \\\n            f\"Layer {i}: Generated {layer_log_expert_ids.size(0)} physical experts, expected {num_phy}\"\n        assert layer_ranks.size(0) == num_phy, \\\n            f\"Layer {i}: Generated {layer_ranks.size(0)} ranks, expected {num_phy}\"\n\n        # Shuffle physical expert assignments within each layer.\n        # This is crucial for distributing replicas across physical resources,\n        # preventing all replicas of an expert from being assigned consecutively,\n        # which helps in actual load balancing on GPUs.\n        perm = torch.randperm(num_phy, device=device)\n        phy2log[i] = layer_log_expert_ids[perm]\n        rank[i] = layer_ranks[perm]\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Store original device for results\n    original_device = weight.device\n    # Move weight to CPU for computations to avoid frequent GPU kernel launches\n    # within Python loops, which can be inefficient for this type of algorithm.\n    weight_on_cpu = weight.float().cpu()\n\n    # Add assertion for num_replicas\n    assert num_replicas % num_gpus == 0, \\\n        f\"num_replicas ({num_replicas}) must be a multiple of num_gpus ({num_gpus})\"\n\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank_local, logcnt = rebalance_experts_hierarchical(\n            weight_on_cpu, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        # For global policy, num_groups and num_nodes are effectively 1.\n        phy2log, phyrank_local, logcnt = rebalance_experts_hierarchical(\n            weight_on_cpu, num_replicas, 1, 1, num_gpus)\n\n    # Calculate max possible replicas for any logical expert globally.\n    # This is used for sizing the log2phy tensor correctly.\n    # An expert can have at most `num_replicas - (num_logical_experts - 1)` replicas\n    # if all other experts get exactly 1 replica.\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n\n    # Calculate global replica ranks for each physical expert.\n    # This is necessary because phyrank_local (from hierarchical/replicate_experts)\n    # is a local rank within a meta-logical expert, not a global rank needed for log2phy.\n    global_phyranks = torch.zeros_like(phy2log, dtype=torch.int64)\n    for layer_idx in range(num_layers):\n        current_expert_replica_counts = torch.zeros(\n            num_logical_experts, dtype=torch.int64, device=weight_on_cpu.device)\n        # Iterate through physical experts in their assigned order within the layer\n        for phy_idx in range(num_replicas):\n            logical_expert_id = phy2log[layer_idx, phy_idx].item()\n            global_phyranks[layer_idx, phy_idx] = current_expert_replica_counts[logical_expert_id]\n            current_expert_replica_counts[logical_expert_id] += 1\n\n    # Construct logical_to_physical_map (log2phy) using the correct global ranks.\n    # Initialize with -1 to indicate unassigned slots.\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=weight_on_cpu.device,\n    )\n    # Use scatter_ to populate log2phy. The index is calculated as\n    # logical_expert_id * maxlogcnt + global_replica_rank.\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + global_phyranks,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=weight_on_cpu.device).expand(num_layers, -1),\n    )\n\n    # Move results back to the original device\n    phy2log = phy2log.to(original_device)\n    log2phy = log2phy.to(original_device)\n    logcnt = logcnt.to(original_device)\n\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "45c19290-a1d6-4f84-828e-583b6251d0ad", "generation": 7, "timestamp": 1751065538.360637, "iteration_found": 246, "metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "Layer 0: Generated 134 physical experts, expected 72"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 9 lines with 17 lines", "parent_metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "Layer 0: Generated 134 physical experts, expected 72"}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.0000\n- speed_score: 0.0000\n- combined_score: 0.0000\n- error: Layer 0: Generated 134 physical experts, expected 72\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n### Program 2 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n### Program 3 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.2315, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 32 lines with 32 lines, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.0000, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 5 (Score: 0.1648, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 3 lines with 3 lines\nChange 2: Replace 2 lines with 2 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight'.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-allocate a tensor for float('inf') to avoid repeated creation.\n    # This tensor will be used in torch.where to mask full packs.\n    infinity_mask_filler = torch.full((num_packs,), float('inf'), dtype=weight.dtype, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        current_layer_indices = indices[i] # Cache for performance\n        current_layer_weights = weight[i] # Cache for performance\n\n        for group_id_tensor in current_layer_indices: # group_id is a 0-dim tensor\n            group_id = group_id_tensor.item() # Convert to scalar for direct indexing\n\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find the pack with the minimum current weight among available ones.\n            # Use torch.where to conditionally set weights to infinity for full packs.\n            pack = torch.argmin(\n                torch.where(current_pack_items < groups_per_pack,\n                            current_pack_weights,\n                            infinity_mask_filler))\n\n            # Assert that a valid pack was found and it has space.\n            assert current_pack_items[pack] < groups_per_pack, \\\n                f\"No available packs found, but expected to find one. Pack {pack} is full.\"\n\n            # Assign the group to the chosen pack.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            pack_weights_per_layer[i, pack] += current_layer_weights[group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas using a proportional\n    assignment strategy. This is a faster approximation to the greedy LPT.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n    device = weight.device\n\n    # Calculate desired total weight per replica for each layer\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n\n    # Calculate target logcnt (float) for each expert based on its proportion of total weight.\n    # Handle layers with zero total weight by distributing evenly.\n    target_logcnt_float = torch.where(\n        total_weight_per_layer > 0,\n        weight / total_weight_per_layer * num_phy,\n        torch.full_like(weight, num_phy / num_log)  # Distribute evenly if total_weight is 0\n    )\n\n    # Initial integer counts: floor of target_logcnt_float, ensuring at least 1 replica.\n    # Using floor ensures sum(logcnt) <= num_phy initially (due to rounding down).\n    logcnt = torch.max(torch.ones_like(target_logcnt_float, dtype=torch.int64),\n                       target_logcnt_float.floor().long())\n\n    # Calculate remaining replicas to distribute for each layer.\n    # This difference should be non-negative.\n    remaining_replicas = num_phy - logcnt.sum(dim=-1)\n\n    # Distribute remaining replicas greedily based on the fractional parts.\n    # This ensures the total count for each layer sums exactly to num_phy.\n    fractional_parts = target_logcnt_float - logcnt.float()\n\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Get the top `num_to_add` indices by fractional part for this layer\n            _, top_indices = fractional_parts[i].topk(num_to_add)\n            # Increment logcnt for these chosen experts\n            logcnt[i].scatter_add_(0, top_indices, torch.ones(num_to_add, dtype=torch.int64, device=device))\n\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count.\n    # Pre-allocate tensors for phy2log and rank.\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Iterate over each layer to populate phy2log and rank.\n    # The inner loops are vectorized for efficiency.\n    for i in range(n):\n        # Generate logical expert IDs for replication using repeat_interleave.\n        # Example: if logcnt[i] = [2, 1, 3] for num_log=3, this creates [0, 0, 1, 2, 2, 2].\n        layer_log_expert_ids = torch.repeat_interleave(\n            torch.arange(num_log, device=device), logcnt[i])\n\n        # Generate replica ranks for each repeated expert.\n        # Example: For logcnt[i] = [2, 1, 3], this creates [0, 1, 0, 0, 1, 2].\n        # This uses a list comprehension with torch.cat, which is efficient for typical num_log.\n        layer_ranks = torch.cat(\n            [torch.arange(count, device=device) for count in logcnt[i]])\n\n        # Safety check: Ensure the total generated physical experts match num_phy.\n        # This should always hold if remaining_replicas distribution was correct.\n        assert layer_log_expert_ids.size(0) == num_phy, \\\n            f\"Layer {i}: Generated {layer_log_expert_ids.size(0)} physical experts, expected {num_phy}\"\n        assert layer_ranks.size(0) == num_phy, \\\n            f\"Layer {i}: Generated {layer_ranks.size(0)} ranks, expected {num_phy}\"\n\n        # Shuffle physical expert assignments within each layer.\n        # This is crucial for distributing replicas across physical resources,\n        # preventing all replicas of an expert from being assigned consecutively,\n        # which helps in actual load balancing on GPUs.\n        perm = torch.randperm(num_phy, device=device)\n        phy2log[i] = layer_log_expert_ids[perm]\n        rank[i] = layer_ranks[perm]\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Store original device for results\n    original_device = weight.device\n    # Move weight to CPU for computations to avoid frequent GPU kernel launches\n    # within Python loops, which can be inefficient for this type of algorithm.\n    weight_on_cpu = weight.float().cpu()\n\n    # Add assertion for num_replicas\n    assert num_replicas % num_gpus == 0, \\\n        f\"num_replicas ({num_replicas}) must be a multiple of num_gpus ({num_gpus})\"\n\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank_local, logcnt = rebalance_experts_hierarchical(\n            weight_on_cpu, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        # For global policy, num_groups and num_nodes are effectively 1.\n        phy2log, phyrank_local, logcnt = rebalance_experts_hierarchical(\n            weight_on_cpu, num_replicas, 1, 1, num_gpus)\n\n    # Calculate max possible replicas for any logical expert globally.\n    # This is used for sizing the log2phy tensor correctly.\n    # An expert can have at most `num_replicas - (num_logical_experts - 1)` replicas\n    # if all other experts get exactly 1 replica.\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n\n    # Calculate global replica ranks for each physical expert.\n    # This is necessary because phyrank_local (from hierarchical/replicate_experts)\n    # is a local rank within a meta-logical expert, not a global rank needed for log2phy.\n    global_phyranks = torch.zeros_like(phy2log, dtype=torch.int64)\n    for layer_idx in range(num_layers):\n        current_expert_replica_counts = torch.zeros(\n            num_logical_experts, dtype=torch.int64, device=weight_on_cpu.device)\n        # Iterate through physical experts in their assigned order within the layer\n        for phy_idx in range(num_replicas):\n            logical_expert_id = phy2log[layer_idx, phy_idx].item()\n            global_phyranks[layer_idx, phy_idx] = current_expert_replica_counts[logical_expert_id]\n            current_expert_replica_counts[logical_expert_id] += 1\n\n    # Construct logical_to_physical_map (log2phy) using the correct global ranks.\n    # Initialize with -1 to indicate unassigned slots.\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=weight_on_cpu.device,\n    )\n    # Use scatter_ to populate log2phy. The index is calculated as\n    # logical_expert_id * maxlogcnt + global_replica_rank.\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + global_phyranks,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=weight_on_cpu.device).expand(num_layers, -1),\n    )\n\n    # Move results back to the original device\n    phy2log = phy2log.to(original_device)\n    log2phy = log2phy.to(original_device)\n    logcnt = logcnt.to(original_device)\n\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program exhibits an error: \"Layer 0: Generated 134 physical experts, expected 72\". This indicates a mismatch between the number of physical experts that are actually generated by the `replicate_experts` function and the number that are expected (`num_phy`).\n\nUpon reviewing the `replicate_experts` function, the issue lies in how the `remaining_replicas` are distributed. Specifically, the line `_, top_indices = fractional_parts[i].topk(num_to_add)` is problematic when `num_to_add` (the number of remaining replicas to distribute) is greater than `num_log` (the total number of logical experts). In such a scenario, `torch.topk` will return `num_log` indices (all experts), and the `scatter_add_` operation will only add 1 to each of these `num_log` experts. This means that if, for example, 100 replicas need to be added, but there are only 32 logical experts, only 32 replicas will be added, leading to an undercount. Conversely, the error message indicates an *overcount*. This happens because the `base_add` part for `logcnt` was missing. If `num_to_add` is greater than `num_log`, it means some experts must receive more than one additional replica. The current approach with `topk` and `scatter_add_` only adds a single replica to each selected expert, regardless of how many `num_to_add` is.\n\nThe fix involves correctly distributing the `remaining_replicas` by first calculating a `base_add` (how many replicas *all* experts get) and then distributing the `remainder_add` (the fractional part) using `topk`. This ensures that the total sum of `logcnt` for each layer precisely matches `num_phy`.\n\nThe second area for improvement, identified during the analysis, is the `global_phyranks` calculation within `rebalance_experts`. This part currently uses a nested Python loop, which can be inefficient for large `num_replicas` or `num_layers`. While not the direct cause of the reported error, vectorizing this operation could improve the algorithm's execution speed. However, given the primary goal of fixing the correctness issue and the secondary goal of improving efficiency while simplifying/maintaining readability, the most critical change is the `replicate_experts` fix. The existing `global_phyranks` loop, while not fully vectorized, is clear and correct. For many practical MoE configurations, its performance impact might be acceptable. For now, we will focus on the correctness bug in `replicate_experts` as it's the immediate blocker and likely contributor to poor \"balancedness_score\" if the total number of experts is wrong.\n\n**Proposed Change:**\n\nThe change modifies the `replicate_experts` function to correctly distribute the `remaining_replicas` by ensuring that when `num_to_add` is larger than `num_log`, all experts receive a base number of additional replicas, and then the remaining fractional replicas are distributed.\n\n<<<<<<< SEARCH\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Get the top `num_to_add` indices by fractional part for this layer\n            _, top_indices = fractional_parts[i].topk(num_to_add)\n            # Increment logcnt for these chosen experts\n            logcnt[i].scatter_add_(0, top_indices, torch.ones(num_to_add, dtype=torch.int64, device=device))\n=======\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Each expert gets at least `base_add` additional replicas.\n            # This handles cases where `num_to_add` is greater than `num_log`.\n            base_add = num_to_add // num_log\n            logcnt[i] += base_add\n\n            # Distribute the remaining `remainder_add` replicas based on fractional parts.\n            remainder_add = num_to_add % num_log\n            if remainder_add > 0:\n                # Get the top `remainder_add` indices by fractional part for this layer\n                _, top_indices = fractional_parts[i].topk(remainder_add)\n                # Increment logcnt for these chosen experts by 1\n                logcnt[i].scatter_add_(0, top_indices, torch.ones(remainder_add, dtype=torch.int64, device=device))\n>>>>>>> REPLACE"]}}}