{"id": "da4f6b4a-ef8c-424b-8fbb-307c260b6d1d", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on its original device (e.g., GPU)\n    # from rebalance_experts, so no explicit device transfer is needed here.\n    _, sorted_indices = weight.sort(-1, descending=True)\n\n    # Initialize pack_index and rank_in_pack.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Generate the assignment pattern for items in sorted order (k = 0 to num_groups-1)\n    k_indices = torch.arange(num_groups, dtype=torch.int64, device=weight.device)\n\n    # Calculate rank_in_pack for the sorted items.\n    # The rank is based on how many items have already been assigned to a pack.\n    # Since each pack receives `groups_per_pack` items, and we are assigning\n    # items in sorted order, the `k`-th sorted item will get rank `k // num_packs`.\n    ranks_for_sorted_items = k_indices // num_packs\n\n    # Calculate pack_id for the sorted items using the \"snake\" pattern.\n    # This ensures that the heaviest items are distributed among packs,\n    # and subsequent items fill them in a way that keeps the sums balanced.\n    idx_in_block = k_indices % num_packs\n    block_num = k_indices // num_packs\n    is_even_block = (block_num % 2 == 0)\n    \n    packs_for_sorted_items = torch.where(\n        is_even_block,\n        idx_in_block,\n        num_packs - 1 - idx_in_block\n    )\n\n    # Expand the assignments to all layers\n    expanded_packs = packs_for_sorted_items.unsqueeze(0).expand(num_layers, -1)\n    expanded_ranks = ranks_for_sorted_items.unsqueeze(0).expand(num_layers, -1)\n\n    # Use scatter_ to populate the output tensors based on original group IDs.\n    # For each layer, `sorted_indices[i, k]` gives the original group ID\n    # for the item at sorted position `k`.\n    # We want to assign `expanded_packs[i, k]` to `pack_index[i, original_group_id]`\n    # And `expanded_ranks[i, k]` to `rank_in_pack[i, original_group_id]`\n    pack_index.scatter_(1, sorted_indices, expanded_packs)\n    rank_in_pack.scatter_(1, sorted_indices, expanded_ranks)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized. Optimized using a greedy approach\n    with vectorized PyTorch operations.\n\n    Parameters:\n        weight: [X, num_log]  (e.g., [num_layers * num_nodes, num_logical_experts_per_node])\n        num_phy: total number of experts after replication (e.g., num_physical_experts_per_node)\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank (0-indexed)\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    num_layers, num_log = weight.shape\n    assert num_phy >= num_log\n    device = weight.device\n\n    # Initialize output tensors\n    phy2log = torch.empty((num_layers, num_phy), dtype=torch.int64, device=device)\n    rank = torch.empty((num_layers, num_phy), dtype=torch.int64, device=device)\n    \n    # current_logcnt: tracks the number of replicas assigned to each logical expert.\n    # Initialized to 0, will be incremented as replicas are assigned.\n    current_logcnt = torch.zeros(num_layers, num_log, dtype=torch.int64, device=device)\n    \n    # current_replica_rank_to_assign: For each logical expert, this stores the next 0-indexed\n    # replica rank that will be assigned if this expert is chosen.\n    current_replica_rank_to_assign = torch.zeros(num_layers, num_log, dtype=torch.int64, device=device)\n\n    # next_avg_load_score: This tensor stores the 'score' for each logical expert.\n    # The score is `weight[i,j] / (current_logcnt[i,j] + 1.0)`.\n    # We want to pick the expert that, if it receives its next replica,\n    # would have the *highest* average load among all experts.\n    # This is equivalent to picking the expert that currently has the highest average load,\n    # and then assigning it a replica to reduce its load.\n    # A small epsilon is added to the denominator to prevent division by zero,\n    # especially if `weight` is 0 and `current_logcnt` is 0.\n    # `weight` is already float from `rebalance_experts` caller.\n    next_avg_load_score = weight / (current_logcnt.float() + 1.0 + 1e-6)\n\n    # Iterate num_phy times to fill all physical expert slots.\n    # In each iteration, one physical expert slot is assigned for each layer.\n    for k_phy_idx in range(num_phy):\n        # For each layer, find the logical expert with the maximum `next_avg_load_score`.\n        # `max_scores` will be [num_layers], `best_log_indices` will be [num_layers].\n        max_scores, best_log_indices = torch.max(next_avg_load_score, dim=-1)\n\n        # Assign the selected logical expert and its rank to the current physical slot (`k_phy_idx`).\n        # `best_log_indices` contains the logical expert ID for each layer.\n        # `current_replica_rank_to_assign` (gathered using `best_log_indices`) provides the\n        # 0-indexed rank for that logical expert's current replica being assigned.\n        phy2log[:, k_phy_idx] = best_log_indices\n        rank[:, k_phy_idx] = current_replica_rank_to_assign.gather(\n            1, best_log_indices.unsqueeze(1)).squeeze(1)\n\n    # Pre-allocate ones tensor for scatter_add_ operations, as its shape is constant.\n    ones_for_scatter = torch.ones(num_layers, dtype=torch.int64, device=device)\n\n    # Iterate num_phy times to fill all physical expert slots.\n    # In each iteration, one physical expert slot is assigned for each layer.\n    for k_phy_idx in range(num_phy):\n        # For each layer, find the logical expert with the maximum `next_avg_load_score`.\n        # `max_scores` will be [num_layers], `best_log_indices` will be [num_layers].\n        max_scores, best_log_indices = torch.max(next_avg_load_score, dim=-1)\n\n        # Assign the selected logical expert and its rank to the current physical slot (`k_phy_idx`).\n        # `best_log_indices` contains the logical expert ID for each layer.\n        # `current_replica_rank_to_assign` (gathered using `best_log_indices`) provides the\n        # 0-indexed rank for that logical expert's current replica being assigned.\n        phy2log[:, k_phy_idx] = best_log_indices\n        rank[:, k_phy_idx] = current_replica_rank_to_assign.gather(\n            1, best_log_indices.unsqueeze(1)).squeeze(1)\n\n        # Update `current_logcnt` for the selected experts (increment by 1).\n        current_logcnt.scatter_add_(1, best_log_indices.unsqueeze(1), ones_for_scatter.unsqueeze(1))\n        \n        # Update `current_replica_rank_to_assign` for the selected experts (increment by 1).\n        # This prepares the rank for the *next* replica assignment for these experts.\n        current_replica_rank_to_assign.scatter_add_(\n            1, best_log_indices.unsqueeze(1), ones_for_scatter.unsqueeze(1))\n        \n        # Calculate the new `next_avg_load_score` for the selected logical experts.\n        # This is `weight[i, selected_expert] / (new_current_logcnt[i, selected_expert] + 1.0)`.\n        # The `current_logcnt` for these experts has just been incremented.\n        \n        # Gather the weights of the selected experts. `weight` is already float.\n        selected_weights = weight.gather(1, best_log_indices.unsqueeze(1)).squeeze(1)\n        # Gather the new (incremented) counts for the selected experts.\n        updated_counts = current_logcnt.gather(1, best_log_indices.unsqueeze(1)).squeeze(1).float()\n        \n        # Calculate the new scores for these selected experts.\n        # This is the average load if they receive one more replica (i.e., (updated_counts + 1)).\n        new_scores = selected_weights / (updated_counts + 1.0 + 1e-6)\n        \n        # Scatter the new scores back into `next_avg_load_score`.\n        next_avg_load_score.scatter_(1, best_log_indices.unsqueeze(1), new_scores.unsqueeze(1))\n        \n    # The `current_logcnt` tensor now holds the final number of replicas for each logical expert.\n    return phy2log, rank, current_logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        # More concise way to get values 0 to perm.size(1)-1 for scattering\n        values = torch.arange(perm.size(1), dtype=torch.int64, device=perm.device)\n        inv.scatter_(\n            1,\n            perm,\n            values.unsqueeze(0).expand_as(perm), # Expand values to match perm's shape\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float() # Keep on original device (likely GPU)\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    # Determine the maximum number of replicas any single logical expert received.\n    # This ensures log2phy is sized precisely to avoid excessive memory allocation.\n    max_log_replicas = logcnt.max().item()\n    # Ensure max_log_replicas is at least 1 to prevent zero-sized dimensions\n    # in case logcnt.max() is 0 (e.g., if no experts were assigned replicas,\n    # though this should not happen given num_phy >= num_log assertion).\n    if max_log_replicas == 0:\n        max_log_replicas = 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, max_log_replicas),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    # The scatter_ operation needs a flat index.\n    # The index is logical_expert_id * max_log_replicas + phyrank.\n    # The maximum index will be (num_logical_experts - 1) * max_log_replicas + (max_log_replicas - 1)\n    # which equals num_logical_experts * max_log_replicas - 1.\n    # So the flattened size of log2phy must be num_logical_experts * max_log_replicas.\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * max_log_replicas + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "dda249bb-0af1-4e20-b627-a5e539a9f957", "generation": 11, "timestamp": 1751067255.2862017, "iteration_found": 272, "metrics": {"balancedness_score": 0.3527582622846887, "speed_score": 0.11228144562207878, "combined_score": 0.23251985395338376}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 3 lines with 3 lines\nChange 2: Replace 10 lines with 25 lines", "parent_metrics": {"balancedness_score": 0.3527582622846887, "speed_score": 0.11246983322149347, "combined_score": 0.23261404775309108}, "island": 3}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.3528\n- speed_score: 0.1125\n- combined_score: 0.2326\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing improvement: speed_score, combined_score. Consider continuing with similar changes.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1104, combined_score: 0.2316\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1125, combined_score: 0.2326\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.2326)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1125), Performs well on combined_score (0.2326)\n\n\n### Program 2 (Score: 0.2316)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1104), Performs well on combined_score (0.2316)\n\n\n### Program 3 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.0000, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0310, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace weight = weight.float().cpu() with 3 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.1494, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 11 lines with 7 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.1920, Type: Migrant)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 5 (Score: 0.0000, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 25 lines with 53 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    _, sorted_indices = weight.sort(-1, descending=True)\n\n    # Initialize pack_index and rank_in_pack.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Generate the assignment pattern for items in sorted order (k = 0 to num_groups-1)\n    k_indices = torch.arange(num_groups, dtype=torch.int64, device=weight.device)\n\n    # Calculate rank_in_pack for the sorted items.\n    # The rank is based on how many items have already been assigned to a pack.\n    # Since each pack receives `groups_per_pack` items, and we are assigning\n    # items in sorted order, the `k`-th sorted item will get rank `k // num_packs`.\n    ranks_for_sorted_items = k_indices // num_packs\n\n    # Calculate pack_id for the sorted items using the \"snake\" pattern.\n    # This ensures that the heaviest items are distributed among packs,\n    # and subsequent items fill them in a way that keeps the sums balanced.\n    idx_in_block = k_indices % num_packs\n    block_num = k_indices // num_packs\n    is_even_block = (block_num % 2 == 0)\n    \n    packs_for_sorted_items = torch.where(\n        is_even_block,\n        idx_in_block,\n        num_packs - 1 - idx_in_block\n    )\n\n    # Expand the assignments to all layers\n    expanded_packs = packs_for_sorted_items.unsqueeze(0).expand(num_layers, -1)\n    expanded_ranks = ranks_for_sorted_items.unsqueeze(0).expand(num_layers, -1)\n\n    # Use scatter_ to populate the output tensors based on original group IDs.\n    # For each layer, `sorted_indices[i, k]` gives the original group ID\n    # for the item at sorted position `k`.\n    # We want to assign `expanded_packs[i, k]` to `pack_index[i, original_group_id]`\n    # And `expanded_ranks[i, k]` to `rank_in_pack[i, original_group_id]`\n    pack_index.scatter_(1, sorted_indices, expanded_packs)\n    rank_in_pack.scatter_(1, sorted_indices, expanded_ranks)\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized. Optimized using a greedy approach\n    with vectorized PyTorch operations.\n\n    Parameters:\n        weight: [X, num_log]  (e.g., [num_layers * num_nodes, num_logical_experts_per_node])\n        num_phy: total number of experts after replication (e.g., num_physical_experts_per_node)\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank (0-indexed)\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    num_layers, num_log = weight.shape\n    assert num_phy >= num_log\n    device = weight.device\n\n    # Initialize output tensors\n    phy2log = torch.empty((num_layers, num_phy), dtype=torch.int64, device=device)\n    rank = torch.empty((num_layers, num_phy), dtype=torch.int64, device=device)\n    \n    # current_logcnt: tracks the number of replicas assigned to each logical expert.\n    # Initialized to 0, will be incremented as replicas are assigned.\n    current_logcnt = torch.zeros(num_layers, num_log, dtype=torch.int64, device=device)\n    \n    # current_replica_rank_to_assign: For each logical expert, this stores the next 0-indexed\n    # replica rank that will be assigned if this expert is chosen.\n    current_replica_rank_to_assign = torch.zeros(num_layers, num_log, dtype=torch.int64, device=device)\n\n    # next_avg_load_score: This tensor stores the 'score' for each logical expert.\n    # The score is `weight[i,j] / (current_logcnt[i,j] + 1.0)`.\n    # We want to pick the expert that, if it receives its next replica,\n    # would have the *highest* average load among all experts.\n    # This is equivalent to picking the expert that currently has the highest average load,\n    # and then assigning it a replica to reduce its load.\n    # A small epsilon is added to the denominator to prevent division by zero,\n    # especially if `weight` is 0 and `current_logcnt` is 0.\n    # `weight` is already float from `rebalance_experts` caller.\n    next_avg_load_score = weight / (current_logcnt.float() + 1.0 + 1e-6)\n\n    # Iterate num_phy times to fill all physical expert slots.\n    # In each iteration, one physical expert slot is assigned for each layer.\n    for k_phy_idx in range(num_phy):\n        # For each layer, find the logical expert with the maximum `next_avg_load_score`.\n        # `max_scores` will be [num_layers], `best_log_indices` will be [num_layers].\n        max_scores, best_log_indices = torch.max(next_avg_load_score, dim=-1)\n\n        # Assign the selected logical expert and its rank to the current physical slot (`k_phy_idx`).\n        # `best_log_indices` contains the logical expert ID for each layer.\n        # `current_replica_rank_to_assign` (gathered using `best_log_indices`) provides the\n        # 0-indexed rank for that logical expert's current replica being assigned.\n        phy2log[:, k_phy_idx] = best_log_indices\n        rank[:, k_phy_idx] = current_replica_rank_to_assign.gather(\n            1, best_log_indices.unsqueeze(1)).squeeze(1)\n\n        # Prepare a 1-hot tensor to increment counts and ranks for the selected experts.\n        ones = torch.ones_like(best_log_indices, dtype=torch.int64, device=device)\n        \n        # Update `current_logcnt` for the selected experts (increment by 1).\n        current_logcnt.scatter_add_(1, best_log_indices.unsqueeze(1), ones.unsqueeze(1))\n        \n        # Update `current_replica_rank_to_assign` for the selected experts (increment by 1).\n        # This prepares the rank for the *next* replica assignment for these experts.\n        current_replica_rank_to_assign.scatter_add_(\n            1, best_log_indices.unsqueeze(1), ones.unsqueeze(1))\n        \n        # Calculate the new `next_avg_load_score` for the selected logical experts.\n        # This is `weight[i, selected_expert] / (new_current_logcnt[i, selected_expert] + 1.0)`.\n        # The `current_logcnt` for these experts has just been incremented.\n        \n        # Gather the weights of the selected experts. `weight` is already float.\n        selected_weights = weight.gather(1, best_log_indices.unsqueeze(1)).squeeze(1)\n        # Gather the new (incremented) counts for the selected experts.\n        updated_counts = current_logcnt.gather(1, best_log_indices.unsqueeze(1)).squeeze(1).float()\n        \n        # Calculate the new scores for these selected experts.\n        # This is the average load if they receive one more replica (i.e., (updated_counts + 1)).\n        new_scores = selected_weights / (updated_counts + 1.0 + 1e-6)\n        \n        # Scatter the new scores back into `next_avg_load_score`.\n        next_avg_load_score.scatter_(1, best_log_indices.unsqueeze(1), new_scores.unsqueeze(1))\n        \n    # The `current_logcnt` tensor now holds the final number of replicas for each logical expert.\n    return phy2log, rank, current_logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        # More concise way to get values 0 to perm.size(1)-1 for scattering\n        values = torch.arange(perm.size(1), dtype=torch.int64, device=perm.device)\n        inv.scatter_(\n            1,\n            perm,\n            values.unsqueeze(0).expand_as(perm), # Expand values to match perm's shape\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float() # Keep on original device (likely GPU)\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    # Determine the maximum number of replicas any single logical expert received.\n    # This ensures log2phy is sized precisely to avoid excessive memory allocation.\n    max_log_replicas = logcnt.max().item()\n    # Ensure max_log_replicas is at least 1 to prevent zero-sized dimensions\n    # in case logcnt.max() is 0 (e.g., if no experts were assigned replicas,\n    # though this should not happen given num_phy >= num_log assertion).\n    if max_log_replicas == 0:\n        max_log_replicas = 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, max_log_replicas),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    # The scatter_ operation needs a flat index.\n    # The index is logical_expert_id * max_log_replicas + phyrank.\n    # The maximum index will be (num_logical_experts - 1) * max_log_replicas + (max_log_replicas - 1)\n    # which equals num_logical_experts * max_log_replicas - 1.\n    # So the flattened size of log2phy must be num_logical_experts * max_log_replicas.\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * max_log_replicas + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current load balancing algorithm employs well-known greedy heuristics for packing and replication, which are generally efficient and effective for NP-hard problems like load balancing. The use of vectorized PyTorch operations already ensures good performance on GPUs.\n\nTo improve performance, particularly `speed_score`, we can focus on micro-optimizations that reduce redundant computations or memory allocations within critical loops.\n\nOne such area is the `replicate_experts` function, specifically the `for k_phy_idx in range(num_phy)` loop. Inside this loop, a `torch.ones_like` tensor is created in each iteration. While `torch.ones_like` is efficient, repeated allocation of a small tensor `num_phy` times can incur minor overheads due to kernel launches and memory management. Pre-allocating this tensor once outside the loop can slightly reduce this overhead.\n\nAdditionally, a comment in the `balanced_packing` function incorrectly states that `weight` is on CPU. Correcting this comment improves code clarity and maintainability without affecting performance.\n\n**Proposed Changes:**\n\n1.  **Micro-optimization in `replicate_experts`:** Move the `torch.ones` tensor creation outside the main loop to avoid redundant allocations. This improves `speed_score` slightly by reducing overhead.\n2.  **Comment Correction in `balanced_packing`:** Update the misleading comment regarding `weight` being on CPU to reflect that it remains on its original device (e.g., GPU). This improves readability and maintainability.\n\nThese changes are targeted and aim to improve `speed_score` and code quality while maintaining the current `balancedness_score`, as the core algorithmic logic remains unchanged.\n\n<<<<<<< SEARCH\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    _, sorted_indices = weight.sort(-1, descending=True)\n=======\n    # 'weight' is already float and on its original device (e.g., GPU)\n    # from rebalance_experts, so no explicit device transfer is needed here.\n    _, sorted_indices = weight.sort(-1, descending=True)\n>>>>>>> REPLACE\n<<<<<<< SEARCH\n        # Prepare a 1-hot tensor to increment counts and ranks for the selected experts.\n        ones = torch.ones_like(best_log_indices, dtype=torch.int64, device=device)\n        \n        # Update `current_logcnt` for the selected experts (increment by 1).\n        current_logcnt.scatter_add_(1, best_log_indices.unsqueeze(1), ones.unsqueeze(1))\n        \n        # Update `current_replica_rank_to_assign` for the selected experts (increment by 1).\n        # This prepares the rank for the *next* replica assignment for these experts.\n        current_replica_rank_to_assign.scatter_add_(\n            1, best_log_indices.unsqueeze(1), ones.unsqueeze(1))\n=======\n    # Pre-allocate ones tensor for scatter_add_ operations, as its shape is constant.\n    ones_for_scatter = torch.ones(num_layers, dtype=torch.int64, device=device)\n\n    # Iterate num_phy times to fill all physical expert slots.\n    # In each iteration, one physical expert slot is assigned for each layer.\n    for k_phy_idx in range(num_phy):\n        # For each layer, find the logical expert with the maximum `next_avg_load_score`.\n        # `max_scores` will be [num_layers], `best_log_indices` will be [num_layers].\n        max_scores, best_log_indices = torch.max(next_avg_load_score, dim=-1)\n\n        # Assign the selected logical expert and its rank to the current physical slot (`k_phy_idx`).\n        # `best_log_indices` contains the logical expert ID for each layer.\n        # `current_replica_rank_to_assign` (gathered using `best_log_indices`) provides the\n        # 0-indexed rank for that logical expert's current replica being assigned.\n        phy2log[:, k_phy_idx] = best_log_indices\n        rank[:, k_phy_idx] = current_replica_rank_to_assign.gather(\n            1, best_log_indices.unsqueeze(1)).squeeze(1)\n\n        # Update `current_logcnt` for the selected experts (increment by 1).\n        current_logcnt.scatter_add_(1, best_log_indices.unsqueeze(1), ones_for_scatter.unsqueeze(1))\n        \n        # Update `current_replica_rank_to_assign` for the selected experts (increment by 1).\n        # This prepares the rank for the *next* replica assignment for these experts.\n        current_replica_rank_to_assign.scatter_add_(\n            1, best_log_indices.unsqueeze(1), ones_for_scatter.unsqueeze(1))\n>>>>>>> REPLACE"]}}}