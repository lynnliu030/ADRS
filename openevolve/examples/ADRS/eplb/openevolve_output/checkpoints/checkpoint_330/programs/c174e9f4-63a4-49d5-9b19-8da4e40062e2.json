{"id": "c174e9f4-63a4-49d5-9b19-8da4e40062e2", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # This approach avoids creating a large temporary tensor with float('inf').\n            # Find the pack with the minimum current weight among available ones.\n            # Mark full packs with infinity to exclude them from argmin.\n            # Clone current_pack_weights to avoid modifying the original tensor in place\n            # with float('inf') values before the actual update.\n            # Find the pack with the minimum current weight among available ones.\n            # Use torch.where to conditionally set weights to infinity for full packs.\n            pack = torch.argmin(\n                torch.where(current_pack_items < groups_per_pack,\n                            current_pack_weights,\n                            torch.full_like(current_pack_weights, float('inf'))))\n\n            # Assert that a valid pack was found and it has space.\n            # Using pack directly as a 0-dim tensor for indexing.\n            assert current_pack_items[pack] < groups_per_pack, \\\n                f\"No available packs found, but expected to find one. Pack {pack} is full.\"\n\n            # Assign the group to the chosen pack.\n            # group_id is a 0-dim tensor, so it works directly for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # weight[i, group_id] is the weight of the current group (0-dim tensor).\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas using a proportional\n    assignment strategy. This is a faster approximation to the greedy LPT.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    # The algorithm is designed for replication, implying num_phy >= num_log.\n    # If num_phy < num_log, a different strategy (e.g., expert selection/mapping)\n    # would be required, as not all logical experts can have a replica.\n    assert num_phy >= num_log, \\\n        f\"num_phy ({num_phy}) must be greater than or equal to num_log ({num_log}). \" \\\n        \"The current replication algorithm does not support num_phy < num_log, \" \\\n        \"as it guarantees at least one replica per logical expert.\"\n    device = weight.device\n\n    # Calculate desired total weight per replica for each layer\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n\n    # Calculate target logcnt (float) for each expert based on its proportion of total weight.\n    # Handle layers with zero total weight by distributing evenly.\n    target_logcnt_float = torch.where(\n        total_weight_per_layer > 0,\n        weight / total_weight_per_layer * num_phy,\n        torch.full_like(weight, num_phy / num_log)  # Distribute evenly if total_weight is 0\n    )\n\n    # Initial integer counts: floor of target_logcnt_float, ensuring at least 1 replica.\n    # Using floor ensures sum(logcnt) <= num_phy initially (due to rounding down).\n    logcnt = torch.max(torch.ones_like(target_logcnt_float, dtype=torch.int64),\n                       target_logcnt_float.floor().long())\n\n    # Calculate remaining replicas to distribute for each layer.\n    # This difference should be non-negative.\n    remaining_replicas = num_phy - logcnt.sum(dim=-1)\n\n    # Distribute remaining replicas greedily based on the fractional parts.\n    # This ensures the total count for each layer sums exactly to num_phy.\n    fractional_parts = target_logcnt_float - logcnt.float()\n\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Get the top `num_to_add` indices by fractional part for this layer\n            _, top_indices = fractional_parts[i].topk(num_to_add)\n            # Increment logcnt for these chosen experts\n            logcnt[i].scatter_add_(0, top_indices, torch.ones(num_to_add, dtype=torch.int64, device=device))\n\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count, vectorized across layers.\n\n    # 1. Generate logical expert IDs for all layers, repeated by their counts.\n    # `expert_ids_base` is [1, num_log]. Expanded to [n, num_log] for repeat_interleave.\n    expert_ids_base = torch.arange(num_log, device=device).unsqueeze(0)\n    phy2log_unshuffled = torch.repeat_interleave(expert_ids_base.expand(n, -1), logcnt, dim=1)\n\n    # 2. Generate ranks for all layers.\n    # For each logical expert in each layer, ranks should be 0 to count-1.\n    # Calculate offsets for each sequence of ranks within each layer.\n    # offsets[i, j] = sum(logcnt[i, 0]...logcnt[i, j-1])\n    offsets = torch.cumsum(logcnt, dim=-1) - logcnt # Shape [n, num_log]\n    repeated_offsets = torch.repeat_interleave(offsets, logcnt, dim=1) # Shape [n, num_phy]\n\n    # Generate a base sequence of ranks (0 to num_phy-1) for each layer.\n    # Then subtract the repeated offsets to get the ranks within each expert's replicas.\n    base_ranks_template = torch.arange(num_phy, dtype=torch.int64, device=device).unsqueeze(0)\n    rank_unshuffled = base_ranks_template.expand(n, -1) - repeated_offsets\n\n    # Assert that the sum of logcnt for each layer exactly equals num_phy.\n    # This should hold true given the `remaining_replicas` distribution logic.\n    assert torch.all(logcnt.sum(dim=-1) == num_phy), \\\n        f\"Internal error: Expert count mismatch. Sum of logcnt per layer does not match num_phy.\"\n\n    # Shuffle physical expert assignments within each layer.\n    # This is crucial for distributing replicas across physical resources,\n    # preventing all replicas of an expert from being assigned consecutively,\n    # which helps in actual load balancing on GPUs.\n    # Generate permutations for all layers at once using argsort of random numbers.\n    perm_indices = torch.rand(n, num_phy, device=device).argsort(dim=1)\n    \n    # Apply permutations using gather.\n    phy2log = torch.gather(phy2log_unshuffled, 1, perm_indices)\n    rank = torch.gather(rank_unshuffled, 1, perm_indices)\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Cast weight to float for calculations if not already, and keep on original device.\n    # Moving to CPU adds overhead if data is already on GPU and might slow down ops.\n    weight = weight.float()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    # Calculate the maximum number of replicas any single logical expert received.\n    # This is crucial for correctly sizing the log2phy tensor to avoid out-of-bounds errors.\n    # If logcnt is empty or contains only zeros (e.g., in edge cases or if num_replicas < num_logical_experts),\n    # ensure maxlogcnt is at least 1 to prevent a dimension of size 0.\n    maxlogcnt = logcnt.max().item() if logcnt.numel() > 0 else 1\n    if maxlogcnt == 0:\n        # This case should ideally not happen if replicate_experts ensures at least 1 replica,\n        # but as a safeguard against potential future changes or unusual inputs.\n        maxlogcnt = 1\n\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "70cdde56-f721-4673-a3be-b2bc1a6e57d1", "generation": 7, "timestamp": 1751059089.4623938, "iteration_found": 143, "metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "repeats must be 0-dim or 1-dim tensor"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\" with 7 lines\nChange 2: Replace 31 lines with 35 lines", "parent_metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "Internal error: Expert count mismatch for layer 0. Expected 72, got 134."}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.0000\n- speed_score: 0.0000\n- combined_score: 0.0000\n- error: Internal error: Expert count mismatch for layer 0. Expected 72, got 134.\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0835, combined_score: 0.1909\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0845, combined_score: 0.1914\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0857, combined_score: 0.1920\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.1920)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0857), Performs well on combined_score (0.1920)\n\n\n### Program 2 (Score: 0.1914)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0845), Performs well on combined_score (0.1914)\n\n\n### Program 3 (Score: 0.1909)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0835), Performs well on combined_score (0.1909)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1907)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1908)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.1920, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 5 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # This approach avoids creating a large temporary tensor with float('inf').\n            # Find the pack with the minimum current weight among available ones.\n            # Mark full packs with infinity to exclude them from argmin.\n            # Clone current_pack_weights to avoid modifying the original tensor in place\n            # with float('inf') values before the actual update.\n            # Find the pack with the minimum current weight among available ones.\n            # Use torch.where to conditionally set weights to infinity for full packs.\n            pack = torch.argmin(\n                torch.where(current_pack_items < groups_per_pack,\n                            current_pack_weights,\n                            torch.full_like(current_pack_weights, float('inf'))))\n\n            # Assert that a valid pack was found and it has space.\n            # Using pack directly as a 0-dim tensor for indexing.\n            assert current_pack_items[pack] < groups_per_pack, \\\n                f\"No available packs found, but expected to find one. Pack {pack} is full.\"\n\n            # Assign the group to the chosen pack.\n            # group_id is a 0-dim tensor, so it works directly for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # weight[i, group_id] is the weight of the current group (0-dim tensor).\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas using a proportional\n    assignment strategy. This is a faster approximation to the greedy LPT.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n    device = weight.device\n\n    # Calculate desired total weight per replica for each layer\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n\n    # Calculate target logcnt (float) for each expert based on its proportion of total weight.\n    # Handle layers with zero total weight by distributing evenly.\n    target_logcnt_float = torch.where(\n        total_weight_per_layer > 0,\n        weight / total_weight_per_layer * num_phy,\n        torch.full_like(weight, num_phy / num_log)  # Distribute evenly if total_weight is 0\n    )\n\n    # Initial integer counts: floor of target_logcnt_float, ensuring at least 1 replica.\n    # Using floor ensures sum(logcnt) <= num_phy initially (due to rounding down).\n    logcnt = torch.max(torch.ones_like(target_logcnt_float, dtype=torch.int64),\n                       target_logcnt_float.floor().long())\n\n    # Calculate remaining replicas to distribute for each layer.\n    # This difference should be non-negative.\n    remaining_replicas = num_phy - logcnt.sum(dim=-1)\n\n    # Distribute remaining replicas greedily based on the fractional parts.\n    # This ensures the total count for each layer sums exactly to num_phy.\n    fractional_parts = target_logcnt_float - logcnt.float()\n\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Get the top `num_to_add` indices by fractional part for this layer\n            _, top_indices = fractional_parts[i].topk(num_to_add)\n            # Increment logcnt for these chosen experts\n            logcnt[i].scatter_add_(0, top_indices, torch.ones(num_to_add, dtype=torch.int64, device=device))\n\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count.\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Vectorized generation of phy2log and rank for each layer\n    for i in range(n):\n        # Generate logical expert IDs for the current layer, repeated by their counts.\n        # Example: if logcnt[i] = [2, 1, 3] for num_log=3, then generates [0, 0, 1, 2, 2, 2]\n        layer_phy2log_temp = torch.repeat_interleave(torch.arange(num_log, device=device), logcnt[i])\n\n        # Generate ranks for the current layer.\n        # Example: if logcnt[i] = [2, 1, 3], then generates [0, 1, 0, 0, 1, 2]\n        # This uses a list comprehension with torch.arange and then concatenates,\n        # which is more efficient than the previous deeply nested Python loop.\n        layer_rank_temp = torch.cat([torch.arange(c, dtype=torch.int64, device=device) for c in logcnt[i]])\n\n        # Ensure the generated tensors have exactly num_phy elements.\n        # This assertion should hold true if the sum of logcnt[i] equals num_phy.\n        assert layer_phy2log_temp.numel() == num_phy, \\\n            f\"Internal error: Expert count mismatch for layer {i}. Expected {num_phy}, got {layer_phy2log_temp.numel()}.\"\n        assert layer_rank_temp.numel() == num_phy, \\\n            f\"Internal error: Rank count mismatch for layer {i}. Expected {num_phy}, got {layer_rank_temp.numel()}.\"\n\n        # Shuffle physical expert assignments within each layer.\n        # This is crucial for distributing replicas across physical resources,\n        # preventing all replicas of an expert from being assigned consecutively,\n        # which helps in actual load balancing on GPUs.\n        perm = torch.randperm(num_phy, device=device)\n        phy2log[i] = layer_phy2log_temp[perm]\n        rank[i] = layer_rank_temp[perm]\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Cast weight to float for calculations if not already, and keep on original device.\n    # Moving to CPU adds overhead if data is already on GPU and might slow down ops.\n    weight = weight.float()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    # Calculate the maximum number of replicas any single logical expert received.\n    # This is crucial for correctly sizing the log2phy tensor to avoid out-of-bounds errors.\n    # If logcnt is empty or contains only zeros (e.g., in edge cases or if num_replicas < num_logical_experts),\n    # ensure maxlogcnt is at least 1 to prevent a dimension of size 0.\n    maxlogcnt = logcnt.max().item() if logcnt.numel() > 0 else 1\n    if maxlogcnt == 0:\n        # This case should ideally not happen if replicate_experts ensures at least 1 replica,\n        # but as a safeguard against potential future changes or unusual inputs.\n        maxlogcnt = 1\n\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program has a critical error: \"Expert count mismatch for layer 0. Expected 72, got 134.\" This error occurs in the `replicate_experts` function when it tries to populate `phy2log` and `rank` tensors.\n\n**Analysis of the Error and Current Algorithm:**\nThe `replicate_experts` function is designed to \"replicate\" logical experts into a larger number of physical experts (`num_phy`). Its core logic, particularly `logcnt = torch.max(torch.ones_like(...), target_logcnt_float.floor().long())`, ensures that every logical expert receives at least one physical replica. This design implicitly assumes that the total number of physical experts (`num_phy`) is greater than or equal to the number of logical experts (`num_log`).\n\nThe error message `Expected 72, got 134` indicates that for a specific layer (or sub-problem within `rebalance_experts_hierarchical`), `num_phy` was 72, but the sum of `logcnt` (the number of replicas assigned) for that layer was 134. This happens when `num_phy < num_log` (e.g., 72 physical slots for 134 logical experts). In such a scenario, forcing each of the 134 logical experts to have at least one replica would result in at least 134 physical experts, which exceeds the available 72 `num_phy` slots. The current algorithm is not designed for this \"fewer physical experts than logical experts\" scenario; it's a replication algorithm, not a selection or mapping algorithm.\n\n**Proposed Improvements:**\n\n1.  **Address the \"Expert count mismatch\" error by enforcing preconditions:**\n    The most direct fix is to add an explicit assertion in `replicate_experts` to ensure `num_phy >= num_log`. This clarifies the intended use case of the function and prevents it from entering an invalid state. If `num_phy < num_log` is a valid input scenario, the `replicate_experts` function would require a fundamental redesign (e.g., to select the most important `num_phy` experts or map multiple logical experts to a single physical expert), which is beyond the scope of \"replication.\"\n\n2.  **Improve efficiency by vectorizing tensor operations in `replicate_experts`:**\n    The current `replicate_experts` function uses a Python `for` loop to populate `phy2log` and `rank` tensors layer by layer. While the operations within the loop are PyTorch operations, the loop itself can introduce overhead, especially for models with many MoE layers (`n`). This can be vectorized using `torch.repeat_interleave` and `torch.gather` to perform these operations for all layers simultaneously, significantly reducing Python overhead and potentially improving speed.\n\n3.  **Minor Code Readability/Robustness:**\n    *   Add a more descriptive assertion message for the `num_phy >= num_log` check.\n    *   Ensure the vectorized `phy2log` and `rank` generation correctly handles all edge cases and maintains numerical stability.\n\nThese changes will improve the algorithm's robustness by explicitly stating its constraints and improve its efficiency by reducing Python loop overhead for tensor construction.\n\n---\nHere are the changes in the specified diff format:\n\n<<<<<<< SEARCH\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n=======\n    # The algorithm is designed for replication, implying num_phy >= num_log.\n    # If num_phy < num_log, a different strategy (e.g., expert selection/mapping)\n    # would be required, as not all logical experts can have a replica.\n    assert num_phy >= num_log, \\\n        f\"num_phy ({num_phy}) must be greater than or equal to num_log ({num_log}). \" \\\n        \"The current replication algorithm does not support num_phy < num_log, \" \\\n        \"as it guarantees at least one replica per logical expert.\"\n>>>>>>> REPLACE\n\n<<<<<<< SEARCH\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count.\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Vectorized generation of phy2log and rank for each layer\n    for i in range(n):\n        # Generate logical expert IDs for the current layer, repeated by their counts.\n        # Example: if logcnt[i] = [2, 1, 3] for num_log=3, then generates [0, 0, 1, 2, 2, 2]\n        layer_phy2log_temp = torch.repeat_interleave(torch.arange(num_log, device=device), logcnt[i])\n\n        # Generate ranks for the current layer.\n        # Example: if logcnt[i] = [2, 1, 3], then generates [0, 1, 0, 0, 1, 2]\n        # This uses a list comprehension with torch.arange and then concatenates,\n        # which is more efficient than the previous deeply nested Python loop.\n        layer_rank_temp = torch.cat([torch.arange(c, dtype=torch.int64, device=device) for c in logcnt[i]])\n\n        # Ensure the generated tensors have exactly num_phy elements.\n        # This assertion should hold true if the sum of logcnt[i] equals num_phy.\n        assert layer_phy2log_temp.numel() == num_phy, \\\n            f\"Internal error: Expert count mismatch for layer {i}. Expected {num_phy}, got {layer_phy2log_temp.numel()}.\"\n        assert layer_rank_temp.numel() == num_phy, \\\n            f\"Internal error: Rank count mismatch for layer {i}. Expected {num_phy}, got {layer_rank_temp.numel()}.\"\n\n        # Shuffle physical expert assignments within each layer.\n        # This is crucial for distributing replicas across physical resources,\n        # preventing all replicas of an expert from being assigned consecutively,\n        # which helps in actual load balancing on GPUs.\n        perm = torch.randperm(num_phy, device=device)\n        phy2log[i] = layer_phy2log_temp[perm]\n        rank[i] = layer_rank_temp[perm]\n=======\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count, vectorized across layers.\n\n    # 1. Generate logical expert IDs for all layers, repeated by their counts.\n    # `expert_ids_base` is [1, num_log]. Expanded to [n, num_log] for repeat_interleave.\n    expert_ids_base = torch.arange(num_log, device=device).unsqueeze(0)\n    phy2log_unshuffled = torch.repeat_interleave(expert_ids_base.expand(n, -1), logcnt, dim=1)\n\n    # 2. Generate ranks for all layers.\n    # For each logical expert in each layer, ranks should be 0 to count-1.\n    # Calculate offsets for each sequence of ranks within each layer.\n    # offsets[i, j] = sum(logcnt[i, 0]...logcnt[i, j-1])\n    offsets = torch.cumsum(logcnt, dim=-1) - logcnt # Shape [n, num_log]\n    repeated_offsets = torch.repeat_interleave(offsets, logcnt, dim=1) # Shape [n, num_phy]\n\n    # Generate a base sequence of ranks (0 to num_phy-1) for each layer.\n    # Then subtract the repeated offsets to get the ranks within each expert's replicas.\n    base_ranks_template = torch.arange(num_phy, dtype=torch.int64, device=device).unsqueeze(0)\n    rank_unshuffled = base_ranks_template.expand(n, -1) - repeated_offsets\n\n    # Assert that the sum of logcnt for each layer exactly equals num_phy.\n    # This should hold true given the `remaining_replicas` distribution logic.\n    assert torch.all(logcnt.sum(dim=-1) == num_phy), \\\n        f\"Internal error: Expert count mismatch. Sum of logcnt per layer does not match num_phy.\"\n\n    # Shuffle physical expert assignments within each layer.\n    # This is crucial for distributing replicas across physical resources,\n    # preventing all replicas of an expert from being assigned consecutively,\n    # which helps in actual load balancing on GPUs.\n    # Generate permutations for all layers at once using argsort of random numbers.\n    perm_indices = torch.rand(n, num_phy, device=device).argsort(dim=1)\n    \n    # Apply permutations using gather.\n    phy2log = torch.gather(phy2log_unshuffled, 1, perm_indices)\n    rank = torch.gather(rank_unshuffled, 1, perm_indices)\n>>>>>>> REPLACE"]}}}