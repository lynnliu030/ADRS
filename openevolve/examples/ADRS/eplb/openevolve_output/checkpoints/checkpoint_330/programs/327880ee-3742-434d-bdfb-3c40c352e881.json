{"id": "327880ee-3742-434d-bdfb-3c40c352e881", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices  # Keep on original device\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=weight.device)  # Use weight's device\n    rank_in_pack = torch.full_like(pack_index,\n                                   fill_value=-1,\n                                   device=weight.device)  # Use weight's device\n\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These are on the same device as the input 'weight'.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-calculate a tensor for broadcasting layer indices\n    layer_indices = torch.arange(num_layers, device=weight.device)\n    \n    # Create an infinity tensor once, with the correct device and dtype\n    inf_tensor = weight.new_full((), float('inf'))\n\n    # Iterate over each \"slot\" in the sorted list of groups (from heaviest to lightest)\n    # This processes the k-th heaviest group for ALL layers simultaneously, leveraging PyTorch's vectorization.\n    for k in range(num_groups):\n        # Get the group_ids that are k-th heaviest for each layer\n        current_group_ids = indices[:, k]  # [num_layers]\n\n        # Get the weights of these groups\n        # Use advanced indexing to get weights: weight[layer_idx, group_id_for_that_layer]\n        current_weights = weight[layer_indices, current_group_ids]  # [num_layers]\n\n        # Find available packs for each layer (those not yet full).\n        # available_mask: [num_layers, num_packs]\n        available_mask = (pack_items_per_layer < groups_per_pack)\n\n        # Set unavailable packs to infinity for argmin\n        # candidate_weights: [num_layers, num_packs]\n        candidate_weights = torch.where(available_mask, pack_weights_per_layer, inf_tensor)\n\n        # Find the pack with the minimum current weight for each layer\n        # pack_indices_to_assign: [num_layers]\n        pack_indices_to_assign = torch.argmin(candidate_weights, dim=-1)\n\n        # Assign the current group to the chosen pack for each layer\n        # Using advanced indexing to update pack_index and rank_in_pack\n        pack_index[layer_indices, current_group_ids] = pack_indices_to_assign\n        rank_in_pack[layer_indices, current_group_ids] = \\\n            pack_items_per_layer[layer_indices, pack_indices_to_assign]\n\n        # Update pack weights and item counts for the chosen packs\n        # These updates are also vectorized across layers\n        pack_weights_per_layer[layer_indices, pack_indices_to_assign] += current_weights\n        pack_items_per_layer[layer_indices, pack_indices_to_assign] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log\n    device = weight.device\n\n    # Initialize logcnt based on proportional allocation\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n    \n    # Calculate ideal fractional logcnt, adding epsilon to avoid division by zero\n    # and handling cases where total_weight_per_layer is zero (all experts have zero weight).\n    # In such cases, the max(..., 1) ensures at least one replica per expert.\n    logcnt_float = weight * num_phy / (total_weight_per_layer + 1e-6)\n    \n    # Ensure each logical expert gets at least one physical expert initially.\n    # This acts as a base distribution.\n    logcnt = torch.max(torch.ones_like(weight, dtype=torch.int64), \n                       logcnt_float.floor().to(torch.int64))\n\n    # Distribute remaining replicas using a greedy approach\n    # The number of remaining replicas to distribute for each layer\n    remaining_replicas = num_phy - logcnt.sum(dim=-1) # [n]\n    \n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Distribute remaining replicas using the D'Hondt method (largest remainders).\n    # This is more efficient and provides a better balanced distribution than iterative greedy.\n    # Calculate the \"remainder\" or \"fractional part\" for each expert based on its proportional share.\n    remainders = logcnt_float - logcnt.float() # [n, num_log]\n    \n    # Iterate over each layer to distribute its remaining replicas.\n    # 'n' (num_layers) is typically small, making this loop efficient.\n    for l_idx in range(n):\n        num_to_add = remaining_replicas[l_idx].item()\n        if num_to_add > 0:\n            # Find the 'num_to_add' experts with the largest remainders for this layer.\n            # torch.topk is efficient for this operation.\n            _, top_indices = torch.topk(remainders[l_idx, :], num_to_add, largest=True)\n            # Assign one replica to each of these selected experts.\n            logcnt[l_idx, top_indices] += 1\n\n    # Now, construct phy2log and rank based on the final logcnt.\n    # This needs to be done efficiently, ideally avoiding Python loops over num_phy.\n    # Iterating over 'n' (num_layers) is usually acceptable as 'n' is typically small.\n\n    # Pre-allocate output tensors\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Vectorized construction for each layer\n    for l_idx in range(n):\n        # Create a sequence of logical expert IDs, repeated according to their logcnt\n        # Example: logcnt[l_idx] = [4, 1, 1] -> layer_phy2log = [0,0,0,0,1,2]\n        layer_phy2log = torch.repeat_interleave(torch.arange(num_log, device=device), logcnt[l_idx, :])\n        \n        # Create a sequence of ranks for each expert's replicas\n        # Example: logcnt[l_idx] = [4, 1, 1] -> layer_rank_parts = [[0,1,2,3], [0], [0]]\n        # -> layer_rank = [0,1,2,3,0,0]\n        layer_rank_parts = [torch.arange(count.item(), device=device) for count in logcnt[l_idx, :]]\n        layer_rank = torch.cat(layer_rank_parts)\n        \n        phy2log[l_idx, :] = layer_phy2log\n        rank[l_idx, :] = layer_rank\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float()  # Ensure float, but keep on original device (e.g., GPU)\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    # Ensure log2phy is created on the same device as other tensors\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=weight.device,  # Use weight's device\n    )\n    # The scatter_ operation and arange should also use the correct device\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        # The original expand might cause issues with specific tensor shapes/PyTorch versions.\n        # Using unsqueeze and repeat is functionally equivalent for this case and potentially more robust.\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=weight.device).unsqueeze(0).repeat(num_layers, 1),  # Use weight's device\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "83ed6199-119b-4fcc-8fe6-883253bc1edd", "generation": 7, "timestamp": 1751063528.4873526, "iteration_found": 217, "metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0.  Target sizes: [72].  Tensor sizes: [134]"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 2 lines with 4 lines\nChange 2: Replace 23 lines with 15 lines", "parent_metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0.  Target sizes: [72].  Tensor sizes: [134]"}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.0000\n- speed_score: 0.0000\n- combined_score: 0.0000\n- error: The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0.  Target sizes: [72].  Tensor sizes: [134]\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n### Program 2 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n### Program 3 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.2315, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 32 lines with 32 lines, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 5 (Score: 0.1626, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 4 lines with 6 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices  # Keep on original device\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=weight.device)  # Use weight's device\n    rank_in_pack = torch.full_like(pack_index,\n                                   fill_value=-1,\n                                   device=weight.device)  # Use weight's device\n\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These are on the same device as the input 'weight'.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-calculate a tensor for broadcasting layer indices\n    layer_indices = torch.arange(num_layers, device=weight.device)\n    \n    # Create an infinity tensor once, with the correct device and dtype\n    inf_tensor = weight.new_full((), float('inf'))\n\n    # Iterate over each \"slot\" in the sorted list of groups (from heaviest to lightest)\n    # This processes the k-th heaviest group for ALL layers simultaneously, leveraging PyTorch's vectorization.\n    for k in range(num_groups):\n        # Get the group_ids that are k-th heaviest for each layer\n        current_group_ids = indices[:, k]  # [num_layers]\n\n        # Get the weights of these groups\n        # Use advanced indexing to get weights: weight[layer_idx, group_id_for_that_layer]\n        current_weights = weight[layer_indices, current_group_ids]  # [num_layers]\n\n        # Find available packs for each layer (those not yet full).\n        # available_mask: [num_layers, num_packs]\n        available_mask = (pack_items_per_layer < groups_per_pack)\n\n        # Set unavailable packs to infinity for argmin\n        # candidate_weights: [num_layers, num_packs]\n        candidate_weights = torch.where(available_mask, pack_weights_per_layer, inf_tensor)\n\n        # Find the pack with the minimum current weight for each layer\n        # pack_indices_to_assign: [num_layers]\n        pack_indices_to_assign = torch.argmin(candidate_weights, dim=-1)\n\n        # Assign the current group to the chosen pack for each layer\n        # Using advanced indexing to update pack_index and rank_in_pack\n        pack_index[layer_indices, current_group_ids] = pack_indices_to_assign\n        rank_in_pack[layer_indices, current_group_ids] = \\\n            pack_items_per_layer[layer_indices, pack_indices_to_assign]\n\n        # Update pack weights and item counts for the chosen packs\n        # These updates are also vectorized across layers\n        pack_weights_per_layer[layer_indices, pack_indices_to_assign] += current_weights\n        pack_items_per_layer[layer_indices, pack_indices_to_assign] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log\n    device = weight.device\n\n    # Initialize logcnt based on proportional allocation\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n    \n    # Calculate ideal fractional logcnt, adding epsilon to avoid division by zero\n    # and handling cases where total_weight_per_layer is zero (all experts have zero weight).\n    # In such cases, the max(..., 1) ensures at least one replica per expert.\n    logcnt_float = weight * num_phy / (total_weight_per_layer + 1e-6)\n    \n    # Ensure each logical expert gets at least one physical expert initially.\n    # This acts as a base distribution.\n    logcnt = torch.max(torch.ones_like(weight, dtype=torch.int64), \n                       logcnt_float.floor().to(torch.int64))\n\n    # Distribute remaining replicas using a greedy approach\n    # The number of remaining replicas to distribute for each layer\n    remaining_replicas = num_phy - logcnt.sum(dim=-1) # [n]\n    \n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Iteratively assign remaining replicas to the logical expert with the highest average load.\n    # This loop runs max(remaining_replicas) times, which is generally much smaller\n    # than num_redundant in the original implementation if num_phy is significantly larger than num_log.\n    for _ in range(remaining_replicas.max().item()):\n        # Only consider layers that still have remaining replicas to distribute\n        active_layers_mask = (remaining_replicas > 0) # [n]\n        \n        # Calculate current average load for active layers.\n        # For inactive layers, set to -inf so they are not chosen by argmax.\n        current_avg_load = torch.where(\n            active_layers_mask.unsqueeze(-1), # [n, 1] for broadcasting\n            weight / logcnt.float(),\n            torch.full_like(weight, -torch.inf)\n        )\n\n        # Find the logical expert with the highest average load for each active layer\n        # experts_to_add_replica_to: [n]\n        experts_to_add_replica_to = current_avg_load.argmax(dim=-1)\n\n        # Update logcnt for these experts in active layers\n        # Use advanced indexing to update selected elements across layers\n        logcnt[arangen[active_layers_mask], experts_to_add_replica_to[active_layers_mask]] += 1\n        remaining_replicas[active_layers_mask] -= 1\n\n    # Now, construct phy2log and rank based on the final logcnt.\n    # This needs to be done efficiently, ideally avoiding Python loops over num_phy.\n    # Iterating over 'n' (num_layers) is usually acceptable as 'n' is typically small.\n\n    # Pre-allocate output tensors\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Vectorized construction for each layer\n    for l_idx in range(n):\n        # Create a sequence of logical expert IDs, repeated according to their logcnt\n        # Example: logcnt[l_idx] = [4, 1, 1] -> layer_phy2log = [0,0,0,0,1,2]\n        layer_phy2log = torch.repeat_interleave(torch.arange(num_log, device=device), logcnt[l_idx, :])\n        \n        # Create a sequence of ranks for each expert's replicas\n        # Example: logcnt[l_idx] = [4, 1, 1] -> layer_rank_parts = [[0,1,2,3], [0], [0]]\n        # -> layer_rank = [0,1,2,3,0,0]\n        layer_rank_parts = [torch.arange(count.item(), device=device) for count in logcnt[l_idx, :]]\n        layer_rank = torch.cat(layer_rank_parts)\n        \n        phy2log[l_idx, :] = layer_phy2log\n        rank[l_idx, :] = layer_rank\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float()  # Ensure float, but keep on original device (e.g., GPU)\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    # Ensure log2phy is created on the same device as other tensors\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=weight.device,  # Use weight's device\n    )\n    # The scatter_ operation and arange should also use the correct device\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=weight.device).expand(num_layers, -1),  # Use weight's device\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program exhibits a `balancedness_score` and `speed_score` of 0.0000, along with a `torch.cuda.OutOfMemoryError` or a shape mismatch error, specifically \"The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0. Target sizes: [72]. Tensor sizes: [134]\". This error points to a problem in how tensors are being created or expanded, likely within the `rebalance_experts` function's final `scatter_` operation.\n\nMy analysis indicates that the error message \"The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0\" implies that a tensor with `size(0)` of 72 is being asked to expand its first dimension to 134, but its `size(0)` is neither 1 nor 134. This behavior is unexpected for a 1D `torch.arange` tensor when expanded. While `torch.arange(N).expand(M, -1)` should normally work fine for `M > N`, this error suggests a specific runtime environment or PyTorch version might be sensitive to it. Replacing `expand` with `unsqueeze().repeat()` is functionally equivalent for this specific use case and might circumvent the underlying issue if it's related to `expand`'s internal handling of 1D tensors. This is a targeted fix for the reported error.\n\nBeyond fixing the error, the `replicate_experts` function's current method of distributing remaining replicas (`for _ in range(remaining_replicas.max().item()):`) is an iterative greedy approach. While it works, it can be inefficient if `remaining_replicas.max()` is large, leading to many loop iterations. A more robust and generally faster approach for distributing integer quotas based on fractional parts is the D'Hondt method (or largest remainders method). This involves calculating the fractional part of each expert's ideal replica count and then assigning the remaining replicas to experts with the largest fractional parts. This can be done efficiently using `torch.topk` per layer. This change is expected to significantly improve the `speed_score` and potentially the `balancedness_score` by providing a more globally optimized distribution of replicas.\n\nI propose two changes:\n\n1.  **Address the `expand` error in `rebalance_experts`**: Replace `expand` with `unsqueeze().repeat()` for the `src` tensor in the `scatter_` operation. This is a defensive change to resolve the reported runtime error without altering the core logic.\n2.  **Improve `replicate_experts` efficiency and balancedness**: Replace the iterative greedy loop for distributing remaining replicas with a `topk`-based approach (D'Hondt method). This will reduce the algorithm's execution time and should lead to a more balanced distribution of experts.\n\nThese changes aim to improve both the `speed_score` and `balancedness_score` while fixing the critical runtime error.\n\n```diff\n<<<<<<< SEARCH\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=weight.device).expand(num_layers, -1),  # Use weight's device\n=======\n        # The original expand might cause issues with specific tensor shapes/PyTorch versions.\n        # Using unsqueeze and repeat is functionally equivalent for this case and potentially more robust.\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=weight.device).unsqueeze(0).repeat(num_layers, 1),  # Use weight's device\n>>>>>>> REPLACE\n<<<<<<< SEARCH\n    # Iteratively assign remaining replicas to the logical expert with the highest average load.\n    # This loop runs max(remaining_replicas) times, which is generally much smaller\n    # than num_redundant in the original implementation if num_phy is significantly larger than num_log.\n    for _ in range(remaining_replicas.max().item()):\n        # Only consider layers that still have remaining replicas to distribute\n        active_layers_mask = (remaining_replicas > 0) # [n]\n        \n        # Calculate current average load for active layers.\n        # For inactive layers, set to -inf so they are not chosen by argmax.\n        current_avg_load = torch.where(\n            active_layers_mask.unsqueeze(-1), # [n, 1] for broadcasting\n            weight / logcnt.float(),\n            torch.full_like(weight, -torch.inf)\n        )\n\n        # Find the logical expert with the highest average load for each active layer\n        # experts_to_add_replica_to: [n]\n        experts_to_add_replica_to = current_avg_load.argmax(dim=-1)\n\n        # Update logcnt for these experts in active layers\n        # Use advanced indexing to update selected elements across layers\n        logcnt[arangen[active_layers_mask], experts_to_add_replica_to[active_layers_mask]] += 1\n        remaining_replicas[active_layers_mask] -= 1\n=======\n    # Distribute remaining replicas using the D'Hondt method (largest remainders).\n    # This is more efficient and provides a better balanced distribution than iterative greedy.\n    # Calculate the \"remainder\" or \"fractional part\" for each expert based on its proportional share.\n    remainders = logcnt_float - logcnt.float() # [n, num_log]\n    \n    # Iterate over each layer to distribute its remaining replicas.\n    # 'n' (num_layers) is typically small, making this loop efficient.\n    for l_idx in range(n):\n        num_to_add = remaining_replicas[l_idx].item()\n        if num_to_add > 0:\n            # Find the 'num_to_add' experts with the largest remainders for this layer.\n            # torch.topk is efficient for this operation.\n            _, top_indices = torch.topk(remainders[l_idx, :], num_to_add, largest=True)\n            # Assign one replica to each of these selected experts.\n            logcnt[l_idx, top_indices] += 1\n>>>>>>> REPLACE\n```"]}}}