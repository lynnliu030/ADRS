{"id": "8d8e5733-e006-47fb-8cc6-81563dbfa9a7", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    groups_per_pack = num_groups // num_packs\n\n    # Initialize pack_index and rank_in_pack.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n\n    # Handle the simple case where each group is its own pack (no packing needed)\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=weight.device).expand(num_layers, num_groups)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order for each layer.\n    # 'weight' is already float and on CPU from rebalance_experts.\n    sorted_weights, sorted_indices = weight.sort(-1, descending=True)\n\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    pack_weights_per_layer = torch.zeros(num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Define an infinity tensor once to avoid repeated creation inside the loops.\n    inf_tensor = torch.full((), float('inf'), dtype=weight.dtype, device=weight.device)\n\n    # Iterate over each layer.\n    for i in range(num_layers):\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # Iterate through the sorted groups for the current layer.\n        for k in range(num_groups):\n            # Get the original group ID for the k-th heaviest group in this layer.\n            original_group_id = sorted_indices[i, k]\n\n            # Find the pack with the minimum current weight among available ones.\n            # Exclude packs that are already full.\n            # `argmin` returns a scalar tensor.\n            pack_idx_tensor = torch.argmin(\n                torch.where(current_pack_items == groups_per_pack,\n                            inf_tensor,\n                            current_pack_weights))\n\n            # Assign the group to the chosen pack.\n            pack_index[i, original_group_id] = pack_idx_tensor\n            rank_in_pack[i, original_group_id] = current_pack_items[pack_idx_tensor]\n\n            # Update pack weights and item counts for the chosen pack.\n            pack_weights_per_layer[i, pack_idx_tensor] += sorted_weights[i, k]\n            pack_items_per_layer[i, pack_idx_tensor] += 1\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    # Ensure that replication is actually possible (i.e., num_phy >= num_log)\n    assert num_redundant >= 0, f\"num_phy ({num_phy}) must be >= num_log ({num_log}) for replication.\"\n    \n    device = weight.device\n    \n    # Initialize phy2log: maps physical expert index to logical expert index.\n    # Initially, physical expert j maps to logical expert j.\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    \n    # Initialize rank: tracks the replica rank within each logical expert group.\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    \n    # logcnt: tracks the number of physical replicas for each logical expert.\n    # Initially, each logical expert has 1 physical replica.\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Calculate initial average loads for each logical expert.\n    # Ensure division is done with float types.\n    current_avg_loads = weight / logcnt.to(weight.dtype)\n    \n    # Iterate to add redundant experts one by one.\n    # In each step, we find the logical expert that currently has the highest\n    # average load and assign a new replica to it.\n    for i in range(num_log, num_phy):\n        # Find the logical expert (for each layer) with the highest average load.\n        # This is the expert that needs a new replica to balance the load.\n        redundant_indices = current_avg_loads.max(dim=-1).indices\n        \n        # Assign this logical expert to the current physical expert slot (i).\n        phy2log[:, i] = redundant_indices\n        \n        # Record the replica rank for this newly assigned physical expert.\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Increment the count of physical experts for the chosen logical expert.\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update the average load ONLY for the logical experts that just received a new replica.\n        # This avoids recomputing the entire current_avg_loads tensor, significantly\n        # improving performance when num_redundant is large.\n        current_avg_loads[arangen, redundant_indices] = \\\n            weight[arangen, redundant_indices] / logcnt[arangen, redundant_indices].to(weight.dtype)\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Ensure weight is float and on CPU, avoiding redundant conversions\n    if weight.dtype != torch.float or weight.device.type != 'cpu':\n        weight = weight.float().cpu()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "b7b1ba6c-a41b-48f7-8521-c9d03187d948", "generation": 8, "timestamp": 1751062074.5804758, "iteration_found": 192, "metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.030407761221893658, "combined_score": 0.1643580563766417}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 76 lines with 65 lines", "parent_metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.028495180811688205, "combined_score": 0.16340176617153898}, "island": 4}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.2983\n- speed_score: 0.0285\n- combined_score: 0.1634\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0857, combined_score: 0.1920\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1097, combined_score: 0.2312\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n### Program 2 (Score: 0.2312)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1097), Performs well on combined_score (0.2312)\n\n\n### Program 3 (Score: 0.1920)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0857), Performs well on combined_score (0.1920)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1909)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1914)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.2315, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 32 lines with 32 lines, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.1920, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 4 (Score: 0.1648, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 3 lines with 3 lines\nChange 2: Replace 2 lines with 2 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 5 (Score: 0.0847, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 5 lines with 38 lines\nChange 2: Replace 51 lines with 89 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Define an infinity tensor once to avoid repeated creation inside the loops.\n    inf_tensor = torch.full((), float('inf'), dtype=weight.dtype, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # Get current state for this layer's packs as views.\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id_tensor in indices[i]:\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of full packs to infinity to exclude them from argmin.\n            # The result 'pack_idx_tensor' will be a 0-dim tensor (scalar tensor).\n            pack_idx_tensor = torch.argmin(\n                torch.where(current_pack_items == groups_per_pack,\n                            inf_tensor, # Use pre-defined infinity tensor\n                            current_pack_weights))\n\n            # Assert that a valid pack was found and it has space.\n            # Use tensor indexing directly, avoiding .item() call.\n            assert current_pack_items[pack_idx_tensor] < groups_per_pack\n\n            # Assign the group to the chosen pack using tensor indexing.\n            # group_id_tensor is a 0-dim tensor, pack_idx_tensor is a 0-dim tensor.\n            pack_index[i, group_id_tensor] = pack_idx_tensor\n            rank_in_pack[i, group_id_tensor] = current_pack_items[pack_idx_tensor]\n\n            # Update pack weights and item counts for the chosen pack using tensor indexing.\n            pack_weights_per_layer[i, pack_idx_tensor] += weight[i, group_id_tensor]\n            pack_items_per_layer[i, pack_idx_tensor] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    # Ensure that replication is actually possible (i.e., num_phy >= num_log)\n    assert num_redundant >= 0, f\"num_phy ({num_phy}) must be >= num_log ({num_log}) for replication.\"\n    \n    device = weight.device\n    \n    # Initialize phy2log: maps physical expert index to logical expert index.\n    # Initially, physical expert j maps to logical expert j.\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    \n    # Initialize rank: tracks the replica rank within each logical expert group.\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    \n    # logcnt: tracks the number of physical replicas for each logical expert.\n    # Initially, each logical expert has 1 physical replica.\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    \n    # Calculate initial average loads for each logical expert.\n    # Ensure division is done with float types.\n    current_avg_loads = weight / logcnt.to(weight.dtype)\n    \n    # Iterate to add redundant experts one by one.\n    # In each step, we find the logical expert that currently has the highest\n    # average load and assign a new replica to it.\n    for i in range(num_log, num_phy):\n        # Find the logical expert (for each layer) with the highest average load.\n        # This is the expert that needs a new replica to balance the load.\n        redundant_indices = current_avg_loads.max(dim=-1).indices\n        \n        # Assign this logical expert to the current physical expert slot (i).\n        phy2log[:, i] = redundant_indices\n        \n        # Record the replica rank for this newly assigned physical expert.\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        \n        # Increment the count of physical experts for the chosen logical expert.\n        logcnt[arangen, redundant_indices] += 1\n        \n        # Update the average load ONLY for the logical experts that just received a new replica.\n        # This avoids recomputing the entire current_avg_loads tensor, significantly\n        # improving performance when num_redundant is large.\n        current_avg_loads[arangen, redundant_indices] = \\\n            weight[arangen, redundant_indices] / logcnt[arangen, redundant_indices].to(weight.dtype)\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Ensure weight is float and on CPU, avoiding redundant conversions\n    if weight.dtype != torch.float or weight.device.type != 'cpu':\n        weight = weight.float().cpu()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current `rebalance_experts` function, particularly its hierarchical implementation, seems to be a good starting point. However, the provided performance metrics (balancedness_score: 0.2983, speed_score: 0.0285, combined_score: 0.1634) indicate that there's room for improvement, especially in balancedness and overall combined score. The historical data suggests that previous attempts (Attempts 2 and 3, Program 1) achieved higher scores, implying that recent changes might have regressed performance.\n\nHere are a few suggestions to improve both balancedness and efficiency:\n\n### 1. Optimized `balanced_packing` for Efficiency\n\nThe `balanced_packing` function iterates through each layer and then through each group within that layer. While the current implementation uses tensor operations effectively, the nested loop structure for assigning groups can potentially be optimized. Specifically, instead of iterating through `indices[i]` (which represents sorted group IDs for a layer), we can directly process the sorted weights and assign them to packs. This might reduce overhead.\n\nAdditionally, the current implementation of `balanced_packing` is designed for the hierarchical approach where `num_groups` can be greater than 1. When `num_groups` is 1 (global load balance policy), it effectively becomes a simpler bin-packing problem. We can add a specific optimization for this case.\n\n### 2. Refined `replicate_experts` Logic for Better Balancing\n\nThe `replicate_experts` function uses a greedy approach to assign replicas. While generally effective, it might not always yield the absolute best load balancing. A potential improvement could involve a more sophisticated assignment strategy if the overhead is acceptable, but given the goal of efficiency, we'll focus on small, impactful changes.\n\nOne observation is that the `current_avg_loads` is updated only for the logical experts that received a new replica. This is a good optimization. We can ensure that the `weight` tensor is used directly for calculating the new average load, avoiding any potential intermediate data structure creation.\n\n### 3. Simplifying the `rebalance_experts` Entry Point\n\nThe `rebalance_experts` function currently has a conditional that calls `rebalance_experts_hierarchical` twice with different parameters based on `num_groups % num_nodes == 0`. This could be simplified by having a single call to `rebalance_experts_hierarchical` and letting it handle the `num_groups=1` case internally as a special condition, or by making the `rebalance_experts_hierarchical` function more adaptable. However, the current structure is clear. The main focus will be on the internal functions.\n\nLet's focus on the `balanced_packing` function for initial improvements.\n\n```python\n<<<<<<< SEARCH\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Define an infinity tensor once to avoid repeated creation inside the loops.\n    inf_tensor = torch.full((), float('inf'), dtype=weight.dtype, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # Get current state for this layer's packs as views.\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id_tensor in indices[i]:\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of full packs to infinity to exclude them from argmin.\n            # The result 'pack_idx_tensor' will be a 0-dim tensor (scalar tensor).\n            pack_idx_tensor = torch.argmin(\n                torch.where(current_pack_items == groups_per_pack,\n                            inf_tensor, # Use pre-defined infinity tensor\n                            current_pack_weights))\n\n            # Assert that a valid pack was found and it has space.\n            # Use tensor indexing directly, avoiding .item() call.\n            assert current_pack_items[pack_idx_tensor] < groups_per_pack\n\n            # Assign the group to the chosen pack using tensor indexing.\n            # group_id_tensor is a 0-dim tensor, pack_idx_tensor is a 0-dim tensor.\n            pack_index[i, group_id_tensor] = pack_idx_tensor\n            rank_in_pack[i, group_id_tensor] = current_pack_items[pack_idx_tensor]\n\n            # Update pack weights and item counts for the chosen pack using tensor indexing.\n            pack_weights_per_layer[i, pack_idx_tensor] += weight[i, group_id_tensor]\n            pack_items_per_layer[i, pack_idx_tensor] += 1\n    return pack_index, rank_in_pack\n=======\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    groups_per_pack = num_groups // num_packs\n\n    # Initialize pack_index and rank_in_pack.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n\n    # Handle the simple case where each group is its own pack (no packing needed)\n    if groups_per_pack == 1:\n        pack_index = torch.arange(num_groups, dtype=torch.int64, device=weight.device).expand(num_layers, num_groups)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order for each layer.\n    # 'weight' is already float and on CPU from rebalance_experts.\n    sorted_weights, sorted_indices = weight.sort(-1, descending=True)\n\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    pack_weights_per_layer = torch.zeros(num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Define an infinity tensor once to avoid repeated creation inside the loops.\n    inf_tensor = torch.full((), float('inf'), dtype=weight.dtype, device=weight.device)\n\n    # Iterate over each layer.\n    for i in range(num_layers):\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # Iterate through the sorted groups for the current layer.\n        for k in range(num_groups):\n            # Get the original group ID for the k-th heaviest group in this layer.\n            original_group_id = sorted_indices[i, k]\n\n            # Find the pack with the minimum current weight among available ones.\n            # Exclude packs that are already full.\n            # `argmin` returns a scalar tensor.\n            pack_idx_tensor = torch.argmin(\n                torch.where(current_pack_items == groups_per_pack,\n                            inf_tensor,\n                            current_pack_weights))\n\n            # Assign the group to the chosen pack.\n            pack_index[i, original_group_id] = pack_idx_tensor\n            rank_in_pack[i, original_group_id] = current_pack_items[pack_idx_tensor]\n\n            # Update pack weights and item counts for the chosen pack.\n            pack_weights_per_layer[i, pack_idx_tensor] += sorted_weights[i, k]\n            pack_items_per_layer[i, pack_idx_tensor] += 1\n\n    return pack_index, rank_in_pack\n>>>>>>> REPLACE\n```\n\n**Reasoning for the changes in `balanced_packing`:**\n\n1.  **Simplified `groups_per_pack == 1` case:** The original code expanded `torch.arange(weight.size(-1))` which is `num_groups`. This is correct, but the new code explicitly uses `num_groups` for clarity. It also directly creates the `pack_index` and `rank_in_pack` with the correct dimensions and values. This change is minor but improves readability.\n\n2.  **Directly processing sorted weights:** Instead of iterating through `indices[i]` and then using `group_id_tensor` to index into `weight[i, group_id_tensor]`, we now compute `sorted_weights, sorted_indices = weight.sort(-1, descending=True)` once per layer. Then, in the inner loop, we iterate from `k = 0` to `num_groups - 1`, using `sorted_indices[i, k]` to get the original group ID and `sorted_weights[i, k]` for the weight. This approach is more direct and potentially more efficient as it avoids repeated indexing into the original `weight` tensor within the inner loop.\n\n3.  **Clearer Variable Names:** Using `sorted_weights` and `sorted_indices` makes the code's intent more obvious. `original_group_id` also clarifies what `sorted_indices[i, k]` represents.\n\nThese changes aim to improve the efficiency of `balanced_packing` by streamlining the assignment process, especially for larger numbers of groups and layers. The core greedy strategy remains the same, which is crucial for maintaining good performance while prioritizing speed.\n\nI will now proceed to review `replicate_experts` for potential similar optimizations."]}}}