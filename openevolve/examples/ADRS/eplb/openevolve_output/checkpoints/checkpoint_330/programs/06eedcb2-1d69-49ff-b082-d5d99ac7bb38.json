{"id": "06eedcb2-1d69-49ff-b082-d5d99ac7bb38", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # This approach avoids creating a large temporary tensor with float('inf').\n            # Find the pack with the minimum current weight among available ones.\n            # Mark full packs with infinity to exclude them from argmin.\n            # Clone current_pack_weights to avoid modifying the original tensor in place\n            # with float('inf') values before the actual update.\n            # Find the pack with the minimum current weight among available ones.\n            # Use torch.where to conditionally set weights to infinity for full packs.\n            pack = torch.argmin(\n                torch.where(current_pack_items < groups_per_pack,\n                            current_pack_weights,\n                            torch.full_like(current_pack_weights, float('inf'))))\n\n            # Assert that a valid pack was found and it has space.\n            # Using pack directly as a 0-dim tensor for indexing.\n            assert current_pack_items[pack] < groups_per_pack, \\\n                f\"No available packs found, but expected to find one. Pack {pack} is full.\"\n\n            # Assign the group to the chosen pack.\n            # group_id is a 0-dim tensor, so it works directly for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # weight[i, group_id] is the weight of the current group (0-dim tensor).\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas using a proportional\n    assignment strategy. This is a faster approximation to the greedy LPT.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n    device = weight.device\n\n    # Calculate desired total weight per replica for each layer\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n\n    # Calculate target logcnt (float) for each expert based on its proportion of total weight.\n    # Handle layers with zero total weight by distributing evenly.\n    target_logcnt_float = torch.where(\n        total_weight_per_layer > 0,\n        weight / total_weight_per_layer * num_phy,\n        torch.full_like(weight, num_phy / num_log)  # Distribute evenly if total_weight is 0\n    )\n\n    # Initial integer counts: floor of target_logcnt_float, ensuring at least 1 replica.\n    # Using floor ensures sum(logcnt) <= num_phy initially (due to rounding down).\n    logcnt = torch.max(torch.ones_like(target_logcnt_float, dtype=torch.int64),\n                       target_logcnt_float.floor().long())\n\n    # Calculate remaining replicas to distribute for each layer.\n    # This difference should be non-negative.\n    remaining_replicas = num_phy - logcnt.sum(dim=-1)\n\n    # Distribute remaining replicas greedily based on the fractional parts.\n    # This ensures the total count for each layer sums exactly to num_phy.\n    fractional_parts = target_logcnt_float - logcnt.float()\n\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Get the top `num_to_add` indices by fractional part for this layer\n            _, top_indices = fractional_parts[i].topk(num_to_add)\n            # Increment logcnt for these chosen experts\n            logcnt[i].scatter_add_(0, top_indices, torch.ones(num_to_add, dtype=torch.int64, device=device))\n\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count.\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Populate phy2log and rank using vectorized operations per layer.\n    # This avoids inefficient Python-level nested loops for tensor assignment.\n    for i in range(n):\n        # Generate phy2log for current layer: repeat expert IDs based on their counts.\n        # Example: if logcnt[i] = [2, 1, 3] for experts 0, 1, 2,\n        # then phy2log[i] will be [0, 0, 1, 2, 2, 2]\n        phy2log[i] = torch.repeat_interleave(\n            torch.arange(num_log, device=device), logcnt[i])\n\n        # Generate rank for current layer: create sequences [0, ..., count-1] for each expert.\n        # Example: if logcnt[i] = [2, 1, 3],\n        # then rank[i] will be [0, 1, 0, 0, 1, 2]\n        rank[i] = torch.cat([torch.arange(c, dtype=torch.int64, device=device) for c in logcnt[i]])\n\n        # Shuffle physical expert assignments within each layer.\n        # This is crucial for distributing replicas across physical resources,\n        # preventing all replicas of an expert from being assigned consecutively,\n        # which helps in actual load balancing on GPUs.\n        perm = torch.randperm(num_phy, device=device)\n        phy2log[i] = phy2log[i, perm]\n        rank[i] = rank[i, perm]\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Cast weight to float for calculations if not already, and keep on original device.\n    # Moving to CPU adds overhead if data is already on GPU and might slow down ops.\n    original_device = weight.device\n    # Cast weight to float for calculations. Move to CPU for potentially faster\n    # execution of Python-loop-heavy sections if the original tensor was on GPU.\n    # This avoids high overhead from many small GPU operations dispatched from Python.\n    weight_on_cpu = weight.float().cpu() # Use a new variable name to clarify it's on CPU\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight_on_cpu, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        # When using global policy, num_groups becomes 1 and num_nodes becomes 1.\n        # This simplifies the hierarchical logic to a flat one.\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight_on_cpu, num_replicas, 1, 1, num_gpus)\n    \n    # Determine the maximum number of replicas assigned to any single logical expert.\n    # This should be the size of the third dimension of log2phy.\n    # Ensure logcnt is not empty before calling max().\n    max_replicas_per_expert = 1\n    if logcnt.numel() > 0:\n        max_replicas_per_expert = logcnt.max().item()\n\n    # Initialize log2phy with a size that can accommodate all assignments.\n    # The shape should be [num_layers, num_logical_experts, max_replicas_per_expert].\n    log2phy = torch.full(\n        (num_layers, num_logical_experts, max_replicas_per_expert),\n        -1,  # Initialize with -1 to indicate no assignment\n        dtype=torch.int64,\n        device=logcnt.device,  # Use the device of logcnt (CPU)\n    )\n\n    # Populate log2phy by iterating through the physical experts and their assignments.\n    # For each physical expert `p_idx` from 0 to `num_replicas - 1`:\n    # - `logical_expert_id = phy2log[layer, p_idx]`\n    # - `rank_in_logical = phyrank[layer, p_idx]`\n    # We want to set `log2phy[layer, logical_expert_id, rank_in_logical] = p_idx`\n\n    # Create a flat index for each layer to map into the flattened log2phy tensor.\n    # The indices should map to the correct slot in `log2phy[layer, logical_expert_id, rank_in_logical]`\n    # The flattened index for `log2phy` is `logical_expert_id * max_replicas_per_expert + rank_in_logical`.\n    all_flat_indices = []\n    for layer in range(num_layers):\n        current_layer_phy2log = phy2log[layer] # Shape: [num_replicas]\n        current_layer_phyrank = phyrank[layer] # Shape: [num_replicas]\n\n        # Calculate the target indices in the flattened log2phy tensor for this layer.\n        # The shape of the flattened log2phy for a layer is num_logical_experts * max_replicas_per_expert.\n        layer_flat_indices = current_layer_phy2log * max_replicas_per_expert + current_layer_phyrank\n\n        # Ensure indices are within bounds. This is a sanity check.\n        max_expected_flat_idx = num_logical_experts * max_replicas_per_expert - 1\n        if layer_flat_indices.max() > max_expected_flat_idx or layer_flat_indices.min() < 0:\n            raise IndexError(\n                f\"Calculated flat index out of bounds for layer {layer}. \"\n                f\"Max generated index: {layer_flat_indices.max().item()}, \"\n                f\"Min generated index: {layer_flat_indices.min().item()}, \"\n                f\"Expected max for dimension: {max_expected_flat_idx}\"\n            )\n        all_flat_indices.append(layer_flat_indices)\n\n    # Stack the flat indices for all layers. Shape: [num_layers, num_replicas]\n    all_flat_indices = torch.stack(all_flat_indices, dim=0)\n\n    # The values to scatter are the physical expert IDs (0 to num_replicas - 1).\n    # Repeat these values for each layer. Shape: [num_layers, num_replicas]\n    values_to_scatter = torch.arange(num_replicas, dtype=torch.int64, device=log2phy.device).expand(num_layers, -1)\n\n    # Scatter these values into the log2phy tensor.\n    # Iterate layer by layer for clarity and safety in scatter operations.\n    for layer in range(num_layers):\n        log2phy[layer].view(-1).scatter_(\n            0,  # Scatter along the flattened dimension\n            all_flat_indices[layer], # Indices into the flattened log2phy for this layer\n            values_to_scatter[layer] # The physical expert IDs to place\n        )\n\n    # Move results back to the original device\n    return phy2log.to(original_device), log2phy.to(original_device), logcnt.to(original_device)\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "35b0f1bb-ff16-4071-826d-5262d9479c10", "generation": 8, "timestamp": 1751059188.4050448, "iteration_found": 146, "metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0.  Target sizes: [72].  Tensor sizes: [134]"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 36 lines with 63 lines", "parent_metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0.  Target sizes: [72].  Tensor sizes: [134]"}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.0000\n- speed_score: 0.0000\n- combined_score: 0.0000\n- error: The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0.  Target sizes: [72].  Tensor sizes: [134]\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0835, combined_score: 0.1909\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0845, combined_score: 0.1914\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0857, combined_score: 0.1920\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.1920)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0857), Performs well on combined_score (0.1920)\n\n\n### Program 2 (Score: 0.1914)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0845), Performs well on combined_score (0.1914)\n\n\n### Program 3 (Score: 0.1909)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0835), Performs well on combined_score (0.1909)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1908)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1907)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.1920, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.1515, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 24 lines with 29 lines\nChange 2: Replace 20 lines with 40 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.0000, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 5 (Score: 0.1619, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 24 lines with 17 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # This approach avoids creating a large temporary tensor with float('inf').\n            # Find the pack with the minimum current weight among available ones.\n            # Mark full packs with infinity to exclude them from argmin.\n            # Clone current_pack_weights to avoid modifying the original tensor in place\n            # with float('inf') values before the actual update.\n            # Find the pack with the minimum current weight among available ones.\n            # Use torch.where to conditionally set weights to infinity for full packs.\n            pack = torch.argmin(\n                torch.where(current_pack_items < groups_per_pack,\n                            current_pack_weights,\n                            torch.full_like(current_pack_weights, float('inf'))))\n\n            # Assert that a valid pack was found and it has space.\n            # Using pack directly as a 0-dim tensor for indexing.\n            assert current_pack_items[pack] < groups_per_pack, \\\n                f\"No available packs found, but expected to find one. Pack {pack} is full.\"\n\n            # Assign the group to the chosen pack.\n            # group_id is a 0-dim tensor, so it works directly for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # weight[i, group_id] is the weight of the current group (0-dim tensor).\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas using a proportional\n    assignment strategy. This is a faster approximation to the greedy LPT.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n    device = weight.device\n\n    # Calculate desired total weight per replica for each layer\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n\n    # Calculate target logcnt (float) for each expert based on its proportion of total weight.\n    # Handle layers with zero total weight by distributing evenly.\n    target_logcnt_float = torch.where(\n        total_weight_per_layer > 0,\n        weight / total_weight_per_layer * num_phy,\n        torch.full_like(weight, num_phy / num_log)  # Distribute evenly if total_weight is 0\n    )\n\n    # Initial integer counts: floor of target_logcnt_float, ensuring at least 1 replica.\n    # Using floor ensures sum(logcnt) <= num_phy initially (due to rounding down).\n    logcnt = torch.max(torch.ones_like(target_logcnt_float, dtype=torch.int64),\n                       target_logcnt_float.floor().long())\n\n    # Calculate remaining replicas to distribute for each layer.\n    # This difference should be non-negative.\n    remaining_replicas = num_phy - logcnt.sum(dim=-1)\n\n    # Distribute remaining replicas greedily based on the fractional parts.\n    # This ensures the total count for each layer sums exactly to num_phy.\n    fractional_parts = target_logcnt_float - logcnt.float()\n\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Get the top `num_to_add` indices by fractional part for this layer\n            _, top_indices = fractional_parts[i].topk(num_to_add)\n            # Increment logcnt for these chosen experts\n            logcnt[i].scatter_add_(0, top_indices, torch.ones(num_to_add, dtype=torch.int64, device=device))\n\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count.\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    # Populate phy2log and rank using vectorized operations per layer.\n    # This avoids inefficient Python-level nested loops for tensor assignment.\n    for i in range(n):\n        # Generate phy2log for current layer: repeat expert IDs based on their counts.\n        # Example: if logcnt[i] = [2, 1, 3] for experts 0, 1, 2,\n        # then phy2log[i] will be [0, 0, 1, 2, 2, 2]\n        phy2log[i] = torch.repeat_interleave(\n            torch.arange(num_log, device=device), logcnt[i])\n\n        # Generate rank for current layer: create sequences [0, ..., count-1] for each expert.\n        # Example: if logcnt[i] = [2, 1, 3],\n        # then rank[i] will be [0, 1, 0, 0, 1, 2]\n        rank[i] = torch.cat([torch.arange(c, dtype=torch.int64, device=device) for c in logcnt[i]])\n\n        # Shuffle physical expert assignments within each layer.\n        # This is crucial for distributing replicas across physical resources,\n        # preventing all replicas of an expert from being assigned consecutively,\n        # which helps in actual load balancing on GPUs.\n        perm = torch.randperm(num_phy, device=device)\n        phy2log[i] = phy2log[i, perm]\n        rank[i] = rank[i, perm]\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Cast weight to float for calculations if not already, and keep on original device.\n    # Moving to CPU adds overhead if data is already on GPU and might slow down ops.\n    original_device = weight.device\n    # Cast weight to float for calculations. Move to CPU for potentially faster\n    # execution of Python-loop-heavy sections if the original tensor was on GPU.\n    # This avoids high overhead from many small GPU operations dispatched from Python.\n    weight_on_cpu = weight.float().cpu() # Use a new variable name to clarify it's on CPU\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight_on_cpu, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        # When using global policy, num_groups becomes 1 and num_nodes becomes 1.\n        # This simplifies the hierarchical logic to a flat one.\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight_on_cpu, num_replicas, 1, 1, num_gpus)\n    \n    # Calculate the true maximum number of replicas any logical expert can have.\n    # This is crucial for correctly sizing log2phy and preventing out-of-bounds errors.\n    # The maximum count for an expert can be num_replicas - (num_logical_experts - 1)\n    # if other experts each get one replica.\n    # We take the max from the actual 'logcnt' calculated by replicate_experts.\n    actual_max_logcnt = logcnt.max().item() if logcnt.numel() > 0 else 1\n    \n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, actual_max_logcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device, # This will be CPU since weight_on_cpu was used\n    )\n    # The scatter index needs to be calculated using the actual_max_logcnt\n    # to ensure it maps correctly into the flattened log2phy tensor.\n    scatter_indices = phy2log * actual_max_logcnt + phyrank\n    \n    # Assert that scatter_indices are within bounds. This acts as a sanity check.\n    max_expected_index = num_logical_experts * actual_max_logcnt - 1\n    if scatter_indices.max() > max_expected_index or scatter_indices.min() < 0:\n        # This indicates a logic error in `replicate_experts` or `rebalance_experts_hierarchical`\n        # if phyrank exceeds actual_max_logcnt or phy2log is out of range.\n        # It shouldn't happen with the corrected actual_max_logcnt, but good to debug.\n        raise IndexError(f\"Scatter index out of bounds. Max generated index: {scatter_indices.max().item()}, \"\n                         f\"Min generated index: {scatter_indices.min().item()}, \"\n                         f\"Expected max for dimension: {max_expected_index}\")\n\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        scatter_indices,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    \n    # Move results back to the original device\n    return phy2log.to(original_device), log2phy.to(original_device), logcnt.to(original_device)\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program aims to rebalance experts in a Mixture-of-Experts (MoE) model. The provided `rebalance_experts` function and its helper `rebalance_experts_hierarchical` use a combination of greedy packing (`balanced_packing`) and proportional expert replication (`replicate_experts`).\n\nThe error message \"The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0. Target sizes: [72]. Tensor sizes: [134]\" suggests an issue with tensor shape mismatches, likely during the construction of `log2phy` or related operations. This indicates that the logic for determining the size of `log2phy` or how `scatter_indices` are generated might be flawed, especially when `actual_max_logcnt` is calculated.\n\nHere are some suggestions for improvement:\n\n### Improvement 1: Correct `log2phy` sizing and scattering for accurate load balancing and error prevention.\n\nThe calculation of `actual_max_logcnt` and its subsequent use in sizing `log2phy` and generating `scatter_indices` appears to be a primary source of the reported error. The current approach might be overestimating or underestimating the maximum number of replicas any single logical expert can receive, leading to shape mismatches during the `scatter_` operation.\n\n**Reasoning:**\nThe `log2phy` tensor is intended to map each physical expert to its logical expert. Its third dimension should accommodate the maximum number of replicas any single logical expert might be assigned. The current calculation of `actual_max_logcnt` as `logcnt.max().item()` might not be robust enough if `logcnt` itself is not perfectly representative of the maximum possible replicas due to the greedy nature of `replicate_experts`. A more conservative upper bound or a dynamic resizing approach might be safer.\n\nHowever, the core issue seems to be how `scatter_indices` are generated and used. The `scatter_indices` are calculated as `phy2log * actual_max_logcnt + phyrank`. If `actual_max_logcnt` is not the *exact* number of replicas assigned to each logical expert in the `phy2log` structure, this calculation can lead to overlapping indices or out-of-bounds access. The `phy2log` tensor itself is reshaped into `[num_layers, num_logical_experts, X]` implicitly by how it's constructed, but the `scatter_indices` are computed based on `num_replicas` and `actual_max_logcnt`.\n\nLet's refine the calculation of `log2phy` and `scatter_indices` to ensure they align correctly. Instead of relying on `logcnt.max().item()`, we should determine the maximum number of physical experts assigned to *any* logical expert.\n\nThe problem statement also mentions the error: \"The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0. Target sizes: [72]. Tensor sizes: [134]\". This specific error indicates a mismatch between a target size of 72 and an existing size of 134. This suggests that `num_replicas` might be 72, but the operations are expecting something related to 134. This could be related to `num_logical_experts` or a miscalculation in intermediate steps.\n\nGiven the error, it's possible that `num_logical_experts` is 134 and `num_replicas` is 72, or vice-versa, and the logic for mapping them is flawed. The `replicate_experts` function calculates `logcnt`, which is the number of replicas per logical expert. The `log2phy` tensor's third dimension should be `max(logcnt)` over all logical experts.\n\nLet's assume `num_replicas` is the total number of physical experts. The `log2phy` tensor should have dimensions `[num_layers, num_logical_experts, max_replicas_per_expert]`. The `max_replicas_per_expert` is the maximum value in the `logcnt` tensor.\n\nThe `scatter_indices` calculation needs to map the `num_replicas` physical experts into the `log2phy` tensor. The `phy2log` tensor tells us which logical expert each physical expert maps to. The `phyrank` tells us the rank of that physical expert within its logical expert group.\n\nLet's re-examine the `scatter_indices` generation and the `log2phy` initialization:\n\nThe current code:\n```python\n    actual_max_logcnt = logcnt.max().item() if logcnt.numel() > 0 else 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, actual_max_logcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device, # This will be CPU since weight_on_cpu was used\n    )\n    scatter_indices = phy2log * actual_max_logcnt + phyrank\n    # ... scatter_indices are used to populate log2phy\n```\n\nThe issue might be that `phy2log` has shape `[num_layers, num_replicas]`, and `phyrank` has shape `[num_layers, num_replicas]`.\nWhen we calculate `scatter_indices = phy2log * actual_max_logcnt + phyrank`, we are effectively trying to map `num_replicas` physical experts.\n\nThe problem is that `phy2log` contains logical expert IDs, not indices into the `log2phy` tensor's third dimension. The `phyrank` *is* the index into the third dimension for a given logical expert.\n\nA more direct way to populate `log2phy` would be to iterate through `phy2log` and `phyrank` and place the physical expert index.\n\nLet's consider the shapes more carefully:\n- `phy2log`: `[num_layers, num_replicas]` (physical expert -> logical expert)\n- `phyrank`: `[num_layers, num_replicas]` (rank of physical expert within its logical expert)\n- `logcnt`: `[num_layers, num_logical_experts]` (count of replicas for each logical expert)\n\nWe want `log2phy[layer, logical_expert_id, rank_within_logical_expert]` to store the physical expert ID.\n\nThe current `scatter_indices` calculation seems to flatten `log2phy` and then scatter into it. The issue might be in how `phy2log` and `phyrank` are used to create the flattened indices.\n\nLet's try to reconstruct the correct indexing for `log2phy.view(num_layers, -1)`.\nThe flattened `log2phy` has shape `[num_layers, num_logical_experts * actual_max_logcnt]`.\nThe indices to scatter into this flattened tensor should represent `(logical_expert_id * actual_max_logcnt + rank_within_logical_expert)`.\n\nWe can get `logical_expert_id` from `phy2log`.\nWe have `rank_within_logical_expert` from `phyrank`.\n\nSo, for each `layer` and `physical_expert_idx` from 0 to `num_replicas - 1`:\n`logical_expert_id = phy2log[layer, physical_expert_idx]`\n`rank_within_logical_expert = phyrank[layer, physical_expert_idx]`\nThe index in the flattened `log2phy` tensor (for that layer) would be `logical_expert_id * actual_max_logcnt + rank_within_logical_expert`.\n\nThe current `scatter_indices` calculation: `phy2log * actual_max_logcnt + phyrank` is likely where the shape mismatch occurs because `phy2log` is `[num_layers, num_replicas]` and `actual_max_logcnt` is a scalar, and `phyrank` is `[num_layers, num_replicas]`. This would result in `scatter_indices` of shape `[num_layers, num_replicas]`.\nThen `log2phy.view(num_layers, -1).scatter_(-1, scatter_indices, ...)` tries to use these `[num_layers, num_replicas]` indices to scatter into a tensor of shape `[num_layers, num_logical_experts * actual_max_logcnt]`. This is where the mismatch happens if `num_replicas != num_logical_experts * actual_max_logcnt`.\n\nThe correct way to generate indices for `scatter_` should consider the structure of `log2phy`.\n\nLet's try to correct the `log2phy` construction. The size of the third dimension should be the maximum number of replicas any logical expert can have, which is `logcnt.max()`.\n\n```python\n# Corrected logic for log2phy construction and scattering\noriginal_device = weight.device\nweight_on_cpu = weight.float().cpu()\n\nif num_groups % num_nodes == 0:\n    phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n        weight_on_cpu, num_replicas, num_groups, num_nodes, num_gpus)\nelse:\n    phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n        weight_on_cpu, num_replicas, 1, 1, num_gpus)\n\n# Determine the maximum number of replicas assigned to any single logical expert.\n# This should be the size of the third dimension of log2phy.\n# Ensure logcnt is not empty before calling max().\nmax_replicas_per_expert = 1\nif logcnt.numel() > 0:\n    max_replicas_per_expert = logcnt.max().item()\n\n# Initialize log2phy with a size that can accommodate all assignments.\n# The shape should be [num_layers, num_logical_experts, max_replicas_per_expert].\nlog2phy = torch.full(\n    (num_layers, num_logical_experts, max_replicas_per_expert),\n    -1,  # Initialize with -1 to indicate no assignment\n    dtype=torch.int64,\n    device=logcnt.device,  # Use the device of logcnt (CPU)\n)\n\n# Populate log2phy by iterating through the physical experts and their assignments.\n# For each physical expert `p_idx` from 0 to `num_replicas - 1`:\n# - `logical_expert_id = phy2log[layer, p_idx]`\n# - `rank_in_logical = phyrank[layer, p_idx]`\n# We want to set `log2phy[layer, logical_expert_id, rank_in_logical] = p_idx`\n\n# Flatten the target indices for log2phy\n# The indices should map to the correct slot in `log2phy[layer, logical_expert_id, rank_in_logical]`\n# The flattened index for `log2phy` is `logical_expert_id * max_replicas_per_expert + rank_in_logical`\n# We can generate these indices directly.\n\n# Create a flat index for each layer\nflat_indices_per_layer = []\nfor layer in range(num_layers):\n    # Get the logical expert IDs and their ranks for the current layer\n    current_layer_phy2log = phy2log[layer] # [num_replicas]\n    current_layer_phyrank = phyrank[layer] # [num_replicas]\n\n    # Calculate the target indices in the flattened log2phy tensor for this layer\n    # The shape of the flattened log2phy for a layer is num_logical_experts * max_replicas_per_expert\n    layer_flat_indices = current_layer_phy2log * max_replicas_per_expert + current_layer_phyrank\n\n    # Ensure indices are within bounds. This is a sanity check.\n    max_expected_flat_idx = num_logical_experts * max_replicas_per_expert - 1\n    if layer_flat_indices.max() > max_expected_flat_idx or layer_flat_indices.min() < 0:\n        raise IndexError(\n            f\"Calculated flat index out of bounds for layer {layer}. \"\n            f\"Max generated index: {layer_flat_indices.max().item()}, \"\n            f\"Min generated index: {layer_flat_indices.min().item()}, \"\n            f\"Expected max for dimension: {max_expected_flat_idx}\"\n        )\n\n    flat_indices_per_layer.append(layer_flat_indices)\n\n# Stack the flat indices for all layers\n# Shape: [num_layers, num_replicas]\nall_flat_indices = torch.stack(flat_indices_per_layer, dim=0)\n\n# The values to scatter are the physical expert IDs (0 to num_replicas - 1)\n# We need to repeat these values for each layer.\nvalues_to_scatter = torch.arange(num_replicas, dtype=torch.int64, device=log2phy.device).expand(num_layers, -1)\n\n# Now, scatter these values into the log2phy tensor.\n# We need to scatter into the *flattened* log2phy tensor for each layer.\n# log2phy.view(num_layers, -1) has shape [num_layers, num_logical_experts * max_replicas_per_expert]\n# all_flat_indices has shape [num_layers, num_replicas]\n# values_to_scatter has shape [num_layers, num_replicas]\n\n# Perform the scatter operation.\n# We scatter into the flattened log2phy. The indices specify the column in the flattened tensor.\n# The scatter operation needs to be done along the last dimension of the flattened log2phy.\n# We can iterate layer by layer or use a more advanced scatter if possible.\n# Given the structure, a layer-by-layer scatter might be clearer and safer.\n\nfor layer in range(num_layers):\n    log2phy[layer].view(-1).scatter_(\n        0,  # Scatter along the flattened dimension\n        all_flat_indices[layer], # Indices into the flattened log2phy for this layer\n        values_to_scatter[layer] # The physical expert IDs to place\n    )\n\n# Move results back to the original device\nreturn phy2log.to(original_device), log2phy.to(original_device), logcnt.to(original_device)\n```\n\nThis revised approach directly constructs the indices for `log2phy` based on the `phy2log` and `phyrank` outputs, ensuring that the correct physical expert ID is placed at the `[layer, logical_expert_id, rank_in_logical]` position. This should resolve the shape mismatch error by correctly sizing and populating `log2phy`.\n\nThe rationale for moving calculations to CPU:\nThe comment `# This avoids high overhead from many small GPU operations dispatched from Python.` is valid. When operations are heavily driven by Python loops (even implicit loops like `torch.where` or `torch.argmin` called within a loop over layers), the Python interpreter's overhead can dominate. Moving to CPU can sometimes be faster for such workloads if the CPU is efficient at these operations and the overhead of moving data back and forth is less than the Python dispatch overhead. However, for very large tensors or operations that are highly optimized on GPU, staying on GPU might be faster. Given the history of improvements, it seems the CPU migration was intended to optimize these Python-driven loops. The change here is primarily about correcting the logic of index calculation and tensor population, not fundamentally changing the device strategy.\n\nLet's format this as a diff.\n\n<<<<<<< SEARCH\n    # Calculate the true maximum number of replicas any logical expert can have.\n    # This is crucial for correctly sizing log2phy and preventing out-of-bounds errors.\n    # The maximum count for an expert can be num_replicas - (num_logical_experts - 1)\n    # if other experts each get one replica.\n    # We take the max from the actual 'logcnt' calculated by replicate_experts.\n    actual_max_logcnt = logcnt.max().item() if logcnt.numel() > 0 else 1\n    \n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, actual_max_logcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device, # This will be CPU since weight_on_cpu was used\n    )\n    # The scatter index needs to be calculated using the actual_max_logcnt\n    # to ensure it maps correctly into the flattened log2phy tensor.\n    scatter_indices = phy2log * actual_max_logcnt + phyrank\n    \n    # Assert that scatter_indices are within bounds. This acts as a sanity check.\n    max_expected_index = num_logical_experts * actual_max_logcnt - 1\n    if scatter_indices.max() > max_expected_index or scatter_indices.min() < 0:\n        # This indicates a logic error in `replicate_experts` or `rebalance_experts_hierarchical`\n        # if phyrank exceeds actual_max_logcnt or phy2log is out of range.\n        # It shouldn't happen with the corrected actual_max_logcnt, but good to debug.\n        raise IndexError(f\"Scatter index out of bounds. Max generated index: {scatter_indices.max().item()}, \"\n                         f\"Min generated index: {scatter_indices.min().item()}, \"\n                         f\"Expected max for dimension: {max_expected_index}\")\n\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        scatter_indices,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    \n    # Move results back to the original device\n    return phy2log.to(original_device), log2phy.to(original_device), logcnt.to(original_device)\n=======\n    # Determine the maximum number of replicas assigned to any single logical expert.\n    # This should be the size of the third dimension of log2phy.\n    # Ensure logcnt is not empty before calling max().\n    max_replicas_per_expert = 1\n    if logcnt.numel() > 0:\n        max_replicas_per_expert = logcnt.max().item()\n\n    # Initialize log2phy with a size that can accommodate all assignments.\n    # The shape should be [num_layers, num_logical_experts, max_replicas_per_expert].\n    log2phy = torch.full(\n        (num_layers, num_logical_experts, max_replicas_per_expert),\n        -1,  # Initialize with -1 to indicate no assignment\n        dtype=torch.int64,\n        device=logcnt.device,  # Use the device of logcnt (CPU)\n    )\n\n    # Populate log2phy by iterating through the physical experts and their assignments.\n    # For each physical expert `p_idx` from 0 to `num_replicas - 1`:\n    # - `logical_expert_id = phy2log[layer, p_idx]`\n    # - `rank_in_logical = phyrank[layer, p_idx]`\n    # We want to set `log2phy[layer, logical_expert_id, rank_in_logical] = p_idx`\n\n    # Create a flat index for each layer to map into the flattened log2phy tensor.\n    # The indices should map to the correct slot in `log2phy[layer, logical_expert_id, rank_in_logical]`\n    # The flattened index for `log2phy` is `logical_expert_id * max_replicas_per_expert + rank_in_logical`.\n    all_flat_indices = []\n    for layer in range(num_layers):\n        current_layer_phy2log = phy2log[layer] # Shape: [num_replicas]\n        current_layer_phyrank = phyrank[layer] # Shape: [num_replicas]\n\n        # Calculate the target indices in the flattened log2phy tensor for this layer.\n        # The shape of the flattened log2phy for a layer is num_logical_experts * max_replicas_per_expert.\n        layer_flat_indices = current_layer_phy2log * max_replicas_per_expert + current_layer_phyrank\n\n        # Ensure indices are within bounds. This is a sanity check.\n        max_expected_flat_idx = num_logical_experts * max_replicas_per_expert - 1\n        if layer_flat_indices.max() > max_expected_flat_idx or layer_flat_indices.min() < 0:\n            raise IndexError(\n                f\"Calculated flat index out of bounds for layer {layer}. \"\n                f\"Max generated index: {layer_flat_indices.max().item()}, \"\n                f\"Min generated index: {layer_flat_indices.min().item()}, \"\n                f\"Expected max for dimension: {max_expected_flat_idx}\"\n            )\n        all_flat_indices.append(layer_flat_indices)\n\n    # Stack the flat indices for all layers. Shape: [num_layers, num_replicas]\n    all_flat_indices = torch.stack(all_flat_indices, dim=0)\n\n    # The values to scatter are the physical expert IDs (0 to num_replicas - 1).\n    # Repeat these values for each layer. Shape: [num_layers, num_replicas]\n    values_to_scatter = torch.arange(num_replicas, dtype=torch.int64, device=log2phy.device).expand(num_layers, -1)\n\n    # Scatter these values into the log2phy tensor.\n    # Iterate layer by layer for clarity and safety in scatter operations.\n    for layer in range(num_layers):\n        log2phy[layer].view(-1).scatter_(\n            0,  # Scatter along the flattened dimension\n            all_flat_indices[layer], # Indices into the flattened log2phy for this layer\n            values_to_scatter[layer] # The physical expert IDs to place\n        )\n\n    # Move results back to the original device\n    return phy2log.to(original_device), log2phy.to(original_device), logcnt.to(original_device)\n>>>>>>> REPLACE\n\n### Improvement 2: Optimize `replicate_experts` for potential speedup.\n\nThe `replicate_experts` function uses a greedy approach to distribute remaining replicas based on fractional parts. While this is generally correct, the loop `for i in range(n):` iterates over layers, and within that, `topk` is called. For very large numbers of layers or experts, this could be a bottleneck.\n\n**Reasoning:**\nThe core of `replicate_experts` is distributing `remaining_replicas` based on `fractional_parts`. If `n` (number of layers) is large, the loop can be slow. While not directly causing the error, optimizing this part could improve the `speed_score`.\n\nConsider if `torch.scatter_add_` or other more vectorized operations can be used to avoid explicit Python loops over layers for the distribution of remaining replicas. However, the `topk` operation is inherently dependent on the values within each layer, making full vectorization across layers difficult without significant restructuring.\n\nFor now, the primary focus is on fixing the error. If performance is still an issue after fixing the error, further profiling of `replicate_experts` could be done. The current `replicate_experts` implementation appears to be reasonably vectorized within each layer. The loop over `n` layers is necessary if `topk` needs to be applied independently per layer.\n\nThe current implementation of `replicate_experts` is already quite optimized with vectorized operations per layer. The loop `for i in range(n):` is necessary because the distribution of remaining replicas is layer-specific. Any attempt to remove this loop would likely require a different strategy for distributing those remaining replicas, which might sacrifice optimality or introduce complexity.\n\nGiven the primary goal is to fix the error and improve load balancing, and the `replicate_experts` function seems to be a standard implementation of proportional replication, I will not suggest changes to `replicate_experts` at this time, as it might introduce regressions or complexity without guaranteed benefits. The focus remains on the `log2phy` construction and the error.\n\n### Improvement 3: Ensure consistent device placement and data types.\n\nThe code already attempts to manage device placement by moving to CPU (`weight.float().cpu()`) and then back to the original device. However, it's crucial to ensure that intermediate tensors (`log2phy`, `scatter_indices`, `values_to_scatter`) are consistently on the CPU when operations are performed there, and then correctly moved back.\n\n**Reasoning:**\nThe error message about tensor sizes suggests that perhaps some tensors are on different devices or have unexpected shapes due to a mix of CPU and GPU operations not being handled carefully. While the current code does move `weight_on_cpu` and uses `logcnt.device` for `log2phy`, a thorough review of all tensor operations within the context of `weight_on_cpu` is good practice. The proposed fix in Improvement 1 explicitly uses `logcnt.device` for `log2phy` and generates indices on the same device, which should help maintain consistency.\n\nThe current code:\n`log2phy = torch.full((...), device=logcnt.device)`\n`scatter_indices = phy2log * actual_max_logcnt + phyrank`\nHere, `phy2log` and `phyrank` are returned from `rebalance_experts_hierarchical` which itself operates on `weight_on_cpu`. So, `phy2log` and `phyrank` are also on CPU. `logcnt` is also on CPU. Thus, `scatter_indices` will be on CPU. `log2phy` is initialized on CPU. The `scatter_` operation is performed on CPU. The final `to(original_device)` moves the results. This seems consistent.\n\nThe suggested change in Improvement 1 maintains this CPU-centric approach for `log2phy` construction, which is appropriate given that `weight_on_cpu` was used.\n\nTherefore, no specific diff is needed for Improvement 3, as the strategy is already in place, and the fix in Improvement 1 adheres to it.\n\nThe core issue is indeed the construction of `log2phy` and the related indexing. The proposed diff addresses this directly.\n\nFinal check on the error: \"The expanded size of the tensor (72) must match the existing size (134) at non-singleton dimension 0. Target sizes: [72]. Tensor sizes: [134]\".\nThis error could arise if, for example:\n- `num_replicas` is 72.\n- `num_logical_experts` is 134.\n- The `log2phy` tensor is being constructed with a size related to `num_logical_experts` (134) but operations expect something related to `num_replicas` (72), or vice-versa.\nThe fix addresses the sizing of `log2phy` based on `max_replicas_per_expert`, and the `scatter_indices` are generated to match this structure. This should resolve the mismatch. If `num_logical_experts` were 72 and `num_replicas` were 134, the logic would still apply, but the specific values causing the error are unknown without a trace. The fix is general enough to handle these shape mismatches by correctly calculating the indices."]}}}