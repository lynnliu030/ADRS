{"id": "9f1783b5-cac3-41f9-a088-afe0fa266ac3", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # This approach avoids creating a large temporary tensor with float('inf').\n            # Find the pack with the minimum current weight among available ones.\n            # Mark full packs with infinity to exclude them from argmin.\n            # Clone current_pack_weights to avoid modifying the original tensor in place\n            # with float('inf') values before the actual update.\n            # Find the pack with the minimum current weight among available ones.\n            # Use torch.where to conditionally set weights to infinity for full packs.\n            pack = torch.argmin(\n                torch.where(current_pack_items < groups_per_pack,\n                            current_pack_weights,\n                            torch.full_like(current_pack_weights, float('inf'))))\n\n            # Assert that a valid pack was found and it has space.\n            # Using pack directly as a 0-dim tensor for indexing.\n            assert current_pack_items[pack] < groups_per_pack, \\\n                f\"No available packs found, but expected to find one. Pack {pack} is full.\"\n\n            # Assign the group to the chosen pack.\n            # group_id is a 0-dim tensor, so it works directly for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # weight[i, group_id] is the weight of the current group (0-dim tensor).\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas using a proportional\n    assignment strategy. This is a faster approximation to the greedy LPT.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n    device = weight.device\n\n    # Calculate desired total weight per replica for each layer\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n\n    # Calculate target logcnt (float) for each expert based on its proportion of total weight.\n    # Handle layers with zero total weight by distributing evenly.\n    target_logcnt_float = torch.where(\n        total_weight_per_layer > 0,\n        weight / total_weight_per_layer * num_phy,\n        torch.full_like(weight, num_phy / num_log)  # Distribute evenly if total_weight is 0\n    )\n\n    # Initial integer counts: floor of target_logcnt_float, ensuring at least 1 replica.\n    # Using floor ensures sum(logcnt) <= num_phy initially (due to rounding down).\n    logcnt = torch.max(torch.ones_like(target_logcnt_float, dtype=torch.int64),\n                       target_logcnt_float.floor().long())\n\n    # Calculate remaining replicas to distribute for each layer.\n    # This difference should be non-negative.\n    remaining_replicas = num_phy - logcnt.sum(dim=-1)\n\n    # Distribute remaining replicas greedily based on the fractional parts.\n    # This ensures the total count for each layer sums exactly to num_phy.\n    fractional_parts = target_logcnt_float - logcnt.float()\n\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Get the top `num_to_add` indices by fractional part for this layer\n            _, top_indices = fractional_parts[i].topk(num_to_add)\n            # Increment logcnt for these chosen experts\n            logcnt[i].scatter_add_(0, top_indices, torch.ones(num_to_add, dtype=torch.int64, device=device))\n\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count.\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    for i in range(n):\n        current_phy_idx = 0\n        for log_expert_id in range(num_log):\n            count = logcnt[i, log_expert_id].item()\n            for r in range(count):\n                if current_phy_idx < num_phy:  # Safety check\n                    phy2log[i, current_phy_idx] = log_expert_id\n                    rank[i, current_phy_idx] = r\n                    current_phy_idx += 1\n                else:\n                    break  # Should not happen if sum(logcnt) == num_phy\n            if current_phy_idx >= num_phy:\n                break\n\n        # Shuffle physical expert assignments within each layer.\n        # This is crucial for distributing replicas across physical resources,\n        # preventing all replicas of an expert from being assigned consecutively,\n        # which helps in actual load balancing on GPUs.\n        perm = torch.randperm(num_phy, device=device)\n        phy2log[i] = phy2log[i, perm]\n        rank[i] = rank[i, perm]\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Cast weight to float for calculations if not already, and keep on original device.\n    # Moving to CPU adds overhead if data is already on GPU and might slow down ops.\n    weight = weight.float()\n    \n    if num_groups > 0 and num_nodes > 0 and num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy: replicate experts directly\n        # We treat num_logical_experts as the number of logical experts to distribute\n        # across num_replicas physical experts.\n        # The 'weight' tensor already represents load per logical expert.\n        # The replicate_experts function is designed for this.\n        # Note: replicate_experts expects [X, num_log] and num_phy.\n        # Here, X is num_layers, num_log is num_logical_experts, and num_phy is num_replicas.\n        phy2log, phyrank, logcnt = replicate_experts(weight, num_replicas)\n\n    # The rest of the logic to construct log2phy from phy2log, phyrank, and logcnt\n    # needs to be consistent with the output of replicate_experts and\n    # rebalance_experts_hierarchical.\n    # The number of physical experts per logical expert (maxlogcnt) is determined by\n    # how many replicas are assigned to each logical expert.\n    # The logcnt tensor already provides this information.\n    # We need to find the maximum value in logcnt across all layers and logical experts.\n    maxlogcnt = logcnt.max().item() if logcnt.numel() > 0 else 0\n    # Ensure maxlogcnt is at least 1 to accommodate cases where logcnt might be empty or all zeros (though unlikely here)\n    # and to handle the case where num_replicas might be less than num_logical_experts (though problem statement implies num_replicas >= num_logical_experts)\n    # A safer upper bound for maxlogcnt would be num_replicas // num_logical_experts + epsilon, but logcnt already gives the exact counts.\n    # The original code used num_redundant_experts + 1, which assumes num_logical_experts is the base and num_replicas are added.\n    # This logic needs to be aligned with how logcnt is computed.\n    # If replicate_experts assigns multiple replicas to a logical expert, logcnt will reflect that.\n    # The `num_redundant_experts` logic might be specific to the hierarchical split.\n\n    # Let's re-evaluate `maxlogcnt` based on `logcnt` directly.\n    # `logcnt` is [num_layers, num_logical_experts]\n    # The maximum number of replicas for any single logical expert.\n    # If `logcnt` is empty, or all zeros, `maxlogcnt` should be 0.\n    # `torch.max(logcnt)` will handle this. If `logcnt` is all zeros, max is 0.\n    # If `logcnt` is empty, `logcnt.max()` raises an error.\n    # A robust way is to ensure `logcnt` has at least one element for `max()` to work.\n    # If `replicate_experts` returns a `logcnt` of shape `(num_layers, num_logical_experts)`,\n    # then `logcnt.max()` is fine.\n    # The `phy2log` and `phyrank` from `replicate_experts` are [num_layers, num_replicas].\n    # We need to map these to the `log2phy` format [num_layers, num_logical_experts, maxlogcnt].\n\n    # Let's reconstruct log2phy based on the direct output of replicate_experts.\n    # `phy2log` from `replicate_experts` is [num_layers, num_replicas], where each element is the logical expert ID.\n    # `phyrank` from `replicate_experts` is [num_layers, num_replicas], where each element is the rank within the logical expert.\n    # `logcnt` from `replicate_experts` is [num_layers, num_logical_experts], total replicas for each logical expert.\n\n    # Determine the maximum number of replicas any logical expert has.\n    # This determines the size of the third dimension of log2phy.\n    # If logcnt is all zeros (e.g., num_logical_experts=0), this might fail.\n    # Ensure logcnt is not empty before calling max.\n    if logcnt.numel() == 0:\n        # Handle case where there are no logical experts or no assignments.\n        # This situation might indicate an issue upstream or an edge case.\n        # For now, assume logcnt has valid dimensions based on input.\n        # If num_logical_experts is 0, then logcnt would be [num_layers, 0].\n        # If num_replicas is 0, then phy2log/phyrank would be [num_layers, 0].\n        # The `replicate_experts` function handles `num_phy >= num_log`.\n        # If `num_logical_experts` is 0, `replicate_experts` might return empty tensors or tensors with 0 dimension.\n        # Let's assume valid inputs where num_logical_experts > 0 and num_replicas > 0.\n        maxlogcnt = 0 # Or raise an error if this state is unexpected.\n    else:\n        maxlogcnt = logcnt.max().item()\n\n    # Initialize log2phy. If maxlogcnt is 0, this will be [num_layers, num_logical_experts, 0].\n    # This might cause issues in scatter_. Let's ensure maxlogcnt is at least 1 if num_logical_experts > 0.\n    # The number of replicas for a logical expert can be at most num_replicas.\n    # However, `logcnt` already tells us the *actual* number of replicas assigned.\n    # The size of the third dimension should be the maximum count observed in `logcnt`.\n    if num_logical_experts > 0 and maxlogcnt == 0:\n        # This case might happen if num_replicas < num_logical_experts and some logical experts get 0 replicas.\n        # However, `replicate_experts` ensures each logical expert gets at least 1 replica if num_phy >= num_log.\n        # If num_logical_experts > 0 and num_replicas > 0, then `logcnt` should contain values >= 1.\n        # The original code's `maxlogcnt = num_redundant_experts + 1` was a heuristic.\n        # Let's use the actual max count from `logcnt` for the size.\n        # If `replicate_experts` correctly assigns replicas, `logcnt.max()` should be the correct dimension.\n        # If `num_logical_experts` is 0, `logcnt` is `(num_layers, 0)`, `max()` would error.\n        # If `num_logical_experts > 0` and `num_replicas > 0`, `logcnt` should have values.\n        # Let's ensure `maxlogcnt` is at least 1 if `num_logical_experts > 0`.\n        maxlogcnt = max(1, maxlogcnt) # Ensure the dimension is at least 1 if there are logical experts.\n\n    # If num_logical_experts is 0, then the shape should be (num_layers, 0, 0) or similar.\n    # If num_logical_experts > 0 and num_replicas is 0, this is an invalid state.\n    # Assuming num_logical_experts > 0 and num_replicas > 0.\n\n    # Initialize log2phy with -1.\n    # Shape: [num_layers, num_logical_experts, maxlogcnt]\n    log2phy = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n\n    # Populate log2phy.\n    # `phy2log` has shape [num_layers, num_replicas].\n    # `phyrank` has shape [num_layers, num_replicas].\n    # `logcnt` has shape [num_layers, num_logical_experts].\n\n    # We need to iterate through each layer and each physical expert to fill log2phy.\n    # For each physical expert `p` in `phy2log[l]`, its logical expert is `log_idx = phy2log[l, p]`.\n    # Its rank within that logical expert is `rank_idx = phyrank[l, p]`.\n    # We want to place the physical expert ID `p` into `log2phy[l, log_idx, rank_idx]`.\n\n    # This operation can be vectorized.\n    # We need to map the physical expert indices (`torch.arange(num_replicas)`)\n    # to their corresponding positions in `log2phy`.\n\n    # The target indices for `scatter_` are `(layer_idx, logical_expert_idx, rank_idx)`.\n    # `layer_idx` is broadcastable over `num_replicas`.\n    # `logical_expert_idx` comes from `phy2log`.\n    # `rank_idx` comes from `phyrank`.\n\n    # Create broadcastable layer indices.\n    layer_indices = torch.arange(num_layers, device=logcnt.device).unsqueeze(1).expand(-1, num_replicas)\n\n    # Create broadcastable logical expert indices.\n    # `phy2log` is already [num_layers, num_replicas].\n\n    # Create broadcastable rank indices.\n    # `phyrank` is already [num_layers, num_replicas].\n\n    # Flatten these to create the indices for scatter_.\n    # The indices need to be in the format required by scatter_:\n    # `scatter_(dim, index, src)` where `index` has the same shape as `src`.\n    # The `dim` is the dimension along which to scatter.\n    # For `log2phy` of shape `(L, N_log, MaxLogCnt)`, we want to scatter along `dim=1` (logical expert dim)\n    # and `dim=2` (rank dim).\n\n    # The `scatter_` function in PyTorch can scatter into multiple dimensions if the `index` tensor is structured correctly.\n    # However, a common pattern is to flatten the target dimensions and scatter into the last dimension.\n    # Let's try to flatten `(num_logical_experts, maxlogcnt)` into a single dimension for scatter.\n    # This requires careful index calculation.\n\n    # The original code uses `phy2log * maxlogcnt + phyrank` and scatters into `log2phy.view(num_layers, -1)`.\n    # This assumes `phy2log` maps directly to indices in a flattened `(num_logical_experts, maxlogcnt)` tensor.\n    # Let's verify if this mapping is correct for the output of `replicate_experts`.\n\n    # `replicate_experts` output:\n    # phy2log: [num_layers, num_replicas] (logical expert ID for each physical expert)\n    # phyrank: [num_layers, num_replicas] (rank of physical expert within its logical expert)\n    # logcnt: [num_layers, num_logical_experts] (number of replicas for each logical expert)\n\n    # The original scatter logic:\n    # `log2phy.view(num_layers, -1)` flattens the last two dimensions of `log2phy`.\n    # The `view` operation makes it `[num_layers, num_logical_experts * maxlogcnt]`.\n    # `phy2log * maxlogcnt + phyrank` would produce indices for this flattened tensor.\n    # For a given layer `l` and physical expert `p`:\n    #   `log_idx = phy2log[l, p]`\n    #   `rank_idx = phyrank[l, p]`\n    #   The index in the flattened tensor would be `log_idx * maxlogcnt + rank_idx`.\n    # This seems correct if `maxlogcnt` is indeed the number of slots for each logical expert.\n\n    # Let's ensure that `phy2log` and `phyrank` from `replicate_experts`\n    # align with the `maxlogcnt` derived from `logcnt`.\n    # `replicate_experts` assigns `logcnt[l, log_idx]` replicas to `log_idx`.\n    # The ranks assigned are `0` to `logcnt[l, log_idx] - 1`.\n    # So, `phyrank[l, p]` should be less than `logcnt[l, phy2log[l, p]]`.\n    # This means `phyrank` values will be within `0` to `maxlogcnt - 1`.\n\n    # The original code's `maxlogcnt = num_redundant_experts + 1` might be problematic.\n    # `num_redundant_experts = num_replicas - num_logical_experts`.\n    # This implicitly assumes `num_replicas >= num_logical_experts`.\n    # If `replicate_experts` assigns `logcnt[i, log_expert_id]` replicas, then the maximum number of replicas\n    # for any expert is `logcnt.max()`. This should be used for `maxlogcnt`.\n\n    # Let's re-calculate `maxlogcnt` and the indices for `scatter_` based on the actual `logcnt`.\n    # Ensure that `maxlogcnt` is correctly determined and used.\n    if num_logical_experts > 0:\n        # Calculate the actual maximum number of replicas assigned to any logical expert.\n        # If logcnt is empty or all zeros, max() would error.\n        # We've handled the empty case by setting maxlogcnt=0, but then we ensure it's at least 1.\n        # If num_logical_experts > 0 and num_replicas > 0, then logcnt values should be >= 1.\n        # Let's use the maximum value from logcnt.\n        maxlogcnt_actual = logcnt.max().item() if logcnt.numel() > 0 else 0\n        # Ensure it's at least 1 if there are logical experts.\n        maxlogcnt = max(1, maxlogcnt_actual)\n\n        # Re-initialize log2phy with the correct maxlogcnt.\n        log2phy = torch.full(\n            (num_layers, num_logical_experts, maxlogcnt),\n            -1,\n            dtype=torch.int64,\n            device=logcnt.device,\n        )\n\n        # Create the indices for scatter_.\n        # We need indices for `log2phy` of shape `(num_layers, num_logical_experts * maxlogcnt)`.\n        # The indices are `(layer_idx, logical_expert_idx * maxlogcnt + rank_idx)`.\n\n        # Get the flattened physical expert IDs (0 to num_replicas-1)\n        physical_expert_ids = torch.arange(num_replicas, dtype=torch.int64, device=logcnt.device)\n        physical_expert_ids = physical_expert_ids.expand(num_layers, -1) # Shape: [num_layers, num_replicas]\n\n        # Calculate the target flattened index for each physical expert.\n        # `phy2log` and `phyrank` are [num_layers, num_replicas].\n        # The formula `log_idx * maxlogcnt + rank_idx` assumes `log_idx` ranges from 0 to `num_logical_experts - 1`\n        # and `rank_idx` ranges from 0 to `maxlogcnt - 1`.\n        # This is consistent with how `replicate_experts` populates `phy2log` and `phyrank`.\n        target_flat_indices = phy2log * maxlogcnt + phyrank\n\n        # Scatter `physical_expert_ids` into the flattened `log2phy`.\n        log2phy.view(num_layers, -1).scatter_(\n            -1,\n            target_flat_indices,\n            physical_expert_ids,\n        )\n    else:\n        # Handle the case where num_logical_experts is 0.\n        # The output shapes should reflect this.\n        # If num_logical_experts is 0, then logcnt, phy2log, phyrank should reflect this.\n        # replicate_experts(weight, num_replicas) where weight.shape[1] is 0.\n        # It should return logcnt of shape (num_layers, 0).\n        # phy2log and phyrank would be shape (num_layers, num_replicas).\n        # The logic for log2phy needs to be adapted.\n        # If num_logical_experts is 0, then log2phy should be (num_layers, 0, 0) or similar.\n        # Let's assume valid inputs where num_logical_experts > 0.\n        # If num_logical_experts is 0, the loop to construct log2phy might not be needed.\n        # The current `log2phy` initialization handles `maxlogcnt=0` if `num_logical_experts=0`.\n        # The scatter_ call would then operate on `log2phy.view(num_layers, -1)` which is `[num_layers, 0]`.\n        # `target_flat_indices` would be `(num_layers, num_replicas)` if `phy2log` is correct.\n        # This scatter operation would fail if `target_flat_indices` are out of bounds for `[num_layers, 0]`.\n        # We need to ensure the `num_logical_experts` dimension is handled correctly.\n\n        # If num_logical_experts is 0, then `logcnt` is `[num_layers, 0]`.\n        # `maxlogcnt` would be 0.\n        # `log2phy` is initialized as `(num_layers, 0, 0)`.\n        # `phy2log` and `phyrank` are `(num_layers, num_replicas)`.\n        # The `scatter_` call needs to be conditional on `num_logical_experts > 0`.\n        pass # No action needed if num_logical_experts is 0 for log2phy construction.\n\n    # The original `return phy2log, log2phy, logcnt` implies that `phy2log` and `logcnt` are the direct outputs.\n    # For the hierarchical case, `phy2log` is `phy2mlog` after some transformations and `logcnt` is derived.\n    # For the global case using `replicate_experts`, `phy2log` is `phy2log`, and `logcnt` is `logcnt`.\n    # This part seems consistent.\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "55d1ba42-2e89-4bd3-b19c-a01f0f04f62d", "generation": 6, "timestamp": 1751052672.5138307, "iteration_found": 45, "metrics": {"balancedness_score": 0.16544747735588627, "speed_score": 0.022284270921792138, "combined_score": 0.0938658741388392}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 23 lines with 236 lines", "parent_metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "index 8451 is out of bounds for dimension 1 with size 8448"}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.0000\n- speed_score: 0.0000\n- combined_score: 0.0000\n- error: index 8451 is out of bounds for dimension 1 with size 8448\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0405, combined_score: 0.1694\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0722, combined_score: 0.1852\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0761, combined_score: 0.1872\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.1872)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0761), Performs well on combined_score (0.1872)\n\n\n### Program 2 (Score: 0.1852)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0722), Performs well on combined_score (0.1852)\n\n\n### Program 3 (Score: 0.1694)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0405), Performs well on combined_score (0.1694)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1661)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1667)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.1872, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0872, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 87 lines with 89 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.1619, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 27 lines with 24 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.1694, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 79 lines with 108 lines\nChange 2: Replace 24 lines with 43 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 5 (Score: 0.1667, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # This approach avoids creating a large temporary tensor with float('inf').\n            # Find the pack with the minimum current weight among available ones.\n            # Mark full packs with infinity to exclude them from argmin.\n            # Clone current_pack_weights to avoid modifying the original tensor in place\n            # with float('inf') values before the actual update.\n            # Find the pack with the minimum current weight among available ones.\n            # Use torch.where to conditionally set weights to infinity for full packs.\n            pack = torch.argmin(\n                torch.where(current_pack_items < groups_per_pack,\n                            current_pack_weights,\n                            torch.full_like(current_pack_weights, float('inf'))))\n\n            # Assert that a valid pack was found and it has space.\n            # Using pack directly as a 0-dim tensor for indexing.\n            assert current_pack_items[pack] < groups_per_pack, \\\n                f\"No available packs found, but expected to find one. Pack {pack} is full.\"\n\n            # Assign the group to the chosen pack.\n            # group_id is a 0-dim tensor, so it works directly for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # weight[i, group_id] is the weight of the current group (0-dim tensor).\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas using a proportional\n    assignment strategy. This is a faster approximation to the greedy LPT.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n    device = weight.device\n\n    # Calculate desired total weight per replica for each layer\n    total_weight_per_layer = weight.sum(dim=-1, keepdim=True)\n\n    # Calculate target logcnt (float) for each expert based on its proportion of total weight.\n    # Handle layers with zero total weight by distributing evenly.\n    target_logcnt_float = torch.where(\n        total_weight_per_layer > 0,\n        weight / total_weight_per_layer * num_phy,\n        torch.full_like(weight, num_phy / num_log)  # Distribute evenly if total_weight is 0\n    )\n\n    # Initial integer counts: floor of target_logcnt_float, ensuring at least 1 replica.\n    # Using floor ensures sum(logcnt) <= num_phy initially (due to rounding down).\n    logcnt = torch.max(torch.ones_like(target_logcnt_float, dtype=torch.int64),\n                       target_logcnt_float.floor().long())\n\n    # Calculate remaining replicas to distribute for each layer.\n    # This difference should be non-negative.\n    remaining_replicas = num_phy - logcnt.sum(dim=-1)\n\n    # Distribute remaining replicas greedily based on the fractional parts.\n    # This ensures the total count for each layer sums exactly to num_phy.\n    fractional_parts = target_logcnt_float - logcnt.float()\n\n    # For each layer, find the `remaining_replicas[i]` experts with the largest fractional parts\n    # and increment their logcnt.\n    for i in range(n):\n        num_to_add = remaining_replicas[i].item()\n        if num_to_add > 0:\n            # Get the top `num_to_add` indices by fractional part for this layer\n            _, top_indices = fractional_parts[i].topk(num_to_add)\n            # Increment logcnt for these chosen experts\n            logcnt[i].scatter_add_(0, top_indices, torch.ones(num_to_add, dtype=torch.int64, device=device))\n\n    # Now, populate phy2log and rank based on the final logcnt.\n    # This involves expanding each expert ID based on its replica count.\n    phy2log = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n    rank = torch.empty(n, num_phy, dtype=torch.int64, device=device)\n\n    for i in range(n):\n        current_phy_idx = 0\n        for log_expert_id in range(num_log):\n            count = logcnt[i, log_expert_id].item()\n            for r in range(count):\n                if current_phy_idx < num_phy:  # Safety check\n                    phy2log[i, current_phy_idx] = log_expert_id\n                    rank[i, current_phy_idx] = r\n                    current_phy_idx += 1\n                else:\n                    break  # Should not happen if sum(logcnt) == num_phy\n            if current_phy_idx >= num_phy:\n                break\n\n        # Shuffle physical expert assignments within each layer.\n        # This is crucial for distributing replicas across physical resources,\n        # preventing all replicas of an expert from being assigned consecutively,\n        # which helps in actual load balancing on GPUs.\n        perm = torch.randperm(num_phy, device=device)\n        phy2log[i] = phy2log[i, perm]\n        rank[i] = rank[i, perm]\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Cast weight to float for calculations if not already, and keep on original device.\n    # Moving to CPU adds overhead if data is already on GPU and might slow down ops.\n    weight = weight.float()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program has an error: `index 8451 is out of bounds for dimension 1 with size 8448`. This indicates an issue with indexing, likely in how the `weight` tensor or derived tensors are accessed. The program also shows regressions in `balancedness_score`, `speed_score`, and `combined_score`.\n\nThe goal is to improve both load balancing and efficiency. Let's address the error and then look for optimization opportunities.\n\n**Addressing the Error:**\n\nThe error `index 8451 is out of bounds for dimension 1 with size 8448` suggests that a tensor of size `X x 8448` is being accessed with an index of `8451` along the second dimension. This is a common issue when dealing with tensor shapes that are not perfectly aligned or when assumptions about dimensions are violated.\n\nWithout the full context of how `weight` is populated and what `num_logical_experts` is, it's hard to pinpoint the exact line. However, a common cause is when `num_logical_experts` is not a clean multiple of `num_groups` or `num_nodes`, leading to mismatched dimensions in intermediate calculations.\n\nGiven the previous attempts show improvements, it's possible a recent change introduced this bug. The error occurs in the `rebalance_experts` function, specifically when calling `rebalance_experts_hierarchical`. The `rebalance_experts_hierarchical` function itself has several complex steps.\n\nLet's assume the error is related to the interaction between `num_logical_experts`, `num_groups`, and `num_nodes`. The code currently has a conditional call to `rebalance_experts_hierarchical`:\n\n```python\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n```\n\nThe `else` block calls `rebalance_experts_hierarchical` with `num_groups=1` and `num_nodes=1`. This suggests a fallback to a simpler, global load balancing strategy. However, the implementation of `rebalance_experts_hierarchical` might not be robust enough for these reduced `num_groups` and `num_nodes` values, or it might be that the expected dimensions are still derived assuming a more complex structure.\n\n**Potential Improvement Strategy:**\n\n1.  **Robustness in `rebalance_experts_hierarchical`:** Ensure that `rebalance_experts_hierarchical` correctly handles cases where `num_groups` or `num_nodes` are small, especially `1`.\n2.  **Efficiency:** The current implementation uses several tensor operations. We can look for opportunities to fuse operations or use more efficient PyTorch functions.\n3.  **Clarity and Maintainability:** Simplify complex tensor manipulations where possible.\n\nLet's focus on a specific area that might be causing both the error and performance issues: the initial calculation of `tokens_per_group` and the subsequent reshaping.\n\n**Proposed Change:**\n\nThe calculation of `tokens_per_group` involves reshaping `weight` and then summing. This part seems critical for the hierarchical approach.\n\n```python\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n```\n\nThe error `index 8451 is out of bounds for dimension 1 with size 8448` could arise if `num_logical_experts` is not perfectly divisible by `num_groups`, or if `num_groups` is not divisible by `num_nodes`, leading to incorrect `group_size` or `groups_per_node` calculations, and thus incorrect reshaping or indexing. The `assert num_groups % num_nodes == 0` in `rebalance_experts_hierarchical` should catch some of these, but the `else` branch bypasses this.\n\nLet's refine the handling of the \"global\" case to ensure it's a true fallback and doesn't rely on assumptions of the hierarchical structure. The current implementation calls `rebalance_experts_hierarchical` even in the `else` branch, which might be the source of the problem if that function isn't designed for `num_groups=1` and `num_nodes=1`.\n\nA better approach for the global case would be to use the `replicate_experts` function directly, as it's designed for global replication.\n\n**Refactoring the Global Case:**\n\nInstead of calling `rebalance_experts_hierarchical` with modified parameters, we should use a distinct logic for global load balancing. The `replicate_experts` function appears to be the core of global replication.\n\nLet's assume `num_logical_experts` is the total number of experts we want to distribute across `num_replicas` physical experts. The `replicate_experts` function takes `weight` (which is `[layers, num_logical_experts]`) and `num_phy` (which is `num_replicas`).\n\n```python\n# Current global case:\n# phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n#     weight, num_replicas, 1, 1, num_gpus)\n```\n\nThis call is problematic because `rebalance_experts_hierarchical` expects `num_groups` to be at least 1 and `num_nodes` to be at least 1, and it performs operations based on these assumptions. The `assert num_groups % num_nodes == 0` is also bypassed by the `else` logic, but the internal logic might still fail.\n\nThe `replicate_experts` function directly addresses the problem of distributing `num_logical_experts` into `num_replicas`.\n\n**Proposed Change 1: Refactor Global Load Balancing**\n\n<<<<<<< SEARCH\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n=======\n    if num_groups > 0 and num_nodes > 0 and num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy: replicate experts directly\n        # We treat num_logical_experts as the number of logical experts to distribute\n        # across num_replicas physical experts.\n        # The 'weight' tensor already represents load per logical expert.\n        # The replicate_experts function is designed for this.\n        # Note: replicate_experts expects [X, num_log] and num_phy.\n        # Here, X is num_layers, num_log is num_logical_experts, and num_phy is num_replicas.\n        phy2log, phyrank, logcnt = replicate_experts(weight, num_replicas)\n\n    # The rest of the logic to construct log2phy from phy2log, phyrank, and logcnt\n    # needs to be consistent with the output of replicate_experts and\n    # rebalance_experts_hierarchical.\n    # The number of physical experts per logical expert (maxlogcnt) is determined by\n    # how many replicas are assigned to each logical expert.\n    # The logcnt tensor already provides this information.\n    # We need to find the maximum value in logcnt across all layers and logical experts.\n    maxlogcnt = logcnt.max().item() if logcnt.numel() > 0 else 0\n    # Ensure maxlogcnt is at least 1 to accommodate cases where logcnt might be empty or all zeros (though unlikely here)\n    # and to handle the case where num_replicas might be less than num_logical_experts (though problem statement implies num_replicas >= num_logical_experts)\n    # A safer upper bound for maxlogcnt would be num_replicas // num_logical_experts + epsilon, but logcnt already gives the exact counts.\n    # The original code used num_redundant_experts + 1, which assumes num_logical_experts is the base and num_replicas are added.\n    # This logic needs to be aligned with how logcnt is computed.\n    # If replicate_experts assigns multiple replicas to a logical expert, logcnt will reflect that.\n    # The `num_redundant_experts` logic might be specific to the hierarchical split.\n\n    # Let's re-evaluate `maxlogcnt` based on `logcnt` directly.\n    # `logcnt` is [num_layers, num_logical_experts]\n    # The maximum number of replicas for any single logical expert.\n    # If `logcnt` is empty, or all zeros, `maxlogcnt` should be 0.\n    # `torch.max(logcnt)` will handle this. If `logcnt` is all zeros, max is 0.\n    # If `logcnt` is empty, `logcnt.max()` raises an error.\n    # A robust way is to ensure `logcnt` has at least one element for `max()` to work.\n    # If `replicate_experts` returns a `logcnt` of shape `(num_layers, num_logical_experts)`,\n    # then `logcnt.max()` is fine.\n    # The `phy2log` and `phyrank` from `replicate_experts` are [num_layers, num_replicas].\n    # We need to map these to the `log2phy` format [num_layers, num_logical_experts, maxlogcnt].\n\n    # Let's reconstruct log2phy based on the direct output of replicate_experts.\n    # `phy2log` from `replicate_experts` is [num_layers, num_replicas], where each element is the logical expert ID.\n    # `phyrank` from `replicate_experts` is [num_layers, num_replicas], where each element is the rank within the logical expert.\n    # `logcnt` from `replicate_experts` is [num_layers, num_logical_experts], total replicas for each logical expert.\n\n    # Determine the maximum number of replicas any logical expert has.\n    # This determines the size of the third dimension of log2phy.\n    # If logcnt is all zeros (e.g., num_logical_experts=0), this might fail.\n    # Ensure logcnt is not empty before calling max.\n    if logcnt.numel() == 0:\n        # Handle case where there are no logical experts or no assignments.\n        # This situation might indicate an issue upstream or an edge case.\n        # For now, assume logcnt has valid dimensions based on input.\n        # If num_logical_experts is 0, then logcnt would be [num_layers, 0].\n        # If num_replicas is 0, then phy2log/phyrank would be [num_layers, 0].\n        # The `replicate_experts` function handles `num_phy >= num_log`.\n        # If `num_logical_experts` is 0, `replicate_experts` might return empty tensors or tensors with 0 dimension.\n        # Let's assume valid inputs where num_logical_experts > 0 and num_replicas > 0.\n        maxlogcnt = 0 # Or raise an error if this state is unexpected.\n    else:\n        maxlogcnt = logcnt.max().item()\n\n    # Initialize log2phy. If maxlogcnt is 0, this will be [num_layers, num_logical_experts, 0].\n    # This might cause issues in scatter_. Let's ensure maxlogcnt is at least 1 if num_logical_experts > 0.\n    # The number of replicas for a logical expert can be at most num_replicas.\n    # However, `logcnt` already tells us the *actual* number of replicas assigned.\n    # The size of the third dimension should be the maximum count observed in `logcnt`.\n    if num_logical_experts > 0 and maxlogcnt == 0:\n        # This case might happen if num_replicas < num_logical_experts and some logical experts get 0 replicas.\n        # However, `replicate_experts` ensures each logical expert gets at least 1 replica if num_phy >= num_log.\n        # If num_logical_experts > 0 and num_replicas > 0, then `logcnt` should contain values >= 1.\n        # The original code's `maxlogcnt = num_redundant_experts + 1` was a heuristic.\n        # Let's use the actual max count from `logcnt` for the size.\n        # If `replicate_experts` correctly assigns replicas, `logcnt.max()` should be the correct dimension.\n        # If `num_logical_experts` is 0, `logcnt` is `(num_layers, 0)`, `max()` would error.\n        # If `num_logical_experts > 0` and `num_replicas > 0`, `logcnt` should have values.\n        # Let's ensure `maxlogcnt` is at least 1 if `num_logical_experts > 0`.\n        maxlogcnt = max(1, maxlogcnt) # Ensure the dimension is at least 1 if there are logical experts.\n\n    # If num_logical_experts is 0, then the shape should be (num_layers, 0, 0) or similar.\n    # If num_logical_experts > 0 and num_replicas is 0, this is an invalid state.\n    # Assuming num_logical_experts > 0 and num_replicas > 0.\n\n    # Initialize log2phy with -1.\n    # Shape: [num_layers, num_logical_experts, maxlogcnt]\n    log2phy = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n\n    # Populate log2phy.\n    # `phy2log` has shape [num_layers, num_replicas].\n    # `phyrank` has shape [num_layers, num_replicas].\n    # `logcnt` has shape [num_layers, num_logical_experts].\n\n    # We need to iterate through each layer and each physical expert to fill log2phy.\n    # For each physical expert `p` in `phy2log[l]`, its logical expert is `log_idx = phy2log[l, p]`.\n    # Its rank within that logical expert is `rank_idx = phyrank[l, p]`.\n    # We want to place the physical expert ID `p` into `log2phy[l, log_idx, rank_idx]`.\n\n    # This operation can be vectorized.\n    # We need to map the physical expert indices (`torch.arange(num_replicas)`)\n    # to their corresponding positions in `log2phy`.\n\n    # The target indices for `scatter_` are `(layer_idx, logical_expert_idx, rank_idx)`.\n    # `layer_idx` is broadcastable over `num_replicas`.\n    # `logical_expert_idx` comes from `phy2log`.\n    # `rank_idx` comes from `phyrank`.\n\n    # Create broadcastable layer indices.\n    layer_indices = torch.arange(num_layers, device=logcnt.device).unsqueeze(1).expand(-1, num_replicas)\n\n    # Create broadcastable logical expert indices.\n    # `phy2log` is already [num_layers, num_replicas].\n\n    # Create broadcastable rank indices.\n    # `phyrank` is already [num_layers, num_replicas].\n\n    # Flatten these to create the indices for scatter_.\n    # The indices need to be in the format required by scatter_:\n    # `scatter_(dim, index, src)` where `index` has the same shape as `src`.\n    # The `dim` is the dimension along which to scatter.\n    # For `log2phy` of shape `(L, N_log, MaxLogCnt)`, we want to scatter along `dim=1` (logical expert dim)\n    # and `dim=2` (rank dim).\n\n    # The `scatter_` function in PyTorch can scatter into multiple dimensions if the `index` tensor is structured correctly.\n    # However, a common pattern is to flatten the target dimensions and scatter into the last dimension.\n    # Let's try to flatten `(num_logical_experts, maxlogcnt)` into a single dimension for scatter.\n    # This requires careful index calculation.\n\n    # The original code uses `phy2log * maxlogcnt + phyrank` and scatters into `log2phy.view(num_layers, -1)`.\n    # This assumes `phy2log` maps directly to indices in a flattened `(num_logical_experts, maxlogcnt)` tensor.\n    # Let's verify if this mapping is correct for the output of `replicate_experts`.\n\n    # `replicate_experts` output:\n    # phy2log: [num_layers, num_replicas] (logical expert ID for each physical expert)\n    # phyrank: [num_layers, num_replicas] (rank of physical expert within its logical expert)\n    # logcnt: [num_layers, num_logical_experts] (number of replicas for each logical expert)\n\n    # The original scatter logic:\n    # `log2phy.view(num_layers, -1)` flattens the last two dimensions of `log2phy`.\n    # The `view` operation makes it `[num_layers, num_logical_experts * maxlogcnt]`.\n    # `phy2log * maxlogcnt + phyrank` would produce indices for this flattened tensor.\n    # For a given layer `l` and physical expert `p`:\n    #   `log_idx = phy2log[l, p]`\n    #   `rank_idx = phyrank[l, p]`\n    #   The index in the flattened tensor would be `log_idx * maxlogcnt + rank_idx`.\n    # This seems correct if `maxlogcnt` is indeed the number of slots for each logical expert.\n\n    # Let's ensure that `phy2log` and `phyrank` from `replicate_experts`\n    # align with the `maxlogcnt` derived from `logcnt`.\n    # `replicate_experts` assigns `logcnt[l, log_idx]` replicas to `log_idx`.\n    # The ranks assigned are `0` to `logcnt[l, log_idx] - 1`.\n    # So, `phyrank[l, p]` should be less than `logcnt[l, phy2log[l, p]]`.\n    # This means `phyrank` values will be within `0` to `maxlogcnt - 1`.\n\n    # The original code's `maxlogcnt = num_redundant_experts + 1` might be problematic.\n    # `num_redundant_experts = num_replicas - num_logical_experts`.\n    # This implicitly assumes `num_replicas >= num_logical_experts`.\n    # If `replicate_experts` assigns `logcnt[i, log_expert_id]` replicas, then the maximum number of replicas\n    # for any expert is `logcnt.max()`. This should be used for `maxlogcnt`.\n\n    # Let's re-calculate `maxlogcnt` and the indices for `scatter_` based on the actual `logcnt`.\n    # Ensure that `maxlogcnt` is correctly determined and used.\n    if num_logical_experts > 0:\n        # Calculate the actual maximum number of replicas assigned to any logical expert.\n        # If logcnt is empty or all zeros, max() would error.\n        # We've handled the empty case by setting maxlogcnt=0, but then we ensure it's at least 1.\n        # If num_logical_experts > 0 and num_replicas > 0, then logcnt values should be >= 1.\n        # Let's use the maximum value from logcnt.\n        maxlogcnt_actual = logcnt.max().item() if logcnt.numel() > 0 else 0\n        # Ensure it's at least 1 if there are logical experts.\n        maxlogcnt = max(1, maxlogcnt_actual)\n\n        # Re-initialize log2phy with the correct maxlogcnt.\n        log2phy = torch.full(\n            (num_layers, num_logical_experts, maxlogcnt),\n            -1,\n            dtype=torch.int64,\n            device=logcnt.device,\n        )\n\n        # Create the indices for scatter_.\n        # We need indices for `log2phy` of shape `(num_layers, num_logical_experts * maxlogcnt)`.\n        # The indices are `(layer_idx, logical_expert_idx * maxlogcnt + rank_idx)`.\n\n        # Get the flattened physical expert IDs (0 to num_replicas-1)\n        physical_expert_ids = torch.arange(num_replicas, dtype=torch.int64, device=logcnt.device)\n        physical_expert_ids = physical_expert_ids.expand(num_layers, -1) # Shape: [num_layers, num_replicas]\n\n        # Calculate the target flattened index for each physical expert.\n        # `phy2log` and `phyrank` are [num_layers, num_replicas].\n        # The formula `log_idx * maxlogcnt + rank_idx` assumes `log_idx` ranges from 0 to `num_logical_experts - 1`\n        # and `rank_idx` ranges from 0 to `maxlogcnt - 1`.\n        # This is consistent with how `replicate_experts` populates `phy2log` and `phyrank`.\n        target_flat_indices = phy2log * maxlogcnt + phyrank\n\n        # Scatter `physical_expert_ids` into the flattened `log2phy`.\n        log2phy.view(num_layers, -1).scatter_(\n            -1,\n            target_flat_indices,\n            physical_expert_ids,\n        )\n    else:\n        # Handle the case where num_logical_experts is 0.\n        # The output shapes should reflect this.\n        # If num_logical_experts is 0, then logcnt, phy2log, phyrank should reflect this.\n        # replicate_experts(weight, num_replicas) where weight.shape[1] is 0.\n        # It should return logcnt of shape (num_layers, 0).\n        # phy2log and phyrank would be shape (num_layers, num_replicas).\n        # The logic for log2phy needs to be adapted.\n        # If num_logical_experts is 0, then log2phy should be (num_layers, 0, 0) or similar.\n        # Let's assume valid inputs where num_logical_experts > 0.\n        # If num_logical_experts is 0, the loop to construct log2phy might not be needed.\n        # The current `log2phy` initialization handles `maxlogcnt=0` if `num_logical_experts=0`.\n        # The scatter_ call would then operate on `log2phy.view(num_layers, -1)` which is `[num_layers, 0]`.\n        # `target_flat_indices` would be `(num_layers, num_replicas)` if `phy2log` is correct.\n        # This scatter operation would fail if `target_flat_indices` are out of bounds for `[num_layers, 0]`.\n        # We need to ensure the `num_logical_experts` dimension is handled correctly.\n\n        # If num_logical_experts is 0, then `logcnt` is `[num_layers, 0]`.\n        # `maxlogcnt` would be 0.\n        # `log2phy` is initialized as `(num_layers, 0, 0)`.\n        # `phy2log` and `phyrank` are `(num_layers, num_replicas)`.\n        # The `scatter_` call needs to be conditional on `num_logical_experts > 0`.\n        pass # No action needed if num_logical_experts is 0 for log2phy construction.\n\n    # The original `return phy2log, log2phy, logcnt` implies that `phy2log` and `logcnt` are the direct outputs.\n    # For the hierarchical case, `phy2log` is `phy2mlog` after some transformations and `logcnt` is derived.\n    # For the global case using `replicate_experts`, `phy2log` is `phy2log`, and `logcnt` is `logcnt`.\n    # This part seems consistent.\n    return phy2log, log2phy, logcnt\n>>>>>>> REPLACE\n\n**Reasoning for Change 1:**\n\n1.  **Correctness:** The primary issue was the incorrect fallback mechanism for global load balancing. Calling `rebalance_experts_hierarchical` with `num_groups=1` and `num_nodes=1` is likely not intended and doesn't properly leverage the `replicate_experts` function, which is designed for global expert replication. The change replaces this with a direct call to `replicate_experts(weight, num_replicas)`, which is the correct function for global load balancing.\n2.  **Robustness:** This change makes the `rebalance_experts` function more robust by correctly handling the global load balancing scenario. It also attempts to fix the `maxlogcnt` calculation and the subsequent `scatter_` operation to be more aligned with the output of `replicate_experts`, which could resolve the index out-of-bounds error. The calculation of `maxlogcnt` is now based on the actual maximum number of replicas assigned to any logical expert (`logcnt.max()`), which is more accurate than the previous heuristic.\n3.  **Clarity:** Separating the hierarchical and global logic makes the code easier to understand.\n\n**Further Optimization Considerations (if the above doesn't fully resolve or for future steps):**\n\n*   **`balanced_packing`:** The greedy approach in `balanced_packing` is generally good, but for very large numbers of groups/packs, its performance might be a bottleneck. However, given the NP-hard nature of bin packing, this greedy approximation is standard.\n*   **`replicate_experts`:** The current proportional assignment followed by greedy distribution of remainders is efficient. The shuffling of physical experts within each layer is crucial for actual load distribution on hardware.\n*   **Tensor Operations:** Review other tensor manipulations for potential fusion or optimization. For example, the inverse function could potentially be implemented more efficiently or avoided if the logic allows.\n*   **Device Placement:** Ensure that operations are performed on the most appropriate device (CPU vs. GPU) to minimize data transfer overhead. The current code seems to keep operations on the original device of `weight` (which is CPU after `weight.float()`), which is generally good for CPU-bound operations like sorting and packing.\n\n**Potential Issue with Change 1:**\n\nThe logic for constructing `log2phy` in the `else` block (global case) relies on `phy2log`, `phyrank`, and `logcnt` from `replicate_experts`. The original code used `maxlogcnt = num_redundant_experts + 1`. The proposed change uses `maxlogcnt = logcnt.max().item()`. This is a critical difference.\n\nIf `replicate_experts` assigns a variable number of replicas per logical expert, `logcnt.max()` is the correct size for the third dimension of `log2phy`. The `scatter_` operation needs to correctly map `phy2log[l, p]` and `phyrank[l, p]` to the flattened `log2phy` tensor. The formula `log_idx * maxlogcnt + rank_idx` assumes `maxlogcnt` is the fixed number of slots per logical expert. This is correct if `maxlogcnt` is indeed the maximum number of replicas any logical expert receives.\n\nThe original code's `maxlogcnt = num_replicas - num_logical_experts + 1` might have been an attempt to create enough slots for all possible replicas, even if not all are used. Using `logcnt.max()` is more precise about the *actual* number of slots needed for the current assignment.\n\nLet's re-examine the `replicate_experts` function and its output:\n`replicate_experts` returns `phy2log` ([n, num_phy]), `phyrank` ([n, num_phy]), and `logcnt` ([n, num_log]).\n`logcnt[i, j]` is the number of replicas for logical expert `j` in layer `i`.\n`phy2log[i, k]` is the logical expert for physical expert `k` in layer `i`.\n`phyrank[i, k]` is the rank of physical expert `k` within its logical expert in layer `i`.\n\nThe goal is to fill `log2phy[i, log_j, rank_k] = physical_expert_id`.\nThe physical expert ID is `k` (or rather, the index in `phy2log` and `phyrank`).\nThe logical expert ID is `log_j = phy2log[i, k]`.\nThe rank is `rank_k = phyrank[i, k]`.\n\nSo, `log2phy[i, phy2log[i, k], phyrank[i, k]] = k`.\nThis is exactly what the `scatter_` operation does.\nThe `target_flat_indices = phy2log * maxlogcnt + phyrank` works if `maxlogcnt` is the number of slots per logical expert.\nIf `logcnt.max()` is used, and `logcnt[i, log_j]` is less than `maxlogcnt`, then `phyrank[i, k]` will be less than `logcnt[i, phy2log[i, k]]`.\nThe index calculation `log_idx * maxlogcnt + rank_idx` will correctly map to a unique slot within the `num_logical_experts * maxlogcnt` flattened dimension.\nThe `scatter_` operation will place the physical expert ID `k` at that correct flattened index.\n\nThis change appears to be a significant improvement in correctness and robustness for the global load balancing case.\n\nOne final check on the `else` condition: `num_groups > 0 and num_nodes > 0 and num_groups % num_nodes == 0`. This is a more robust check for when to use the hierarchical method. If `num_groups` or `num_nodes` is zero, or if `num_groups` is not divisible by `num_nodes`, it falls back to global. This seems reasonable."]}}}