{"id": "940e5990-7d6c-4e87-98f4-ff1bf0b98ede", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n# Helper function for inverse permutation, moved outside for reusability\ndef _inverse_permutation(perm: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Computes the inverse of a permutation tensor.\n\n    Parameters:\n        perm: [X, N], a permutation tensor where perm[i, j] is the new index\n              of the element originally at index j for row i.\n\n    Returns:\n        inv: [X, N], the inverse permutation tensor where inv[i, j] is the\n             original index of the element now at index j for row i.\n    \"\"\"\n    inv = torch.empty_like(perm)\n    inv.scatter_(\n        1,\n        perm,\n        torch.arange(perm.size(1), dtype=torch.int64,\n                     device=perm.device).expand(perm.shape),\n    )\n    return inv\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-create the infinity tensor once for efficiency to avoid repeated torch.tensor() calls.\n    inf_tensor = torch.tensor(float('inf'), dtype=weight.dtype, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # Get current state for this layer's packs as views.\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # For each layer, process groups in sorted order of their weights.\n        for group_id_tensor in indices[i]:\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of full packs to infinity to exclude them from argmin.\n            pack_idx_tensor = torch.argmin(\n                torch.where(current_pack_items == groups_per_pack,\n                            inf_tensor, # Use pre-created tensor\n                            current_pack_weights))\n\n            assert current_pack_items[pack_idx_tensor] < groups_per_pack\n\n            # Assign the group to the chosen pack using tensor indexing.\n            pack_index[i, group_id_tensor] = pack_idx_tensor\n            rank_in_pack[i, group_id_tensor] = current_pack_items[pack_idx_tensor]\n\n            # Update pack weights and item counts for the chosen pack using tensor indexing.\n            pack_weights_per_layer[i, pack_idx_tensor] += weight[i, group_id_tensor]\n            pack_items_per_layer[i, pack_idx_tensor] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = _inverse_permutation(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = _inverse_permutation(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Ensure weight is float and on CPU, avoiding redundant conversions\n    if weight.dtype != torch.float or weight.device.type != 'cpu':\n        weight = weight.float().cpu()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log_final, phyrank_final, logcnt_final = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # Use a direct global load-balance policy.\n        # This path is taken when hierarchical grouping is not applicable,\n        # providing a simpler, flat balancing strategy.\n        assert num_replicas % num_gpus == 0\n        phy_experts_per_gpu = num_replicas // num_gpus\n\n        # Step 1: Replicate logical experts to achieve target physical expert counts.\n        # This determines the count of each logical expert and their initial assignment.\n        phy2log_temp, phyrank_temp, logcnt_final = replicate_experts(weight, num_replicas)\n\n        # Step 2: Calculate the effective load for each physical expert.\n        # This is the original logical expert load divided by its replica count,\n        # then mapped to the physical expert IDs.\n        tokens_per_phy = (weight / logcnt_final).gather(-1, phy2log_temp)\n\n        # Step 3: Pack these physical experts (tokens_per_phy) onto GPUs.\n        # This assigns a GPU index (pack_index) and a rank within that GPU (rank_in_pack)\n        # for each physical expert, aiming for balanced GPU loads.\n        pack_index, rank_in_pack = balanced_packing(tokens_per_phy, num_gpus)\n\n        # Step 4: Reorder physical_to_logical_map and phyrank based on GPU packing.\n        # The `pack_index` and `rank_in_pack` define the final ordering of physical experts.\n        # We need to create a permutation that maps the *new* physical expert indices (0 to num_replicas-1,\n        # ordered by GPU and rank within GPU) back to their *original* indices from `replicate_experts`.\n        # `phy_expert_packed_order_indices` maps original `phy_idx` to new `packed_phy_idx`.\n        phy_expert_packed_order_indices = pack_index * phy_experts_per_gpu + rank_in_pack\n        \n        # Get the inverse permutation: maps new `packed_phy_idx` back to original `phy_idx`.\n        original_phy_indices = _inverse_permutation(phy_expert_packed_order_indices)\n\n        # Apply the inverse permutation to get the final physical_to_logical_map and phyrank\n        # in the new GPU-packed order.\n        phy2log_final = phy2log_temp.gather(-1, original_phy_indices)\n        phyrank_final = phyrank_temp.gather(-1, original_phy_indices)\n        \n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt_final.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log_final * maxlogcnt + phyrank_final,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log_final, log2phy, logcnt_final\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "c9e91222-40eb-4244-81f0-617ade789d86", "generation": 7, "timestamp": 1751061997.5130386, "iteration_found": 190, "metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.02900564014602172, "combined_score": 0.16365699583870574}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 247 lines with 284 lines", "parent_metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.026602747974471267, "combined_score": 0.1624555497529305}, "island": 4}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.2983\n- speed_score: 0.0266\n- combined_score: 0.1625\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0857, combined_score: 0.1920\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1097, combined_score: 0.2312\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n### Program 2 (Score: 0.2312)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1097), Performs well on combined_score (0.2312)\n\n\n### Program 3 (Score: 0.1920)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0857), Performs well on combined_score (0.1920)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1909)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1914)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.2315, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 32 lines with 32 lines, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.1920, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 3 (Score: 0.1920, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 4 (Score: 0.1920, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 5 (Score: 0.1613, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 4 lines with 4 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # Get current state for this layer's packs as views.\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id_tensor in indices[i]:\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of full packs to infinity to exclude them from argmin.\n            # The result 'pack_idx_tensor' will be a 0-dim tensor (scalar tensor).\n            pack_idx_tensor = torch.argmin(\n                torch.where(current_pack_items == groups_per_pack,\n                            torch.tensor(float('inf'), dtype=weight.dtype, device=weight.device),\n                            current_pack_weights))\n\n            # Assert that a valid pack was found and it has space.\n            # Use tensor indexing directly, avoiding .item() call.\n            assert current_pack_items[pack_idx_tensor] < groups_per_pack\n\n            # Assign the group to the chosen pack using tensor indexing.\n            # group_id_tensor is a 0-dim tensor, pack_idx_tensor is a 0-dim tensor.\n            pack_index[i, group_id_tensor] = pack_idx_tensor\n            rank_in_pack[i, group_id_tensor] = current_pack_items[pack_idx_tensor]\n\n            # Update pack weights and item counts for the chosen pack using tensor indexing.\n            pack_weights_per_layer[i, pack_idx_tensor] += weight[i, group_id_tensor]\n            pack_items_per_layer[i, pack_idx_tensor] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Ensure weight is float and on CPU, avoiding redundant conversions\n    if weight.dtype != torch.float or weight.device.type != 'cpu':\n        weight = weight.float().cpu()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program shows a regression in both `balancedness_score` and `speed_score` compared to previous top-performing versions. This suggests issues with both the load balancing efficacy and the algorithm's execution speed.\n\nThe analysis points to two main areas for improvement:\n\n1.  **Balancedness Score Regression**: The `rebalance_experts` function uses a hierarchical load-balancing policy if `num_groups` is a multiple of `num_nodes`. Otherwise, it falls back to a \"global\" policy by calling `rebalance_experts_hierarchical` with `num_groups=1` and `num_nodes=1`. This \"global\" fallback might be less effective for load balancing than a more direct, explicit global policy, or it might introduce subtle inefficiencies by forcing a hierarchical function to operate in a flattened mode. A dedicated and explicit global policy is likely to be more robust and potentially yield better balancedness when the hierarchical conditions are not met.\n\n2.  **Speed Score Regression**: The `balanced_packing` function, particularly within its main loop, repeatedly calls `torch.tensor(float('inf'), ...)` inside a nested loop. This creates a new scalar tensor object in each iteration, leading to Python overhead and unnecessary object creation. Pre-creating this tensor once outside the loop can significantly reduce this overhead.\n\nAdditionally, the `_inverse` helper function is defined inside `rebalance_experts_hierarchical`, limiting its scope. Moving it to a global helper function allows for its reuse, improving code organization and potentially slightly reducing overhead if the interpreter needs to re-evaluate its definition.\n\n### Proposed Changes:\n\n1.  **Optimize `balanced_packing` for Speed**: Pre-create the `inf_tensor` outside the main loop in `balanced_packing` to avoid repeated tensor creation.\n2.  **Implement a Direct Global Policy for Balancedness**: Replace the implicit \"global\" fallback in `rebalance_experts` (i.e., `rebalance_experts_hierarchical(..., 1, 1, ...)`) with a direct and explicit implementation of a global load balancing strategy. This involves directly calling `replicate_experts` and `balanced_packing` in sequence, avoiding the overhead and potential sub-optimality of coercing the hierarchical function into a global role. This change aims to improve `balancedness_score`.\n3.  **Refactor `_inverse` to a Global Helper**: Move the `_inverse` helper function out of `rebalance_experts_hierarchical` to make it a module-level helper, improving code structure and reusability. Rename it to `_inverse_permutation` for clarity.\n\nThese changes are designed to directly address the identified performance regressions in both balancedness and speed.\n\n---\n\n```python\n<<<<<<< SEARCH\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These tensors are on the same device as 'weight' (which is CPU).\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # Get current state for this layer's packs as views.\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id_tensor in indices[i]:\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of full packs to infinity to exclude them from argmin.\n            # The result 'pack_idx_tensor' will be a 0-dim tensor (scalar tensor).\n            pack_idx_tensor = torch.argmin(\n                torch.where(current_pack_items == groups_per_pack,\n                            torch.tensor(float('inf'), dtype=weight.dtype, device=weight.device),\n                            current_pack_weights))\n\n            # Assert that a valid pack was found and it has space.\n            # Use tensor indexing directly, avoiding .item() call.\n            assert current_pack_items[pack_idx_tensor] < groups_per_pack\n\n            # Assign the group to the chosen pack using tensor indexing.\n            # group_id_tensor is a 0-dim tensor, pack_idx_tensor is a 0-dim tensor.\n            pack_index[i, group_id_tensor] = pack_idx_tensor\n            rank_in_pack[i, group_id_tensor] = current_pack_items[pack_idx_tensor]\n\n            # Update pack weights and item counts for the chosen pack using tensor indexing.\n            pack_weights_per_layer[i, pack_idx_tensor] += weight[i, group_id_tensor]\n            pack_items_per_layer[i, pack_idx_tensor] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Ensure weight is float and on CPU, avoiding redundant conversions\n    if weight.dtype != torch.float or weight.device.type != 'cpu':\n        weight = weight.float().cpu()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n=======\nimport torch\n\n# Helper function for inverse permutation, moved outside for reusability\ndef _inverse_permutation(perm: torch.Tensor) -> torch.Tensor:\n    \"\"\"\n    Computes the inverse of a permutation tensor.\n\n    Parameters:\n        perm: [X, N], a permutation tensor where perm[i, j] is the new index\n              of the element originally at index j for row i.\n\n    Returns:\n        inv: [X, N], the inverse permutation tensor where inv[i, j] is the\n             original index of the element now at index j for row i.\n    \"\"\"\n    inv = torch.empty_like(perm)\n    inv.scatter_(\n        1,\n        perm,\n        torch.arange(perm.size(1), dtype=torch.int64,\n                     device=perm.device).expand(perm.shape),\n    )\n    return inv\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Initialize tensors to hold pack weights and item counts for all layers.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-create the infinity tensor once for efficiency to avoid repeated torch.tensor() calls.\n    inf_tensor = torch.tensor(float('inf'), dtype=weight.dtype, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # Get current state for this layer's packs as views.\n        current_pack_weights = pack_weights_per_layer[i]\n        current_pack_items = pack_items_per_layer[i]\n\n        # For each layer, process groups in sorted order of their weights.\n        for group_id_tensor in indices[i]:\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of full packs to infinity to exclude them from argmin.\n            pack_idx_tensor = torch.argmin(\n                torch.where(current_pack_items == groups_per_pack,\n                            inf_tensor, # Use pre-created tensor\n                            current_pack_weights))\n\n            assert current_pack_items[pack_idx_tensor] < groups_per_pack\n\n            # Assign the group to the chosen pack using tensor indexing.\n            pack_index[i, group_id_tensor] = pack_idx_tensor\n            rank_in_pack[i, group_id_tensor] = current_pack_items[pack_idx_tensor]\n\n            # Update pack weights and item counts for the chosen pack using tensor indexing.\n            pack_weights_per_layer[i, pack_idx_tensor] += weight[i, group_id_tensor]\n            pack_items_per_layer[i, pack_idx_tensor] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = _inverse_permutation(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = _inverse_permutation(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    # Ensure weight is float and on CPU, avoiding redundant conversions\n    if weight.dtype != torch.float or weight.device.type != 'cpu':\n        weight = weight.float().cpu()\n    \n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log_final, phyrank_final, logcnt_final = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # Use a direct global load-balance policy.\n        # This path is taken when hierarchical grouping is not applicable,\n        # providing a simpler, flat balancing strategy.\n        assert num_replicas % num_gpus == 0\n        phy_experts_per_gpu = num_replicas // num_gpus\n\n        # Step 1: Replicate logical experts to achieve target physical expert counts.\n        # This determines the count of each logical expert and their initial assignment.\n        phy2log_temp, phyrank_temp, logcnt_final = replicate_experts(weight, num_replicas)\n\n        # Step 2: Calculate the effective load for each physical expert.\n        # This is the original logical expert load divided by its replica count,\n        # then mapped to the physical expert IDs.\n        tokens_per_phy = (weight / logcnt_final).gather(-1, phy2log_temp)\n\n        # Step 3: Pack these physical experts (tokens_per_phy) onto GPUs.\n        # This assigns a GPU index (pack_index) and a rank within that GPU (rank_in_pack)\n        # for each physical expert, aiming for balanced GPU loads.\n        pack_index, rank_in_pack = balanced_packing(tokens_per_phy, num_gpus)\n\n        # Step 4: Reorder physical_to_logical_map and phyrank based on GPU packing.\n        # The `pack_index` and `rank_in_pack` define the final ordering of physical experts.\n        # We need to create a permutation that maps the *new* physical expert indices (0 to num_replicas-1,\n        # ordered by GPU and rank within GPU) back to their *original* indices from `replicate_experts`.\n        # `phy_expert_packed_order_indices` maps original `phy_idx` to new `packed_phy_idx`.\n        phy_expert_packed_order_indices = pack_index * phy_experts_per_gpu + rank_in_pack\n        \n        # Get the inverse permutation: maps new `packed_phy_idx` back to original `phy_idx`.\n        original_phy_indices = _inverse_permutation(phy_expert_packed_order_indices)\n\n        # Apply the inverse permutation to get the final physical_to_logical_map and phyrank\n        # in the new GPU-packed order.\n        phy2log_final = phy2log_temp.gather(-1, original_phy_indices)\n        phyrank_final = phyrank_temp.gather(-1, original_phy_indices)\n        \n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt_final.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log_final * maxlogcnt + phyrank_final,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log_final, log2phy, logcnt_final\n>>>>>>> REPLACE\n```"]}}}