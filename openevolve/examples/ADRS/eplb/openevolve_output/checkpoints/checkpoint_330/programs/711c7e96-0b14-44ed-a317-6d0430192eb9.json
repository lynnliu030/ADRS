{"id": "711c7e96-0b14-44ed-a317-6d0430192eb9", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These are on CPU because the input 'weight' is moved to CPU in rebalance_experts.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of unavailable packs to infinity to exclude them from argmin.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n            \n            # Use torch.argmin to find the index of the pack with the minimum weight.\n            # .item() converts the 0-dim tensor result to a Python scalar.\n            pack = torch.argmin(candidate_weights).item()\n\n            # Assert that a valid pack was found and it has space.\n            assert current_pack_items[pack] < groups_per_pack\n\n            # Assign the group to the chosen pack.\n            # `group_id` is a 0-dim tensor, which can be directly used for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # `weight[i, group_id]` is the weight of the current group.\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        # To minimize the maximum load, we should add replicas to the\n        # logical experts with the minimum current average load.\n        # The original code used .max(dim=-1).indices, which seems incorrect for load balancing.\n        # We replace it with .argmin() to select the least loaded expert.\n        redundant_indices = (weight / logcnt).argmin(dim=-1)\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "6ab778e4-b4f5-4b0f-8daf-f927d0185bed", "generation": 2, "timestamp": 1751049834.428225, "iteration_found": 4, "metrics": {"balancedness_score": 0.14515957884623945, "speed_score": 0.022060352271930185, "combined_score": 0.08360996555908481}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 12 lines with 19 lines\nChange 2: Replace 12 lines with 19 lines\nChange 3: Replace 5 lines with 9 lines\nChange 4: Replace 12 lines with 19 lines\nChange 5: Replace 12 lines with 19 lines", "parent_metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.02363647697015292, "combined_score": 0.16097241425077133}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.2983\n- speed_score: 0.0236\n- combined_score: 0.1610\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.0000, speed_score: 0.0000, combined_score: 0.0000, error: 'builtin_function_or_method' object has no attribute 'at'\n- Outcome: Mixed results\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0236, combined_score: 0.1610\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0350, combined_score: 0.1667\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.1667)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0350), Performs well on combined_score (0.1667)\n\n\n### Program 2 (Score: 0.1610)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0236), Performs well on combined_score (0.1610)\n\n\n### Program 3 (Score: 0.0000)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.0000), Performs well on speed_score (0.0000), Performs well on combined_score (0.0000), Performs well on error ('builtin_function_or_method' object has no attribute 'at')\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.0000)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.1667, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices.cpu()\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=\"cpu\")\n    rank_in_pack = torch.full_like(pack_index, fill_value=-1)\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These are on CPU because the input 'weight' is moved to CPU in rebalance_experts.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of unavailable packs to infinity to exclude them from argmin.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n            \n            # Use torch.argmin to find the index of the pack with the minimum weight.\n            # .item() converts the 0-dim tensor result to a Python scalar.\n            pack = torch.argmin(candidate_weights).item()\n\n            # Assert that a valid pack was found and it has space.\n            assert current_pack_items[pack] < groups_per_pack\n\n            # Assign the group to the chosen pack.\n            # `group_id` is a 0-dim tensor, which can be directly used for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # `weight[i, group_id]` is the weight of the current group.\n            pack_weights_per_layer[i, pack] += weight[i, group_id]\n            pack_items_per_layer[i, pack] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current `rebalance_experts` function has a performance score of 0.1610, with a balancedness score of 0.2983 and a speed score of 0.0236. The goal is to improve both balancedness and speed.\n\nThe `rebalance_experts_hierarchical` function is the core of the logic. It uses `balanced_packing` and `replicate_experts` as subroutines.\n\nLet's analyze potential areas for improvement:\n\n1.  **`balanced_packing` efficiency**: The current `balanced_packing` function iterates through layers and then through sorted groups. For each group, it finds the minimum weight available pack. This involves operations like `torch.where`, `torch.argmin`, and updates to `pack_weights_per_layer` and `pack_items_per_layer`. While it's a greedy approach, the repeated searching for the minimum might be a bottleneck.\n\n2.  **`replicate_experts` efficiency**: This function iteratively adds replicas to the least loaded logical expert. The `max(dim=-1).indices` operation within the loop can be computationally intensive.\n\n3.  **Code Simplification and Readability**: The prompt mentions improving readability and maintainability. While not directly performance metrics, cleaner code often leads to fewer bugs and easier optimization.\n\n4.  **Hierarchical vs. Global Policy**: The `rebalance_experts` function decides between `rebalance_experts_hierarchical` and a simplified global policy (by setting `num_groups=1`, `num_nodes=1`). The condition `num_groups % num_nodes == 0` might be too restrictive. If it's not met, it falls back to a global policy, which might not be optimal.\n\n**Proposed Improvements:**\n\n**Improvement 1: Optimize `balanced_packing` for speed**\n\nThe current `balanced_packing` sorts groups by weight and then greedily assigns them. A potential optimization is to use a min-heap data structure to efficiently find the pack with the minimum current weight. This would change the complexity of finding the best pack from O(num_packs) to O(log num_packs).\n\nHowever, implementing a min-heap directly with PyTorch tensors can be complex and might not yield significant speedups due to PyTorch's overhead. A simpler optimization could be to pre-sort the packs by their current weights and then iterate through them.\n\nLet's consider an alternative approach for `balanced_packing` that might be more efficient. Instead of finding the minimum pack for each group, we can iterate through the packs and assign groups to them.\n\n**Improvement 2: Optimize `replicate_experts`**\n\nThe current `replicate_experts` function iteratively assigns replicas. The core operation `(weight / logcnt).max(dim=-1).indices` is performed `num_redundant` times. This could be optimized by more directly calculating which expert gets the next replica.\n\n**Improvement 3: Refine the hierarchical vs. global policy condition**\n\nThe current logic `if num_groups % num_nodes == 0:` might be too strict. If it's not divisible, it defaults to a global policy. A more flexible approach could be to always use the hierarchical structure but adjust the `groups_per_node` calculation.\n\n**Focusing on the provided code and the prompt's emphasis on speed and balancedness, let's try to optimize the existing functions first.**\n\nThe `balanced_packing` function has a loop that iterates over `indices[i]` (sorted group IDs) and for each `group_id`, it finds the minimum weight pack.\n\n```python\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of unavailable packs to infinity to exclude them from argmin.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n\n            # Use torch.argmin to find the index of the pack with the minimum weight.\n            # .item() converts the 0-dim tensor result to a Python scalar.\n            pack = torch.argmin(candidate_weights).item()\n```\n\nThis section can be optimized. Instead of iterating through each group and finding the min pack, we can iterate through the packs and assign groups to them. This would change the logic from \"for each item, find the best bin\" to \"for each bin, fill it with items\".\n\nLet's reconsider the `balanced_packing` function. The goal is to pack `n` weighted objects into `m` packs, with `n/m` objects per pack, balancing weights. The current approach sorts items and greedily assigns them to the least loaded pack.\n\nA more direct approach to achieve balanced packing, especially when the number of items per pack is fixed, is to sort all items globally and then distribute them round-robin into the packs. However, the problem statement says \"each bin contains exactly n/m objects\", which implies a fixed size.\n\nLet's look at the `replicate_experts` function.\n\n```python\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n```\n\nHere, in each iteration, `max(dim=-1).indices` is computed. This finds the logical expert that would receive the next replica to keep the load balanced. This is a greedy approach.\n\nLet's focus on making `balanced_packing` more efficient. The current implementation iterates through each layer and then each group within that layer. For each group, it finds the least loaded pack.\n\nConsider the possibility of vectorizing the assignment within `balanced_packing`.\n\nThe core issue in `balanced_packing` is finding the pack with the minimum weight for each group. This is a classic assignment problem.\n\nLet's explore a change that aims to improve the speed score by reducing redundant computations or improving data access patterns.\n\nThe `rebalance_experts_hierarchical` function has several `gather` operations and `view` operations. These can sometimes be optimized.\n\n**Focusing on `balanced_packing`'s inner loop:**\n\nThe current inner loop iterates through `indices[i]` (sorted group IDs). For each `group_id`, it finds the best pack.\n\n```python\n        for group_id in indices[i]:\n            # ... find best pack ...\n            pack = torch.argmin(candidate_weights).item()\n            # ... assign ...\n```\n\nThis is O(num_groups * num_packs) per layer. If `num_groups` is large, this can be slow.\n\nA potentially faster approach for `balanced_packing` when `groups_per_pack` is fixed:\nWe can sort all `num_groups` items globally and then assign them in a round-robin fashion to the packs. However, the `weight` is per layer.\n\nLet's consider the `tokens_per_group` calculation:\n`tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)`\nThis effectively sums the weights of `group_size` logical experts to get the total load for each of the `num_groups`.\n\nThen, `balanced_packing` is called with `tokens_per_group` and `num_nodes`. This attempts to pack `num_groups` into `num_nodes` packs.\n\n**Let's target a specific optimization in `balanced_packing`:**\n\nThe current method of finding the minimum available pack in `balanced_packing` involves `torch.where` and `torch.argmin`. This is done for each group. If `num_packs` is large, this can be slow.\n\nA more efficient way to find the `k` smallest elements and their indices is using `torch.topk`. However, we need the *single* minimum element that's available.\n\nInstead of iterating through `group_id` and finding the best pack, let's try to assign groups to packs more directly.\n\nConsider the `balanced_packing` function again. The goal is to assign `num_groups` items (with weights `tokens_per_group`) into `num_packs` bins, with `groups_per_pack` items per bin, such that bin weights are balanced.\n\nThe current approach is greedy: for each item (sorted by weight), assign it to the least loaded bin.\n\nLet's consider a different perspective. We want to fill `num_packs` bins, each with `groups_per_pack` items. We have `num_groups` items in total.\n\nThe total weight to be distributed is `tokens_per_group.sum()`. Ideally, each pack should have `tokens_per_group.sum() / num_packs` weight.\n\nThe current code sorts the groups by weight within each layer and then greedily assigns them.\n\nLet's try to optimize the selection of the minimum pack. Instead of using `torch.where` and `torch.argmin` repeatedly, we can maintain a sorted list or a min-heap of pack weights. Given the context of PyTorch tensors, a direct min-heap implementation might be cumbersome.\n\nHowever, we can try to optimize the data access. The `pack_weights_per_layer` and `pack_items_per_layer` are updated in a loop.\n\nLet's consider the possibility of directly constructing the `pack_index` without explicitly finding the minimum in each step. This is difficult because the assignment of one group affects the choice for the next.\n\n**Revisiting `replicate_experts`:**\n\nThe core loop finds the `max(dim=-1).indices`. This is done `num_redundant` times. If `num_redundant` is large, this is a bottleneck.\n\n```python\n    for i in range(num_log, num_phy):\n        # This line is potentially slow if num_log is large\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n```\n\nCan we avoid this repeated `max` operation?\nThe goal is to add `num_redundant` replicas. Each replica is assigned to the logical expert that currently has the fewest replicas or the smallest average load.\n\nLet's consider a simpler assignment strategy for `replicate_experts`. If we want to add `k` replicas, we can sort the logical experts by their current load and assign the replicas to the `k` least loaded ones. However, the current code assigns one replica at a time, dynamically updating the load.\n\nLet's focus on the structure of the `balanced_packing` function.\n\nThe current `balanced_packing` function is designed to pack `n` items into `m` packs, with `n/m` items per pack. It sorts items and greedily assigns them.\n\nConsider the case where `groups_per_pack` is small.\n\n**Potential optimization for `balanced_packing`:**\n\nInstead of finding the minimum pack for each group, we can pre-sort the packs by their current weights. Then, iterate through the groups and assign them to the available packs in order.\n\n```python\n    # Inside balanced_packing, for a given layer `i`:\n    # `indices[i]` are sorted group IDs.\n    # `groups_per_pack` is the capacity of each pack.\n\n    # Instead of:\n    # for group_id in indices[i]:\n    #     find_min_pack()\n\n    # Consider:\n    # Keep track of packs and their current weights.\n    # Sort packs by weight.\n    # Iterate through groups and assign to the current least-loaded pack.\n\n    # This requires a more complex data structure to efficiently update pack weights\n    # and maintain sorted order.\n\n    # Let's try a simpler change that might improve speed.\n    # The current approach uses `torch.where` which might be less efficient than direct indexing.\n    # However, `torch.argmin` is necessary to find the minimum.\n```\n\nLet's examine the `rebalance_experts_hierarchical` function for potential speedups.\n\n```python\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n```\n\nThe repeated calls to `balanced_packing` and `replicate_experts` are where the computation happens.\n\nLet's focus on optimizing `balanced_packing` by making the selection of the best pack more efficient.\n\nInstead of `torch.where` and `torch.argmin` inside the loop, we can try to use a more direct method. However, the \"greedy\" nature implies we must find the minimum at each step.\n\nConsider the possibility of pre-sorting the packs by their current load.\n\n**Proposed Change: Optimize `balanced_packing`'s pack selection.**\n\nThe current `balanced_packing` iterates through sorted groups and for each group, finds the minimum available pack. This is O(N_groups * N_packs) per layer.\n\nWe can optimize this by maintaining the packs in a structure that allows efficient retrieval of the minimum. A min-heap is ideal, but implementing it with PyTorch tensors might be complex.\n\nA simpler optimization: Instead of re-computing `candidate_weights` and then `torch.argmin` for *every* group, we can try to iterate through the packs in a way that leverages their sorted order.\n\nLet's try to modify `balanced_packing` to be more efficient.\n\nThe core of `balanced_packing` is assigning `num_groups` items to `num_packs` bins, with `groups_per_pack` items per bin.\n\n```python\n    # For each layer i:\n    # indices[i] is the sorted order of group_ids by weight\n    # groups_per_pack is the capacity of each bin\n\n    # Current logic:\n    # for group_id in indices[i]:\n    #   find_min_pack()\n    #   assign group_id to pack\n\n    # Alternative:\n    # Keep track of pack assignments and current weights.\n    # Instead of finding the minimum pack for each group,\n    # we can try to fill the packs more directly.\n\n    # Example: If groups_per_pack = 2, num_packs = 3\n    # We need to fill 3 packs with 2 groups each.\n    # We have num_groups = 6 groups.\n    # Sorted groups: g1, g2, g3, g4, g5, g6 (by weight)\n\n    # Assign g1 to pack 0.\n    # Assign g2 to pack 1.\n    # Assign g3 to pack 2.\n    # Now packs 0, 1, 2 have one item each.\n    # We need to assign g4 to the least loaded pack (say pack 0).\n    # Assign g5 to the next least loaded pack (say pack 1).\n    # Assign g6 to the last pack (pack 2).\n```\n\nThe current logic is already doing this greedy assignment. The optimization would be in *how* the minimum pack is found.\n\nLet's consider a change that targets the `torch.where` and `torch.argmin` part.\nIf we can avoid creating a temporary `candidate_weights` tensor each time, it might save some overhead.\n\n```python\n            # Find available packs (those not yet full).\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of unavailable packs to infinity to exclude them from argmin.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n\n            pack = torch.argmin(candidate_weights).item()\n```\n\nWe can try to directly find the index of the minimum among available packs without creating the `candidate_weights` tensor.\n\nThis can be achieved by sorting the available packs by their weights.\n\nLet's try to optimize `balanced_packing` by using `torch.topk` to find the minimum available pack more efficiently.\n\n```python\n            # Find available packs (those not yet full).\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Get the indices of available packs\n            available_indices = torch.where(available_mask)[0]\n\n            # If there are available packs\n            if available_indices.numel() > 0:\n                # Get the weights of available packs\n                available_weights = current_pack_weights[available_indices]\n\n                # Find the index of the minimum weight among available packs\n                # `min_idx_in_available` is the index within `available_indices`\n                min_idx_in_available = torch.argmin(available_weights)\n\n                # Get the actual pack index\n                pack = available_indices[min_idx_in_available].item()\n            else:\n                # This case should ideally not happen if num_groups % num_packs == 0\n                # and groups_per_pack is correctly calculated.\n                # However, for robustness, we might need a fallback.\n                # For now, assume it won't happen based on problem constraints.\n                pass\n```\nThis change replaces `torch.where` and `torch.full_like` with `torch.where` and `torch.argmin` on a subset. This might be slightly more efficient if `num_packs` is large, as it avoids creating a full-size tensor with infinities.\n\nHowever, the original code's `torch.where` and `torch.argmin` is quite idiomatic and likely optimized by PyTorch.\n\nLet's consider the **readability** aspect. The current code is relatively well-structured.\n\nA potential improvement for speed could be to **reduce redundant computations in `replicate_experts`**. The repeated `max(dim=-1).indices` is the main suspect.\n\nConsider `replicate_experts`:\n`num_redundant = num_phy - num_log`\nWe are adding `num_redundant` experts.\n\n```python\n    for i in range(num_log, num_phy):\n        # This line finds the logical expert with the minimum (weight / logcnt)\n        # It effectively finds which expert is least loaded *on average*\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n```\n\nThis greedy approach is standard. The performance bottleneck is likely the repeated `max` operation.\n\nCan we optimize the selection of the `num_redundant` experts?\nIf we were to add `k` replicas, we could compute `weight / logcnt` once, sort it, and pick the top `k` indices. However, the `logcnt` changes dynamically.\n\nLet's try to optimize the `balanced_packing` function by making the pack selection more efficient.\n\nThe current approach is: for each group, find the minimum weight pack among those that are not full.\n\n```python\n            # Get current state for this layer's packs.\n            current_pack_weights = pack_weights_per_layer[i]\n            current_pack_items = pack_items_per_layer[i]\n\n            # Find available packs (those not yet full).\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n\n            # Use torch.argmin to find the index of the pack with the minimum weight.\n            pack = torch.argmin(candidate_weights).item()\n```\n\nInstead of creating `candidate_weights` and then `argmin`, we can directly find the index of the minimum among the available packs.\n\n```python\n            # Find available packs (those not yet full).\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Get the indices of the available packs\n            available_pack_indices = torch.arange(num_packs, device=weight.device)[available_mask]\n\n            # If there are available packs\n            if available_pack_indices.numel() > 0:\n                # Get the weights of these available packs\n                available_pack_weights = current_pack_weights[available_pack_indices]\n\n                # Find the index within `available_pack_indices` that corresponds to the minimum weight\n                min_available_idx = torch.argmin(available_pack_weights)\n\n                # Get the actual pack index\n                pack = available_pack_indices[min_available_idx].item()\n            else:\n                # This case should not happen if the logic is correct and num_packs is sufficient.\n                # For robustness, one might raise an error or handle it.\n                # Assuming valid inputs and logic, this branch is not taken.\n                raise RuntimeError(\"No available packs found, which should not happen.\")\n```\nThis modification aims to be slightly more efficient by directly selecting from available packs rather than creating an intermediate tensor with infinities. It avoids `torch.full_like` which might have some overhead.\n\nLet's consider the potential performance gain. `torch.where` creates a new tensor. `torch.argmin` on that tensor. The proposed change uses `torch.arange`, `torch.where` to get indices, and then `current_pack_weights[available_pack_indices]` to get weights, and `torch.argmin` on that subset. This might be more memory efficient and potentially faster if `num_packs` is large compared to the number of available packs.\n\n**Diff for `balanced_packing` optimization:**\n\n```python\n<<<<<<< SEARCH\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of unavailable packs to infinity to exclude them from argmin.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n\n            # Use torch.argmin to find the index of the pack with the minimum weight.\n            # .item() converts the 0-dim tensor result to a Python scalar.\n            pack = torch.argmin(candidate_weights).item()\n=======\n            # Find available packs (those not yet full).\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Get the indices of the available packs\n            available_pack_indices = torch.arange(num_packs, device=weight.device)[available_mask]\n\n            # If there are available packs\n            if available_pack_indices.numel() > 0:\n                # Get the weights of these available packs\n                available_pack_weights = current_pack_weights[available_pack_indices]\n\n                # Find the index within `available_pack_indices` that corresponds to the minimum weight\n                min_available_idx = torch.argmin(available_pack_weights)\n\n                # Get the actual pack index\n                pack = available_pack_indices[min_available_idx].item()\n            else:\n                # This case should not happen if the logic is correct and num_packs is sufficient.\n                raise RuntimeError(\"No available packs found, which should not happen.\")\n>>>>>>> REPLACE\n```\n\nThis change focuses on optimizing the inner loop of `balanced_packing` for speed by avoiding the creation of a temporary tensor with infinities and directly working with available packs. It aims to improve the `speed_score` while ideally maintaining or improving the `balancedness_score`. The complexity of finding the minimum pack remains O(N_packs) in the worst case for this selection method, but the constant factors might be improved.\n\nLet's also consider the `replicate_experts` optimization. The repeated `max` operation is a concern.\n\nInstead of `(weight / logcnt).max(dim=-1).indices`, we can try to use a more direct method to find the `num_redundant` logical experts that would receive the replicas.\n\nOne way to optimize `replicate_experts` would be to use a min-heap to keep track of the logical experts and their current load. When a replica is assigned, the expert's load is updated, and it's re-inserted into the heap. This would make the selection of the least loaded expert O(log N_log) instead of O(N_log).\n\nHowever, implementing a min-heap with PyTorch tensors efficiently can be tricky.\n\nLet's try a simpler optimization for `replicate_experts` that avoids the repeated `max` calculation.\n\nThe current loop adds one replica at a time.\n`redundant_indices = (weight / logcnt).max(dim=-1).indices`\n\nWhat if we sort all logical experts by their current load `weight / logcnt` and then assign the `num_redundant` replicas to the `num_redundant` least loaded experts? This would require sorting `num_log` elements `num_redundant` times, which is what the current code does implicitly.\n\nConsider the case where `num_redundant` is large.\nWe need to find the `num_redundant` smallest values of `weight / logcnt`.\n\nLet's try to optimize `replicate_experts` by using `torch.topk` to find the indices of the least loaded experts more directly.\n\n```python\n    # Inside replicate_experts\n    # ...\n    # arangen = torch.arange(n, dtype=torch.int64, device=device)\n    # ...\n    # for i in range(num_log, num_phy):\n        # redundant_indices = (weight / logcnt).max(dim=-1).indices\n        # phy2log[:, i] = redundant_indices\n        # rank[:, i] = logcnt[arangen, redundant_indices]\n        # logcnt[arangen, redundant_indices] += 1\n\n    # Optimized approach:\n    # Calculate current average loads for all logical experts\n    avg_load = weight / logcnt # [n, num_log]\n\n    # We need to assign num_redundant replicas.\n    # Each replica is assigned to the expert that currently has the minimum average load.\n    # The current loop does this iteratively.\n\n    # A more efficient way to select the experts to receive replicas:\n    # We want to find the num_redundant experts that will receive the *next* replica.\n    # This is equivalent to repeatedly finding the minimum.\n\n    # Let's try to pre-calculate the assignments if possible.\n    # This is difficult because `logcnt` changes.\n\n    # Alternative strategy:\n    # For each of the `num_redundant` slots (i from num_log to num_phy-1):\n    # Find the logical expert with the minimum `weight/logcnt`.\n    # The current code does this.\n\n    # Let's focus on the computation of `weight / logcnt`.\n    # `logcnt` is [n, num_log]. `weight` is [n, num_log].\n    # Division is element-wise.\n\n    # The `max(dim=-1).indices` is the bottleneck.\n\n    # Consider using `torch.topk` with `largest=False` to find the indices of the smallest values.\n    # However, we need to do this `num_redundant` times, and `logcnt` changes.\n\n    # Let's try to optimize the selection of the minimum by avoiding the explicit `max` call\n    # and potentially using a more efficient way to get the index.\n\n    # One common technique for such problems is to use a min-heap.\n    # However, given the constraints and the need for PyTorch tensor operations,\n    # let's try to find an alternative within PyTorch.\n\n    # If we can sort `weight / logcnt` and pick the top `num_redundant` indices,\n    # that would be faster, but the assignment is sequential.\n\n    # Let's reconsider the provided example code.\n    # The current `replicate_experts` is likely a standard greedy approach.\n    # The performance bottleneck might be the repeated computation of `max(dim=-1).indices`.\n\n    # Let's try to use `torch.topk` to find the minimum, but this needs careful handling of the loop.\n    # The `torch.topk` function returns values and indices.\n\n    # Consider this:\n    # Calculate all `weight / logcnt` values.\n    # Find the minimum index.\n    # Update `logcnt` and `rank`.\n    # Repeat `num_redundant` times.\n\n    # This is what the code already does. The optimization is to make the \"find minimum index\" faster.\n\n    # Let's try to use `torch.min` instead of `max(dim=-1).indices`.\n    # `torch.min(tensor)` returns the minimum value.\n    # `torch.argmin(tensor)` returns the index of the minimum value.\n    # The current code uses `max(dim=-1).indices`, which means it's finding the logical expert\n    # with the *highest* average load among those that have the *most* replicas already.\n    # This seems counter-intuitive for balancing.\n\n    # Let's re-read the `replicate_experts` docstring:\n    # \"such that the maximum load of all replicas is minimized.\"\n    # This means we should be adding replicas to the *least* loaded experts.\n    # The current code is using `max(dim=-1).indices`, which means it's selecting the logical expert\n    # that would *maximize* the `weight / logcnt` *after* adding a replica if `logcnt` were to increase.\n    # This is confusing.\n\n    # Let's assume the intention is to add replicas to the LEAST loaded experts.\n    # So, `(weight / logcnt)` should be minimized.\n\n    # If the goal is to minimize the maximum load, we should be picking the expert with the minimum `weight / logcnt`.\n    # The current code is using `max(dim=-1).indices` on `weight / logcnt`. This means it's picking the expert\n    # that would result in the *largest* `weight / logcnt` if `logcnt` were to increase. This is likely a bug or misinterpretation.\n\n    # Let's assume it should be `torch.argmin`.\n\n    # If it *is* `torch.argmin`, then the repeated calculation is the issue.\n    # Let's try to optimize `replicate_experts` by using `torch.topk` to find the indices of the smallest loads.\n    # However, the dynamic update of `logcnt` makes this tricky.\n\n    # Let's stick to the first optimization for `balanced_packing` as it's a more direct optimization of an existing pattern.\n```\n\nConsidering the prompt's request for improved balancedness and speed, and the history of the code, the optimization within `balanced_packing` is a good candidate. The original code's approach to finding the minimum pack is a bottleneck. The proposed change aims to make this selection more efficient.\n\nThe `replicate_experts` function might have a logical error in using `max` instead of `min` if the goal is load balancing. However, without further context or tests, it's hard to confirm. Assuming the current logic is intended, the optimization would be in the repeated calculation.\n\nGiven the constraint to provide *one* diff, the optimization in `balanced_packing` is a solid choice for improving the speed score, as it targets a clear computational bottleneck in a core function.\n\nFinal check on the proposed diff for `balanced_packing`:\nIt replaces the `torch.where` + `torch.full_like` + `torch.argmin` with `torch.arange` + `torch.where` + indexing + `torch.argmin` on a subset. This is a common optimization pattern to avoid creating large intermediate tensors.\n\n```python\n<<<<<<< SEARCH\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of unavailable packs to infinity to exclude them from argmin.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n\n            # Use torch.argmin to find the index of the pack with the minimum weight.\n            # .item() converts the 0-dim tensor result to a Python scalar.\n            pack = torch.argmin(candidate_weights).item()\n=======\n            # Find available packs (those not yet full).\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Get the indices of the available packs\n            available_pack_indices = torch.arange(num_packs, device=weight.device)[available_mask]\n\n            # If there are available packs\n            if available_pack_indices.numel() > 0:\n                # Get the weights of these available packs\n                available_pack_weights = current_pack_weights[available_pack_indices]\n\n                # Find the index within `available_pack_indices` that corresponds to the minimum weight\n                min_available_idx = torch.argmin(available_pack_weights)\n\n                # Get the actual pack index\n                pack = available_pack_indices[min_available_idx].item()\n            else:\n                # This case should not happen if the logic is correct and num_packs is sufficient.\n                raise RuntimeError(\"No available packs found, which should not happen.\")\n>>>>>>> REPLACE\n```\nThis change is a good candidate for improving the speed score by making the inner loop of `balanced_packing` more efficient. It's a targeted optimization.\n\n\nOne final thought: the `replicate_experts` function uses `max(dim=-1).indices`. If the goal is load balancing, this should likely be `min(dim=-1).indices`. If this is indeed a bug, fixing it would improve both balancedness and potentially speed (if the `max` operation is slower than `min` for some reason, which is unlikely). However, I will not propose a change that assumes a bug without explicit confirmation. The current proposed change focuses on optimizing the existing logic.\n\n\nLet's re-evaluate the `replicate_experts` function. If the goal is to minimize the maximum load, we should be adding replicas to the experts with the *least* load. The current code uses `max(dim=-1).indices` on `weight / logcnt`. This means it picks the expert that, after adding a replica (increasing `logcnt`), would have the *highest* average load. This is counter-intuitive for load balancing.\n\nIf the intention is to pick the expert with the *minimum* average load, then `torch.argmin` should be used. Assuming the intention is indeed to minimize the maximum load, then `torch.argmin` is the correct operation.\n\nThe prompt is about improving the algorithm. If the algorithm's current implementation is flawed for its stated goal, fixing that flaw is an improvement.\n\nLet's assume the intention is to pick the minimum.\n\n**Proposed Change 2: Correct `replicate_experts` to use `argmin`**\n\nThis change addresses a potential logical flaw that directly impacts balancedness.\n\n```python\n<<<<<<< SEARCH\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n=======\n    for i in range(num_log, num_phy):\n        # To minimize the maximum load, we should add replicas to the\n        # logical experts with the minimum current average load.\n        # The original code used .max(dim=-1).indices, which seems incorrect for load balancing.\n        # We replace it with .argmin() to select the least loaded expert.\n        redundant_indices = (weight / logcnt).argmin(dim=-1)\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n>>>>>>> REPLACE\n```\nThis change is more impactful for balancedness. The speedup might be negligible or even slightly negative if `argmin` is slower than `max` in certain contexts, but the primary goal is improved balancedness.\n\nGiven the prompt's emphasis on *both* balancedness and speed, and the previous performance scores, the `balanced_packing` optimization is a safer bet for improving the overall score without introducing potential functional regressions.\n\nHowever, if we consider \"improving the algorithm\" to mean making it achieve its goal better, then correcting the `replicate_experts` function is paramount for balancedness.\n\nLet's stick with the `balanced_packing` optimization as it's a direct performance improvement on existing logic. If the user wants to address potential logical flaws, that's a different request. The prompt is about improving performance metrics.\n\nThe current `balancedness_score: 0.2983`, `speed_score: 0.0236`, `combined_score: 0.1610`.\nThe previous best `balancedness_score: 0.2983`, `speed_score: 0.0350`, `combined_score: 0.1667`.\nThe goal is to improve both.\n\nThe optimization in `balanced_packing` is likely to improve the `speed_score` without hurting `balancedness_score`.\n\n```python\n# Proposed change: Optimize balanced_packing's pack selection for speed.\n# This targets the inner loop where the minimum available pack is found.\n# It replaces the creation of a temporary tensor with infinities by directly\n# selecting from available packs.\n```\n\nThis is the most direct path to improving the speed score while maintaining or improving balancedness.\n\n```python\n<<<<<<< SEARCH\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of unavailable packs to infinity to exclude them from argmin.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n\n            # Use torch.argmin to find the index of the pack with the minimum weight.\n            # .item() converts the 0-dim tensor result to a Python scalar.\n            pack = torch.argmin(candidate_weights).item()\n=======\n            # Find available packs (those not yet full).\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Get the indices of the available packs\n            available_pack_indices = torch.arange(num_packs, device=weight.device)[available_mask]\n\n            # If there are available packs\n            if available_pack_indices.numel() > 0:\n                # Get the weights of these available packs\n                available_pack_weights = current_pack_weights[available_pack_indices]\n\n                # Find the index within `available_pack_indices` that corresponds to the minimum weight\n                min_available_idx = torch.argmin(available_pack_weights)\n\n                # Get the actual pack index\n                pack = available_pack_indices[min_available_idx].item()\n            else:\n                # This case should not happen if the logic is correct and num_packs is sufficient.\n                raise RuntimeError(\"No available packs found, which should not happen.\")\n>>>>>>> REPLACE\n```\n\nThis change is focused on improving the efficiency of the `balanced_packing` function's core assignment logic, which is a significant part of the overall computation. By avoiding the creation of a full-sized tensor with infinities and directly working with the weights of available packs, we aim to reduce computational overhead and potentially improve the `speed_score`. This change should not negatively impact the `balancedness_score` as it's a different way to achieve the same greedy assignment.\n\n<<<<<<< SEARCH\n            # Find available packs (those not yet full).\n            # `available_mask` is a boolean tensor.\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Find the pack with the minimum current weight among available ones.\n            # Set weights of unavailable packs to infinity to exclude them from argmin.\n            candidate_weights = torch.where(available_mask, current_pack_weights,\n                                            torch.full_like(current_pack_weights, float('inf')))\n\n            # Use torch.argmin to find the index of the pack with the minimum weight.\n            # .item() converts the 0-dim tensor result to a Python scalar.\n            pack = torch.argmin(candidate_weights).item()\n=======\n            # Find available packs (those not yet full).\n            available_mask = (current_pack_items < groups_per_pack)\n\n            # Get the indices of the available packs\n            available_pack_indices = torch.arange(num_packs, device=weight.device)[available_mask]\n\n            # If there are available packs\n            if available_pack_indices.numel() > 0:\n                # Get the weights of these available packs\n                available_pack_weights = current_pack_weights[available_pack_indices]\n\n                # Find the index within `available_pack_indices` that corresponds to the minimum weight\n                min_available_idx = torch.argmin(available_pack_weights)\n\n                # Get the actual pack index\n                pack = available_pack_indices[min_available_idx].item()\n            else:\n                # This case should not happen if the logic is correct and num_packs is sufficient.\n                raise RuntimeError(\"No available packs found, which should not happen.\")\n>>>>>>> REPLACE"]}}}