{"id": "7428f798-f7cd-45bb-9852-540854911445", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\nimport heapq # Added import for balanced_packing optimization\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        current_layer_weight = weight[i] # Get weights for the current layer\n\n        # Min-heap to store (current_pack_weight, pack_idx) for the current layer\n        # Initialize with 0 weight for all packs.\n        pack_heap = [(0.0, p_idx) for p_idx in range(num_packs)]\n        \n        # Keep track of current pack weights and item counts for the current layer\n        current_pack_weights = torch.zeros(\n            num_packs, dtype=weight.dtype, device=weight.device)\n        current_pack_items = torch.zeros(\n            num_packs, dtype=torch.int64, device=weight.device)\n\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Pop the pack with the minimum current weight\n            min_weight_val, selected_pack_idx = heapq.heappop(pack_heap)\n            \n            pack = selected_pack_idx\n\n            # Assign the group to the chosen pack.\n            # `group_id` is a 0-dim tensor, which can be directly used for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # `current_layer_weight[group_id]` is the weight of the current group.\n            current_pack_weights[pack] += current_layer_weight[group_id]\n            current_pack_items[pack] += 1\n            \n            # If the pack is not yet full, push it back to the heap with its updated weight\n            if current_pack_items[pack] < groups_per_pack:\n                # Use .item() to convert tensor scalar to Python float for heapq\n                heapq.heappush(pack_heap, (current_pack_weights[pack].item(), pack))\n            # Else, the pack is full and will not be re-added to the heap.\n            \n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all physical experts (load of logical expert divided by its replicas)\n    is minimized. Optimized using a min-heap.\n\n    Parameters:\n        weight: [X, num_log]  (e.g., [num_layers * num_nodes, num_logical_experts_per_node])\n        num_phy: total number of experts after replication (e.g., num_physical_experts_per_node)\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank (0-indexed)\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    # Initialize output tensors\n    # phy2log: maps physical expert index to logical expert index\n    # rank: maps physical expert index to its replica rank (0-indexed)\n    phy2log = torch.empty((n, num_phy), dtype=torch.int64, device=device)\n    rank = torch.empty((n, num_phy), dtype=torch.int64, device=device)\n    \n    # logcnt will store the final count of replicas for each logical expert per row (layer/node-layer)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    # Iterate for each row (layer or num_layers * num_nodes)\n    for r_idx in range(n):\n        current_layer_weight = weight[r_idx] # This is a 1D tensor of shape [num_log]\n        \n        # Min-heap to store (load_per_replica, logical_expert_index, num_replicas_assigned)\n        layer_min_heap = []\n        \n        # Initialize the heap with the first replica for each logical expert.\n        # The initial load per replica is the expert's full load, with 1 replica.\n        for j in range(num_log):\n            heapq.heappush(layer_min_heap, (current_layer_weight[j].item(), j, 1))\n\n        # Assign physical experts for the current row (layer/node-layer)\n        for i in range(num_phy):  # Iterate through each physical expert slot to be assigned\n            if not layer_min_heap:\n                # This should not be reached if num_phy >= num_log, as we always assign num_phy experts.\n                break\n\n            # Pop the logical expert with the smallest current load per replica.\n            current_load_per_rep, best_log_idx, num_reps_assigned = heapq.heappop(layer_min_heap)\n            \n            # Assign the current physical expert (index `i`) to this logical expert.\n            phy2log[r_idx, i] = best_log_idx\n            # The rank is the number of replicas assigned so far (0-indexed).\n            rank[r_idx, i] = num_reps_assigned - 1 \n\n            # Update the count of replicas for this logical expert for the current row.\n            logcnt[r_idx, best_log_idx] = num_reps_assigned\n            \n            # If this logical expert can receive more replicas, calculate its new\n            # potential load per replica and push it back to the heap.\n            # We calculate the load per replica if one more replica were added.\n            # If this logical expert can receive more replicas, calculate its new\n            # potential load per replica and push it back to the heap.\n            # We calculate the load per replica if one more replica were added.\n            # The maximum replicas an expert can have for this call is determined by the total\n            # physical experts available (`num_phy`) and the number of logical experts (`num_log`).\n            # It's `num_phy - (num_log - 1)` because at least `num_log - 1` experts must have 1 replica.\n            max_allowed_replicas_for_expert = num_phy - (num_log - 1)\n            \n            # Only push back to heap if this expert has not reached its maximum allowed replicas.\n            if num_reps_assigned < max_allowed_replicas_for_expert:\n                expert_weight = current_layer_weight[best_log_idx].item()\n                new_load_per_rep = expert_weight / (num_reps_assigned + 1)\n                heapq.heappush(layer_min_heap, (new_load_per_rep, best_log_idx, num_reps_assigned + 1))\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups > 1 and num_nodes > 0 and num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        # In global policy, we treat all logical experts as a single group\n        # and balance them across all physical experts.\n        # The `replicate_experts` function directly handles this.\n        # We need to reshape weight to [num_layers, num_logical_experts]\n        # and then replicate them to num_physical_experts.\n        phy2log, phyrank, logcnt = replicate_experts(\n            weight, num_replicas)\n        # The output of replicate_experts is [n, num_phy] for phy2log and rank,\n        # and [n, num_log] for logcnt. We need to ensure these match the expected\n        # output shapes after potential reshaping.\n        # For global policy, n is num_layers, num_log is num_logical_experts, num_phy is num_replicas.\n\n    # The rest of the logic for constructing log2phy remains the same.\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "f0acf2e3-0722-4958-aa34-30678d5413cc", "generation": 9, "timestamp": 1751062387.1265001, "iteration_found": 197, "metrics": {"balancedness_score": 0.0037003955074195196, "speed_score": 0.028173567135134667, "combined_score": 0.015936981321277095}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 4 lines with 13 lines", "parent_metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "index 8448 is out of bounds for dimension 1 with size 8448"}, "island": 4}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.0000\n- speed_score: 0.0000\n- combined_score: 0.0000\n- error: index 8448 is out of bounds for dimension 1 with size 8448\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0857, combined_score: 0.1920\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1097, combined_score: 0.2312\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.3528, speed_score: 0.1103, combined_score: 0.2315\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.2315)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1103), Performs well on combined_score (0.2315)\n\n\n### Program 2 (Score: 0.2312)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.3528), Performs well on speed_score (0.1097), Performs well on combined_score (0.2312)\n\n\n### Program 3 (Score: 0.1920)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0857), Performs well on combined_score (0.1920)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1914)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1909)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.2315, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 32 lines with 32 lines, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.0939, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 236 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.1628, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 47 lines with 28 lines\nChange 2: Replace 4 lines with 3 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 5 (Score: 0.1661, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 23 lines with 27 lines\nChange 2: Replace 20 lines with 26 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\nimport heapq # Added import for balanced_packing optimization\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Sort groups by weight in descending order.\n    # 'weight' is already float and on CPU from rebalance_experts,\n    # so no need for .float().cpu() here.\n    indices = weight.sort(-1, descending=True).indices\n\n    # Initialize pack_index and rank_in_pack.\n    # These will be fully populated, so `empty_like` is sufficient.\n    # They will be on the same device as 'weight' (i.e., CPU).\n    pack_index = torch.empty_like(weight, dtype=torch.int64)\n    rank_in_pack = torch.empty_like(pack_index)\n    \n    # Iterate over each layer. The greedy assignment per layer is sequential.\n    for i in range(num_layers):\n        current_layer_weight = weight[i] # Get weights for the current layer\n\n        # Min-heap to store (current_pack_weight, pack_idx) for the current layer\n        # Initialize with 0 weight for all packs.\n        pack_heap = [(0.0, p_idx) for p_idx in range(num_packs)]\n        \n        # Keep track of current pack weights and item counts for the current layer\n        current_pack_weights = torch.zeros(\n            num_packs, dtype=weight.dtype, device=weight.device)\n        current_pack_items = torch.zeros(\n            num_packs, dtype=torch.int64, device=weight.device)\n\n        # For each layer, process groups in sorted order of their weights.\n        # `indices[i]` is a 1D tensor of group IDs for the current layer.\n        for group_id in indices[i]:\n            # Pop the pack with the minimum current weight\n            min_weight_val, selected_pack_idx = heapq.heappop(pack_heap)\n            \n            pack = selected_pack_idx\n\n            # Assign the group to the chosen pack.\n            # `group_id` is a 0-dim tensor, which can be directly used for indexing.\n            pack_index[i, group_id] = pack\n            rank_in_pack[i, group_id] = current_pack_items[pack]\n\n            # Update pack weights and item counts for the chosen pack.\n            # `current_layer_weight[group_id]` is the weight of the current group.\n            current_pack_weights[pack] += current_layer_weight[group_id]\n            current_pack_items[pack] += 1\n            \n            # If the pack is not yet full, push it back to the heap with its updated weight\n            if current_pack_items[pack] < groups_per_pack:\n                # Use .item() to convert tensor scalar to Python float for heapq\n                heapq.heappush(pack_heap, (current_pack_weights[pack].item(), pack))\n            # Else, the pack is full and will not be re-added to the heap.\n            \n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all physical experts (load of logical expert divided by its replicas)\n    is minimized. Optimized using a min-heap.\n\n    Parameters:\n        weight: [X, num_log]  (e.g., [num_layers * num_nodes, num_logical_experts_per_node])\n        num_phy: total number of experts after replication (e.g., num_physical_experts_per_node)\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank (0-indexed)\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    # Initialize output tensors\n    # phy2log: maps physical expert index to logical expert index\n    # rank: maps physical expert index to its replica rank (0-indexed)\n    phy2log = torch.empty((n, num_phy), dtype=torch.int64, device=device)\n    rank = torch.empty((n, num_phy), dtype=torch.int64, device=device)\n    \n    # logcnt will store the final count of replicas for each logical expert per row (layer/node-layer)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    # Iterate for each row (layer or num_layers * num_nodes)\n    for r_idx in range(n):\n        current_layer_weight = weight[r_idx] # This is a 1D tensor of shape [num_log]\n        \n        # Min-heap to store (load_per_replica, logical_expert_index, num_replicas_assigned)\n        layer_min_heap = []\n        \n        # Initialize the heap with the first replica for each logical expert.\n        # The initial load per replica is the expert's full load, with 1 replica.\n        for j in range(num_log):\n            heapq.heappush(layer_min_heap, (current_layer_weight[j].item(), j, 1))\n\n        # Assign physical experts for the current row (layer/node-layer)\n        for i in range(num_phy):  # Iterate through each physical expert slot to be assigned\n            if not layer_min_heap:\n                # This should not be reached if num_phy >= num_log, as we always assign num_phy experts.\n                break\n\n            # Pop the logical expert with the smallest current load per replica.\n            current_load_per_rep, best_log_idx, num_reps_assigned = heapq.heappop(layer_min_heap)\n            \n            # Assign the current physical expert (index `i`) to this logical expert.\n            phy2log[r_idx, i] = best_log_idx\n            # The rank is the number of replicas assigned so far (0-indexed).\n            rank[r_idx, i] = num_reps_assigned - 1 \n\n            # Update the count of replicas for this logical expert for the current row.\n            logcnt[r_idx, best_log_idx] = num_reps_assigned\n            \n            # If this logical expert can receive more replicas, calculate its new\n            # potential load per replica and push it back to the heap.\n            # We calculate the load per replica if one more replica were added.\n            new_load_per_rep = current_layer_weight[best_log_idx].item() / (num_reps_assigned + 1)\n            \n            # Push back to heap for consideration for the next physical expert slot.\n            heapq.heappush(layer_min_heap, (new_load_per_rep, best_log_idx, num_reps_assigned + 1))\n\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float().cpu()\n    if num_groups > 1 and num_nodes > 0 and num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        # In global policy, we treat all logical experts as a single group\n        # and balance them across all physical experts.\n        # The `replicate_experts` function directly handles this.\n        # We need to reshape weight to [num_layers, num_logical_experts]\n        # and then replicate them to num_physical_experts.\n        phy2log, phyrank, logcnt = replicate_experts(\n            weight, num_replicas)\n        # The output of replicate_experts is [n, num_phy] for phy2log and rank,\n        # and [n, num_log] for logcnt. We need to ensure these match the expected\n        # output shapes after potential reshaping.\n        # For global policy, n is num_layers, num_log is num_logical_experts, num_phy is num_replicas.\n\n    # The rest of the logic for constructing log2phy remains the same.\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=logcnt.device,\n    )\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=log2phy.device).expand(num_layers, -1),\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program exhibits a critical \"index out of bounds\" error, leading to zero scores across all metrics. This error likely occurs when constructing the `logical_to_physical_map` (named `log2phy` internally) using `scatter_`, specifically because the calculated indices exceed the dimension size.\n\nThe analysis indicates that the `replicate_experts` function, which determines the replica ranks (`phyrank`), might occasionally generate a rank value that is too high for the `maxlogcnt` (maximum number of replicas for any logical expert) used in the final `log2phy` tensor creation. This happens because the `replicate_experts` function continuously pushes logical experts back into the heap for more replicas, even if they have already received the maximum allowed number of replicas based on the overall configuration.\n\n**Root Cause of the Error:**\nThe `log2phy` tensor is constructed with dimensions `[num_layers, num_logical_experts, maxlogcnt]`. The `scatter_` operation uses `phy2log * maxlogcnt + phyrank` as indices. If `phyrank` (which is `num_reps_assigned - 1`) becomes equal to `maxlogcnt`, then the calculated index `(some_phy2log_value * maxlogcnt) + maxlogcnt` would be `(some_phy2log_value + 1) * maxlogcnt`. If `some_phy2log_value` is `num_logical_experts - 1`, this index becomes `num_logical_experts * maxlogcnt`, which is exactly the size of the dimension, thus causing an out-of-bounds error (valid indices are `0` to `size-1`).\n\n**Proposed Fix for the Error (Balancedness and Stability):**\nIn the `replicate_experts` function, we need to explicitly cap the number of replicas any logical expert can receive. The theoretical maximum number of replicas for any single expert in a given layer (or portion, in the hierarchical case) is `num_physical_experts_per_call - (num_logical_experts_per_call - 1) * 1`. This ensures that even if all other `num_logical_experts_per_call - 1` experts get only one replica, the remaining physical slots go to one expert. By checking against this `max_allowed_replicas_for_expert` before pushing an expert back to the heap, we prevent `phyrank` from exceeding `maxlogcnt - 1`.\n\n**Minor Speed Optimization:**\nA small micro-optimization is to cache the `current_layer_weight[best_log_idx].item()` result in a local variable to avoid redundant lookups and conversions within the loop in `replicate_experts`.\n\nThese changes are expected to resolve the \"index out of bounds\" error, bringing the performance metrics back up to previous levels, and potentially improving `balancedness_score` by ensuring correct behavior under all valid configurations. The speed improvement from the micro-optimization will be marginal but contributes to overall efficiency.\n\n```python\n<<<<<<< SEARCH\n            new_load_per_rep = current_layer_weight[best_log_idx].item() / (num_reps_assigned + 1)\n            \n            # Push back to heap for consideration for the next physical expert slot.\n            heapq.heappush(layer_min_heap, (new_load_per_rep, best_log_idx, num_reps_assigned + 1))\n=======\n            # If this logical expert can receive more replicas, calculate its new\n            # potential load per replica and push it back to the heap.\n            # We calculate the load per replica if one more replica were added.\n            # The maximum replicas an expert can have for this call is determined by the total\n            # physical experts available (`num_phy`) and the number of logical experts (`num_log`).\n            # It's `num_phy - (num_log - 1)` because at least `num_log - 1` experts must have 1 replica.\n            max_allowed_replicas_for_expert = num_phy - (num_log - 1)\n            \n            # Only push back to heap if this expert has not reached its maximum allowed replicas.\n            if num_reps_assigned < max_allowed_replicas_for_expert:\n                expert_weight = current_layer_weight[best_log_idx].item()\n                new_load_per_rep = expert_weight / (num_reps_assigned + 1)\n                heapq.heappush(layer_min_heap, (new_load_per_rep, best_log_idx, num_reps_assigned + 1))\n>>>>>>> REPLACE\n```"]}}}