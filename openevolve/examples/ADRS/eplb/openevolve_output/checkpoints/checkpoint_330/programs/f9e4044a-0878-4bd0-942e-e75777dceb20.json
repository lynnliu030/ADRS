{"id": "f9e4044a-0878-4bd0-942e-e75777dceb20", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.sort(-1, descending=True).indices  # weight is already float\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=weight.device)  # Use weight's device\n    rank_in_pack = torch.full_like(pack_index,\n                                   fill_value=-1,\n                                   device=weight.device)  # Use weight's device\n\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These are on the same device as the input 'weight'.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-calculate a tensor for broadcasting layer indices\n    layer_indices = torch.arange(num_layers, device=weight.device)\n    \n    # Create an infinity tensor once, with the correct device and dtype\n    inf_tensor = weight.new_full((), float('inf'))\n\n    # Iterate over each \"slot\" in the sorted list of groups (from heaviest to lightest)\n    # This processes the k-th heaviest group for ALL layers simultaneously, leveraging PyTorch's vectorization.\n    for k in range(num_groups):\n        # Get the group_ids that are k-th heaviest for each layer\n        current_group_ids = indices[:, k]  # [num_layers]\n\n        # Get the weights of these groups\n        # Use advanced indexing to get weights: weight[layer_idx, group_id_for_that_layer]\n        current_weights = weight[layer_indices, current_group_ids]  # [num_layers]\n\n        # Find available packs for each layer (those not yet full).\n        # available_mask: [num_layers, num_packs]\n        available_mask = (pack_items_per_layer < groups_per_pack)\n\n        # Set unavailable packs to infinity for argmin\n        # candidate_weights: [num_layers, num_packs]\n        candidate_weights = torch.where(available_mask, pack_weights_per_layer, inf_tensor)\n\n        # Find the pack with the minimum current weight for each layer\n        # pack_indices_to_assign: [num_layers]\n        pack_indices_to_assign = torch.argmin(candidate_weights, dim=-1)\n\n        # Assign the current group to the chosen pack for each layer\n        # Using advanced indexing to update pack_index and rank_in_pack\n        pack_index[layer_indices, current_group_ids] = pack_indices_to_assign\n        rank_in_pack[layer_indices, current_group_ids] = \\\n            pack_items_per_layer[layer_indices, pack_indices_to_assign]\n\n        # Update pack weights and item counts for the chosen packs\n        # These updates are also vectorized across layers\n        pack_weights_per_layer[layer_indices, pack_indices_to_assign] += current_weights\n        pack_items_per_layer[layer_indices, pack_indices_to_assign] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        # To minimize the maximum load, we should add replicas to the\n        # logical experts with the minimum current average load.\n        # Reverting to original behavior as suggested by performance metrics.\n        # This strategy aims to reduce the load of the currently most loaded experts.\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float()  # Ensure float, but keep on original device (e.g., GPU)\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    # Ensure log2phy is created on the same device as other tensors\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=weight.device,  # Use weight's device\n    )\n    # The scatter_ operation and arange should also use the correct device\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=weight.device).expand(num_layers, -1),  # Use weight's device\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "e70129e9-0e75-41b2-a61f-904c687b9653", "generation": 6, "timestamp": 1751057026.8443778, "iteration_found": 117, "metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.07740531416828086, "combined_score": 0.1878568328498353}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: 'indices = weight.float().sort(-1, descending=True).indices  # Keep on original device' to 'indices = weight.sort(-1, descending=True).indices  # weight is already float'\nChange 2: Replace 22 lines with 93 lines", "parent_metrics": {"balancedness_score": 0.29830835153138974, "speed_score": 0.08334680991298496, "combined_score": 0.19082758072218736}, "island": 0}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.2983\n- speed_score: 0.0833\n- combined_score: 0.1908\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0830, combined_score: 0.1907\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0833, combined_score: 0.1908\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0835, combined_score: 0.1909\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.1909)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0835), Performs well on combined_score (0.1909)\n\n\n### Program 2 (Score: 0.1908)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0833), Performs well on combined_score (0.1908)\n\n\n### Program 3 (Score: 0.1907)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0830), Performs well on combined_score (0.1907)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1900)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1872)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.1909, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 3 lines with 4 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 3 (Score: 0.0000, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 4 (Score: 0.0434, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace weight = weight.float().cpu() with 3 lines\nChange 2: Replace 2 lines with 2 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 5 (Score: 0.0000, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 61 lines with 46 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    indices = weight.float().sort(-1, descending=True).indices  # Keep on original device\n    pack_index = torch.full_like(weight,\n                                 fill_value=-1,\n                                 dtype=torch.int64,\n                                 device=weight.device)  # Use weight's device\n    rank_in_pack = torch.full_like(pack_index,\n                                   fill_value=-1,\n                                   device=weight.device)  # Use weight's device\n\n    # Initialize tensors to hold pack weights and item counts for all layers.\n    # These are on the same device as the input 'weight'.\n    pack_weights_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=weight.dtype, device=weight.device)\n    pack_items_per_layer = torch.zeros(\n        num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Pre-calculate a tensor for broadcasting layer indices\n    layer_indices = torch.arange(num_layers, device=weight.device)\n    \n    # Create an infinity tensor once, with the correct device and dtype\n    inf_tensor = weight.new_full((), float('inf'))\n\n    # Iterate over each \"slot\" in the sorted list of groups (from heaviest to lightest)\n    # This processes the k-th heaviest group for ALL layers simultaneously, leveraging PyTorch's vectorization.\n    for k in range(num_groups):\n        # Get the group_ids that are k-th heaviest for each layer\n        current_group_ids = indices[:, k]  # [num_layers]\n\n        # Get the weights of these groups\n        # Use advanced indexing to get weights: weight[layer_idx, group_id_for_that_layer]\n        current_weights = weight[layer_indices, current_group_ids]  # [num_layers]\n\n        # Find available packs for each layer (those not yet full).\n        # available_mask: [num_layers, num_packs]\n        available_mask = (pack_items_per_layer < groups_per_pack)\n\n        # Set unavailable packs to infinity for argmin\n        # candidate_weights: [num_layers, num_packs]\n        candidate_weights = torch.where(available_mask, pack_weights_per_layer, inf_tensor)\n\n        # Find the pack with the minimum current weight for each layer\n        # pack_indices_to_assign: [num_layers]\n        pack_indices_to_assign = torch.argmin(candidate_weights, dim=-1)\n\n        # Assign the current group to the chosen pack for each layer\n        # Using advanced indexing to update pack_index and rank_in_pack\n        pack_index[layer_indices, current_group_ids] = pack_indices_to_assign\n        rank_in_pack[layer_indices, current_group_ids] = \\\n            pack_items_per_layer[layer_indices, pack_indices_to_assign]\n\n        # Update pack weights and item counts for the chosen packs\n        # These updates are also vectorized across layers\n        pack_weights_per_layer[layer_indices, pack_indices_to_assign] += current_weights\n        pack_items_per_layer[layer_indices, pack_indices_to_assign] += 1\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        # To minimize the maximum load, we should add replicas to the\n        # logical experts with the minimum current average load.\n        # Reverting to original behavior as suggested by performance metrics.\n        # This strategy aims to reduce the load of the currently most loaded experts.\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Step 1: pack groups to nodes\n    tokens_per_group = weight.unflatten(-1, (num_groups, group_size)).sum(-1)\n    group_pack_index, group_rank_in_pack = balanced_packing(\n        tokens_per_group, num_nodes)\n    log2mlog = (((group_pack_index * groups_per_node + group_rank_in_pack) *\n                 group_size).unsqueeze(-1) +\n                torch.arange(group_size,\n                             dtype=torch.int64,\n                             device=group_pack_index.device)).flatten(-2)\n    mlog2log = inverse(log2mlog)\n\n    # Step 2: construct redundant experts within nodes\n    # [num_layers * num_nodes, num_logical_experts // num_nodes]\n    tokens_per_mlog = weight.gather(-1, mlog2log).view(\n        -1, num_logical_experts // num_nodes)\n    phy2mlog, phyrank, mlogcnt = replicate_experts(\n        tokens_per_mlog, num_physical_experts // num_nodes)\n\n    # Step 3: pack physical_experts to GPUs\n    # [num_layers * num_nodes, num_physical_experts // num_nodes]\n    tokens_per_phy = (tokens_per_mlog / mlogcnt).gather(-1, phy2mlog)\n    pack_index, rank_in_pack = balanced_packing(tokens_per_phy,\n                                                num_gpus // num_nodes)\n    phy2pphy = pack_index * phy_experts_per_gpu + rank_in_pack\n    pphy2phy = inverse(phy2pphy)\n\n    pphy2mlog = phy2mlog.gather(\n        -1, pphy2phy)  # [num_layers * num_nodes, num_log_per_nodes]\n    pphy2mlog = (pphy2mlog.view(num_layers, num_nodes, -1) + torch.arange(\n        0,\n        num_logical_experts,\n        num_logical_experts // num_nodes,\n        device=group_pack_index.device,\n    ).view(1, -1, 1)).flatten(-2)\n    pphy2log = mlog2log.gather(-1, pphy2mlog)\n    pphyrank = phyrank.gather(-1, pphy2phy).view(num_layers, -1)\n    logcnt = mlogcnt.view(num_layers, -1).gather(-1, log2mlog)\n    return pphy2log, pphyrank, logcnt\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float()  # Ensure float, but keep on original device (e.g., GPU)\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log, phyrank, logcnt = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n    num_redundant_experts = num_replicas - num_logical_experts\n    maxlogcnt = num_redundant_experts + 1\n    # Ensure log2phy is created on the same device as other tensors\n    log2phy: torch.Tensor = torch.full(\n        (num_layers, num_logical_experts, maxlogcnt),\n        -1,\n        dtype=torch.int64,\n        device=weight.device,  # Use weight's device\n    )\n    # The scatter_ operation and arange should also use the correct device\n    log2phy.view(num_layers, -1).scatter_(\n        -1,\n        phy2log * maxlogcnt + phyrank,\n        torch.arange(num_replicas, dtype=torch.int64,\n                     device=weight.device).expand(num_layers, -1),  # Use weight's device\n    )\n    return phy2log, log2phy, logcnt\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current algorithm employs a hierarchical greedy approach for load balancing. While the greedy heuristics (Longest Processing Time for `balanced_packing` and iterative max-load reduction for `replicate_experts`) are standard, there are opportunities for improvement in both efficiency and potentially load balancedness.\n\n**Analysis of Current Program and Identified Areas for Improvement:**\n\n1.  **`balanced_packing` function:**\n    *   The `weight.float().sort` call is redundant because the `weight` tensor is already converted to `float` at the entry point of `rebalance_experts`. This creates an unnecessary temporary tensor and copy, which can be a minor performance overhead.\n    *   The core greedy strategy (sort by weight, assign to minimum-load pack) is a well-known heuristic for bin packing and is generally effective for load balancing. The Python loop `for k in range(num_groups)` processes items one by one, but the internal operations are vectorized. If `num_groups` is very large, this loop could become a bottleneck, but for typical MoE setups, `num_groups` is usually moderate.\n\n2.  **`replicate_experts` function:**\n    *   This function currently uses an iterative greedy strategy: in each step, it identifies the logical expert with the highest average load per replica (`weight / logcnt`) and assigns an additional replica to it. This process is repeated `num_redundant` times within a Python `for` loop.\n    *   **Efficiency concern:** If `num_redundant` (the number of additional physical experts to create) or `num_log` (number of logical experts) is large, the repeated `max(dim=-1).indices` operation inside the Python loop can be computationally expensive. Each `max` operation scans `num_layers * num_log` elements. The total complexity is `O(num_redundant * num_layers * num_log)`.\n    *   **Balancedness concern:** While this greedy strategy directly targets minimizing the maximum load, it's a local optimization. A more global apportionment method could potentially yield better overall balance by considering the desired final distribution more directly.\n\n**Proposed Improvements:**\n\n1.  **Micro-optimization: Remove redundant `float()` conversion in `balanced_packing`.**\n    *   **Reasoning:** The `weight` tensor is already converted to `float` at the start of `rebalance_experts`. Calling `.float()` again on an already float tensor creates a redundant copy and wastes computation. This is a small but straightforward efficiency gain.\n\n2.  **Major algorithmic change: Reimplement `replicate_experts` using the Largest Remainder Method (LRM).**\n    *   **Reasoning for Speed:** The LRM is an apportionment algorithm that aims to distribute a fixed number of items (physical experts) among categories (logical experts) proportionally to their \"votes\" (weights). This method can be largely vectorized, replacing the `num_redundant` Python loop with a series of efficient PyTorch tensor operations (`sum`, `floor`, `argsort`, `repeat_interleave`, `cumsum`). The overall complexity would be closer to `O(num_layers * num_log * log(num_log))` (dominated by `argsort`) plus vectorized operations, which is significantly faster than `O(num_redundant * num_layers * num_log)` when `num_redundant` is large.\n    *   **Reasoning for Balancedness:** LRM is a standard method for fair apportionment. By aiming for proportionality of physical experts to logical expert loads, it naturally leads to a more balanced distribution of load across physical experts. This might improve the `balancedness_score` compared to the current iterative greedy approach, which can sometimes get stuck in local optima. The goal of `replicate_experts` is to create physical experts whose individual average loads (`tokens_per_mlog / mlogcnt`) are themselves balanced, which then feeds into the final `balanced_packing` step. LRM directly calculates the target `logcnt` values for this purpose.\n\n**Detailed Changes (in SEARCH/REPLACE format):**\n\n**Change 1: Optimize `balanced_packing` by removing redundant `float()` conversion.**\n\n<<<<<<< SEARCH\n    indices = weight.float().sort(-1, descending=True).indices  # Keep on original device\n=======\n    indices = weight.sort(-1, descending=True).indices  # weight is already float\n>>>>>>> REPLACE\n\n**Change 2: Reimplement `replicate_experts` using the Largest Remainder Method.**\n\n<<<<<<< SEARCH\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        # To minimize the maximum load, we should add replicas to the\n        # logical experts with the minimum current average load.\n        # Reverting to original behavior as suggested by performance metrics.\n        # This strategy aims to reduce the load of the currently most loaded experts.\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices]\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n=======\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    n, num_log = weight.shape  # n is num_layers\n    assert num_phy >= num_log, \"num_phy must be greater than or equal to num_log\"\n    device = weight.device\n\n    # Step 1: Calculate initial `logcnt` using Largest Remainder Method (LRM)\n    # The goal is to distribute `num_phy` total experts proportionally to `weight`.\n\n    # Sum of weights for each layer\n    sum_weights_per_layer = weight.sum(dim=-1, keepdim=True)  # [n, 1]\n\n    # Calculate ideal load per physical expert if weights were perfectly balanced\n    # Add a small epsilon to denominator to prevent division by zero for zero-load experts\n    avg_load_per_phy = sum_weights_per_layer / (num_phy + 1e-9)\n\n    # Quotas: how many physical experts each logical expert ideally gets (fractional)\n    quotas = weight / (avg_load_per_phy + 1e-9)  # [n, num_log]\n\n    # Assign initial replicas based on the floor of quotas\n    logcnt = torch.floor(quotas).to(torch.int64)  # [n, num_log]\n\n    # Ensure each logical expert gets at least one physical expert if num_phy >= num_log.\n    # This aligns with the original behavior where `logcnt` starts at 1,\n    # and prevents logical experts from having zero physical experts unless explicitly intended\n    # by the problem setup (which it isn't, given `num_phy >= num_log`).\n    logcnt = torch.max(logcnt, torch.ones_like(logcnt))\n    \n    # Calculate remaining replicas to distribute for each layer\n    # These are the 'remainder' experts to be assigned to experts with highest fractional parts.\n    remaining_replicas_to_assign = num_phy - logcnt.sum(dim=-1)  # [n]\n    \n    # Calculate remainders (fractional parts of quotas)\n    remainders = quotas - logcnt.float()  # [n, num_log]\n\n    # Get the indices of experts sorted by remainder (descending) for each layer\n    sorted_indices_by_remainder = torch.argsort(remainders, dim=-1, descending=True)  # [n, num_log]\n\n    # Step 2: Distribute remaining replicas based on largest remainders\n    # This loop iterates `n` (num_layers) times, which is typically small,\n    # and operations inside are efficient PyTorch ops.\n    for i in range(n):\n        num_to_add = remaining_replicas_to_assign[i]\n        if num_to_add > 0:\n            # Select the top `num_to_add` experts for this layer\n            experts_to_increment = sorted_indices_by_remainder[i, :num_to_add]\n            logcnt[i, experts_to_increment] += 1\n    \n    # Step 3: Construct `phy2log` and `rank` tensors from the final `logcnt`\n    # This part needs to map each of the `num_phy` physical experts to its\n    # corresponding logical expert ID and its rank among replicas of that logical expert.\n    \n    phy2log_list = []\n    rank_list = []\n\n    # Iterate over layers to construct `phy2log` and `rank`\n    # This loop is also over `n` (num_layers), with vectorized ops inside.\n    for i in range(n):\n        # `phy2log_flat_i`: logical expert IDs, repeated according to their final `logcnt`\n        # E.g., if logcnt[i] = [2, 1, 3] for experts 0, 1, 2\n        # -> [0, 0, 1, 2, 2, 2]\n        phy2log_flat_i = torch.repeat_interleave(\n            torch.arange(num_log, device=device), logcnt[i])\n        phy2log_list.append(phy2log_flat_i)\n\n        # `rank_flat_i`: ranks within each logical expert's replicas\n        # E.g., if logcnt[i] = [2, 1, 3]\n        # -> [0, 1, 0, 0, 1, 2]\n        # This is achieved by:\n        # 1. Calculate cumulative sum of counts (e.g., [2, 3, 6])\n        # 2. Calculate offset for each block (e.g., [0, 2, 3])\n        # 3. Repeat offsets based on counts (e.g., [0, 0, 2, 3, 3, 3])\n        # 4. Subtract repeated offsets from global indices (0 to num_phy-1)\n        \n        current_phy_indices = torch.arange(num_phy, dtype=torch.int64, device=device)\n        # Prefix sum of `logcnt` excluding current expert's count\n        # e.g., for [2, 1, 3], cumsum_prev is [0, 2, 3]\n        cumsum_prev = torch.cat((torch.zeros(1, dtype=torch.int64, device=device),\n                                 logcnt[i, :-1].cumsum(dim=0)))\n        \n        # Repeat these offsets for each physical expert\n        rank_offsets = torch.repeat_interleave(cumsum_prev, logcnt[i])\n        \n        # Calculate rank within each logical expert\n        rank_flat_i = current_phy_indices - rank_offsets\n        rank_list.append(rank_flat_i)\n\n    # Stack the lists to get the final tensors\n    phy2log = torch.stack(phy2log_list)  # [n, num_phy]\n    rank = torch.stack(rank_list)        # [n, num_phy]\n\n    return phy2log, rank, logcnt # Return logcnt as final_logcnt\n>>>>>>> REPLACE"]}}}