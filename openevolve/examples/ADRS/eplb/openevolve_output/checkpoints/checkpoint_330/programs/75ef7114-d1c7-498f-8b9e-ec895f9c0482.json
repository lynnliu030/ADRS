{"id": "75ef7114-d1c7-498f-8b9e-ec895f9c0482", "code": "# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimized balanced_packing using torch.min and broadcasting\n    # (The initial `if groups_per_pack == 1` block is already handled above this SEARCH block)\n\n    # Sort weights and get indices\n    # Ensure weight is float for sorting, keep on original device\n    sorted_weights, sorted_indices = weight.float().sort(-1, descending=True)\n\n    # Initialize pack_index and rank_in_pack on the same device as weight\n    pack_index = torch.full((num_layers, num_groups), -1, dtype=torch.int64, device=weight.device)\n    rank_in_pack = torch.full((num_layers, num_groups), -1, dtype=torch.int64, device=weight.device)\n\n    # Initialize pack_loads and pack_counts on the same device as weight\n    pack_loads = torch.zeros(num_layers, num_packs, dtype=torch.float32, device=weight.device)\n    pack_counts = torch.zeros(num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Vectorized assignment: Iterate through sorted items and assign them to the least loaded pack\n    # This loop processes all layers simultaneously for each item 'g'\n    for g in range(num_groups):\n        # Find the pack with the minimum current load and available slots for all layers\n        # Use a large value for unavailable packs to ensure they are not chosen\n        available_packs_mask = (pack_counts < groups_per_pack)\n        current_pack_loads_masked = pack_loads.masked_fill(~available_packs_mask, float('inf'))\n        \n        # chosen_pack_idx_for_layers will be [num_layers]\n        chosen_pack_idx_for_layers = torch.argmin(current_pack_loads_masked, dim=-1)\n\n        # Get original group index and its weight for current item 'g' across all layers\n        original_group_idx_for_layers = sorted_indices[:, g] # Shape [num_layers]\n        current_item_weights_for_layers = weight[torch.arange(num_layers, device=weight.device), original_group_idx_for_layers] # Shape [num_layers]\n\n        # Update pack_loads: Add current item's weight to the chosen pack for each layer\n        # Use scatter_add_ for efficient update\n        # index: [num_layers, 1], src: [num_layers, 1]\n        pack_loads.scatter_add_(1, chosen_pack_idx_for_layers.unsqueeze(1), current_item_weights_for_layers.unsqueeze(1))\n        \n        # Update pack_counts: Increment count for the chosen pack for each layer\n        # index: [num_layers, 1], src: [num_layers, 1] (ones)\n        pack_counts.scatter_add_(1, chosen_pack_idx_for_layers.unsqueeze(1), torch.ones_like(chosen_pack_idx_for_layers).unsqueeze(1))\n\n        # Update pack_index: Assign the chosen pack ID to the original group index\n        # index: [num_layers, 1], src: [num_layers, 1]\n        pack_index.scatter_(1, original_group_idx_for_layers.unsqueeze(1), chosen_pack_idx_for_layers.unsqueeze(1))\n        \n        # Update rank_in_pack: Assign the rank within the pack.\n        # The rank is the count BEFORE the current item was added.\n        # pack_counts has already been incremented, so subtract 1.\n        # index: [num_layers, 1], src: [num_layers, 1]\n        rank_in_pack.scatter_(1, original_group_idx_for_layers.unsqueeze(1), (pack_counts.gather(1, chosen_pack_idx_for_layers.unsqueeze(1)) - 1))\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    # Initialize phy2log: First num_log physical experts map to logical experts 0 to num_log-1.\n    # The remaining physical experts (num_redundant) will be assigned in the loop.\n    phy2log = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    phy2log[:, :num_log] = torch.arange(num_log, dtype=torch.int64, device=device).unsqueeze(0).expand(n, -1)\n    \n    # Initialize rank: The first num_log physical experts are rank 0 for their respective logical experts.\n    # Ranks for redundant experts will be assigned in the loop.\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    \n    # logcnt tracks the number of replicas *already assigned* for each logical expert.\n    # Initially, each logical expert has 1 replica (the first num_log physical experts).\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Assign redundant physical experts\n    for i in range(num_log, num_phy):\n        # Find the logical expert that currently has the minimum average load (weight / #replicas)\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        \n        # Assign this physical expert (index i) to the chosen logical expert\n        phy2log[:, i] = redundant_indices\n        \n        # Assign the replica rank for this physical expert.\n        # This rank is the current count of replicas for the chosen logical expert (0-indexed).\n        rank[:, i] = logcnt[arangen, redundant_indices] - 1\n        \n        # Increment the count of replicas for the chosen logical expert\n        logcnt[arangen, redundant_indices] += 1\n        \n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Unified rebalancing logic:\n    # The hierarchical approach is used when num_groups is divisible by num_nodes.\n    # Otherwise, it falls back to a global balancing strategy by setting num_nodes=1 and num_groups=1.\n    # We can simplify this by directly implementing the global strategy when needed,\n    # or by ensuring the hierarchical logic correctly handles num_nodes=1.\n\n    # Determine the effective number of groups and nodes for balancing.\n    # If num_groups is not divisible by num_nodes, we treat it as a single group\n    # across all nodes for the first level of balancing.\n    effective_num_groups = num_groups if num_groups % num_nodes == 0 else 1\n    effective_num_nodes = num_nodes if num_groups % num_nodes == 0 else 1\n\n    # If num_groups % num_nodes != 0, we effectively want to balance across all groups as if they were one large group.\n    # And then balance those groups onto nodes.\n    # This is equivalent to setting num_nodes = 1 and num_groups = 1 in the hierarchical logic.\n    # Let's adjust parameters for a unified call to a simplified hierarchical logic.\n\n    # Simplified approach:\n    # First, balance logical experts across groups within layers.\n    # Then, balance these groups across nodes.\n    # Finally, replicate experts within nodes to balance across GPUs.\n\n    # Step 1: Balance logical experts into groups.\n    # If num_groups == 1, this step is trivial and doesn't change anything.\n    group_size = num_logical_experts // num_groups\n    tokens_per_group_layer = weight.unflatten(-1, (num_groups, group_size)).sum(-1) # [num_layers, num_groups]\n\n    # Pack groups onto nodes.\n    # If num_groups % num_nodes != 0, we effectively want to balance all groups onto a single 'node' conceptually,\n    # and then distribute those across the actual num_nodes.\n    # Let's consider the case where num_groups is not divisible by num_nodes.\n    # The original code uses num_nodes for packing groups. If num_groups < num_nodes, this packing might be problematic.\n    # A more robust approach is to balance groups onto num_nodes, and if num_groups < num_nodes, some nodes get 0 groups.\n    # The current `balanced_packing` assumes num_groups is divisible by num_packs (num_nodes here).\n\n    # Let's redefine the packing strategy:\n    # We want to pack 'num_groups' items (groups) into 'num_nodes' packs.\n    # If num_groups is not divisible by num_nodes, balanced_packing needs to handle it.\n    # The current `balanced_packing` asserts `num_groups % num_packs == 0`.\n    # This means if num_groups % num_nodes != 0, the original code calls `rebalance_experts_hierarchical` with num_nodes=1, num_groups=1.\n    # This is a global balancing strategy.\n\n    # Let's ensure the function call correctly reflects the intended strategy.\n    # If num_groups % num_nodes == 0, use hierarchical.\n    # Otherwise, use global (which is hierarchical with num_nodes=1, num_groups=1).\n\n    if num_groups % num_nodes == 0:\n        # Hierarchical balancing: balance groups to nodes, then nodes to GPUs.\n        # Step 1: Pack groups to nodes.\n        group_pack_index, group_rank_in_pack = balanced_packing(tokens_per_group_layer, num_nodes)\n        # Map logical experts to \"middle\" logical experts (logical experts per node)\n        # log2mlog: [num_layers, num_logical_experts] -> maps logical expert to its middle logical expert\n        mlog2log_map = (((group_pack_index * groups_per_node + group_rank_in_pack) * group_size).unsqueeze(-1) +\n                        torch.arange(group_size, dtype=torch.int64, device=group_pack_index.device)).flatten(-2)\n        # mlog2log_map: [num_layers, num_logical_experts] maps each logical expert to its \"middle\" logical expert ID.\n        # We need the inverse mapping for `weight.gather` later.\n        # This inverse mapping is tricky because multiple logical experts can map to the same middle expert.\n        # The `inverse` function is designed for permutations, which isn't directly applicable here.\n\n        # Let's rethink the mapping and replication.\n        # We have `num_layers` of `weight` ([num_layers, num_logical_experts]).\n        # First, we group logical experts: `tokens_per_group_layer` ([num_layers, num_groups]).\n        # Then, we pack these groups onto `num_nodes`: `group_pack_index` ([num_layers, num_groups]) and `group_rank_in_pack` ([num_layers, num_groups]).\n        # This means `num_groups` are assigned to `num_nodes`. `groups_per_node` groups per node.\n        # So, we have `num_layers * num_nodes` \"node-level\" expert weight tensors.\n        # Each node-level tensor has `num_logical_experts // num_nodes` \"middle\" experts.\n\n        # Let's create the \"middle\" logical experts' weights.\n        # `mlog_weights`: [num_layers * num_nodes, num_logical_experts // num_nodes]\n        # This requires carefully gathering weights.\n        # The `mlog2log` mapping needs to be constructed correctly.\n\n        # `mlog2log_map` assigns each logical expert to a conceptual \"middle\" logical expert.\n        # e.g., if num_logical_experts=8, num_groups=2, group_size=4.\n        # Group 0 contains logical experts 0,1,2,3. Group 1 contains 4,5,6,7.\n        # If num_nodes=2, groups_per_node=1.\n        # Group 0 (log experts 0-3) goes to node 0. Group 1 (log experts 4-7) goes to node 1.\n        # Node 0 has 1 middle expert. Node 1 has 1 middle expert.\n        # Middle expert for node 0 is logical experts 0-3. Middle expert for node 1 is 4-7.\n        # The mapping `mlog2log_map` should map:\n        # 0,1,2,3 -> 0 (on node 0)\n        # 4,5,6,7 -> 0 (on node 1)\n        # The current `mlog2log` calculation seems to be constructing the indices of the middle experts.\n        # `log2mlog` is `[num_layers, num_logical_experts]`.\n        # It maps logical expert ID to its index within the middle expert group.\n        # The `mlog2log` is the inverse of this index mapping.\n\n        # Let's reconstruct `mlog2log` and `tokens_per_mlog` more directly.\n        # For each layer, we have `num_groups` of `group_size`.\n        # `group_pack_index`: [num_layers, num_groups] - node assignment for each group.\n        # `group_rank_in_pack`: [num_layers, num_groups] - index of group within the node's assigned groups.\n\n        # We want to create `num_layers * num_nodes` \"node-level\" expert groups.\n        # Each node-level group corresponds to a set of original logical experts.\n        # The `tokens_per_mlog` should be `[num_layers * num_nodes, num_logical_experts // num_nodes]`.\n\n        # Calculate the logical expert index for each \"middle\" expert.\n        # `mlog_expert_indices`: [num_layers, num_nodes, groups_per_node, group_size]\n        # This is becoming complex. Let's simplify the conceptualization.\n\n        # Simpler approach:\n        # 1. Pack groups to nodes. This determines which logical experts are grouped together on each node.\n        # `group_pack_index`: [num_layers, num_groups] -> node ID for each group.\n        # `group_rank_in_pack`: [num_layers, num_groups] -> rank within node for each group.\n\n        # 2. For each node, create a combined weight tensor for the logical experts assigned to it.\n        #    The number of logical experts per node will be `groups_per_node * group_size`.\n        #    We need to gather the weights of logical experts based on `group_pack_index`.\n\n        # Let's create a mapping from (layer, node) to a contiguous block of logical experts.\n        # `node_logical_expert_map`: [num_layers, num_nodes, groups_per_node * group_size]\n\n        # This requires constructing a permutation for each layer and node.\n        # The original `mlog2log` calculation is:\n        # `((group_pack_index * groups_per_node + group_rank_in_pack) * group_size)`\n        # This forms a base index for each logical expert.\n        # `log2mlog` is this base index + `arange(group_size)`.\n        # `mlog2log` is the inverse of `log2mlog`.\n\n        # Let's directly construct the `tokens_per_mlog` and `mlog2log`.\n        # `tokens_per_mlog` is the weight tensor for experts *within* each node, considering the grouped logical experts.\n        # The number of such \"middle\" experts per node is `groups_per_node * group_size`.\n\n        # For each layer:\n        # `group_pack_index` tells us which node each group belongs to.\n        # `group_rank_in_pack` tells us the order within the node.\n\n        # Let's create `num_layers * num_nodes` tensors, each of size `groups_per_node * group_size`.\n        # `mlog_weights`: [num_layers * num_nodes, groups_per_node * group_size]\n        # `mlog_to_orig_log_map`: [num_layers * num_nodes, groups_per_node * group_size]\n\n        # Example: num_layers=1, num_logical_experts=8, num_groups=2, group_size=4, num_nodes=2, groups_per_node=1, num_gpus=2, phy_experts_per_gpu=1.\n        # weight: [1, 8]\n        # tokens_per_group_layer: [1, 2] (sum of weights for group 0 and group 1)\n        # balanced_packing(tokens_per_group_layer, num_nodes=2) ->\n        #   group_pack_index: [1, 2] -> [[0, 1]] (group 0 to node 0, group 1 to node 1)\n        #   group_rank_in_pack: [1, 2] -> [[0, 0]] (rank 0 within node for both groups)\n        # groups_per_node = 1, group_size = 4.\n\n        # Middle expert for node 0 is logical experts 0,1,2,3.\n        # Middle expert for node 1 is logical experts 4,5,6,7.\n        # `mlog_to_orig_log_map` for node 0 should be [0,1,2,3].\n        # `mlog_to_orig_log_map` for node 1 should be [4,5,6,7].\n\n        # The original `mlog2log` calculation:\n        # `base_idx = (group_pack_index * groups_per_node + group_rank_in_pack) * group_size`\n        # `base_idx`: [1, 2] -> [[0*1+0, 1*1+0]] * 4 = [[0, 4]]\n        # `log2mlog`: `base_idx.unsqueeze(-1) + torch.arange(group_size)`\n        # `log2mlog`: [[0, 4]].unsqueeze(-1) + [0,1,2,3] -> [[0,1,2,3], [4,5,6,7]]\n        # This `log2mlog` is `[num_layers, num_logical_experts]`. It maps original logical expert ID to its \"middle\" expert index.\n        # The original logic uses `weight.gather(-1, mlog2log)` which is incorrect here.\n        # `weight.gather(-1, mlog2log)` expects `mlog2log` to be `[num_layers, num_middle_experts]` where `num_middle_experts` is the number of columns in `weight`.\n        # The shape should be `[num_layers, num_logical_experts]` if we are gathering from `weight` which is `[num_layers, num_logical_experts]`.\n        # The `mlog2log` calculated here has shape `[num_layers, num_logical_experts]`.\n        # It maps `original_logical_expert_id` to `middle_expert_id`.\n        # We need to gather `weight[layer, original_logical_expert_id]` and group them by `middle_expert_id`.\n\n        # Let's create `mlog_weights` directly.\n        # `mlog_weights`: [num_layers * num_nodes, groups_per_node * group_size]\n        # `mlog_to_orig_log_map`: [num_layers * num_nodes, groups_per_node * group_size]\n\n        # Vectorized construction of mlog_weights and mlog_to_orig_log_map\n        # This replaces the nested Python loops for better performance.\n\n        # Calculate the new \"middle expert group\" index for each original group.\n        # This new index combines node assignment and rank within the node.\n        # Shape: [num_layers, num_groups]\n        new_group_idx = group_pack_index * groups_per_node + group_rank_in_pack\n\n        # Create a tensor that maps new group index back to original group index.\n        # This is a permutation tensor for groups within each layer.\n        # Shape: [num_layers, num_nodes * groups_per_node] (which is num_groups)\n        group_permutation = torch.empty((num_layers, num_groups),\n                                        dtype=torch.int64,\n                                        device=weight.device)\n        group_permutation.scatter_(1, new_group_idx,\n                                   torch.arange(num_groups, device=weight.device).expand(num_layers, -1))\n\n        # Reshape original weights to [num_layers, num_groups, group_size]\n        weight_reshaped = weight.view(num_layers, num_groups, group_size)\n\n        # Gather weights based on the group_permutation\n        # The .gather() operation reorders the groups according to the permutation.\n        # Shape: [num_layers, num_groups, group_size]\n        mlog_weights_ordered = weight_reshaped.gather(1, group_permutation.unsqueeze(-1).expand(-1, -1, group_size))\n        \n        # Reshape to [num_layers, num_nodes, groups_per_node * group_size]\n        # This is the final mlog_weights.\n        mlog_weights = mlog_weights_ordered.view(num_layers, num_nodes, groups_per_node * group_size)\n\n        # Construct mlog_to_orig_log_map similarly\n        # Original logical expert IDs, reshaped to [num_groups, group_size]\n        orig_log_ids_reshaped = torch.arange(num_logical_experts,\n                                             dtype=torch.int64,\n                                             device=weight.device).view(num_groups, group_size)\n        \n        # Expand to [num_layers, num_groups, group_size] and gather\n        mlog_to_orig_log_map_ordered = orig_log_ids_reshaped.unsqueeze(0).expand(num_layers, -1, -1).gather(\n            1, group_permutation.unsqueeze(-1).expand(-1, -1, group_size))\n        \n        # Reshape to [num_layers, num_nodes, groups_per_node * group_size]\n        mlog_to_orig_log_map = mlog_to_orig_log_map_ordered.view(\n            num_layers, num_nodes, groups_per_node * group_size)\n\n        # Now, `mlog_weights`: [num_layers, num_nodes, num_logical_experts // num_nodes]\n        # And `mlog_to_orig_log_map`: [num_layers, num_nodes, num_logical_experts // num_nodes]\n\n        # Step 2: Replicate experts within each node.\n        # `mlog_weights` are the weights for experts within each node.\n        # `num_physical_experts // num_nodes` is the target number of physical experts per node.\n        # `replicate_experts` takes `[X, num_log]` and returns `phy2log`, `rank`, `logcnt`.\n        # Here, X = num_layers * num_nodes, num_log = num_logical_experts // num_nodes.\n        # So, we need to reshape `mlog_weights` and `mlog_to_orig_log_map`.\n\n        num_middle_experts = num_logical_experts // num_nodes\n        reshaped_mlog_weights = mlog_weights.view(-1, num_middle_experts)\n        reshaped_mlog_to_orig_log_map = mlog_to_orig_log_map.view(-1, num_middle_experts)\n\n        # `phy2mlog`: [num_layers * num_nodes, num_physical_experts // num_nodes]\n        # `phyrank`: [num_layers * num_nodes, num_physical_experts // num_nodes]\n        # `mlogcnt`: [num_layers * num_nodes, num_middle_experts]\n        phy2mlog, phyrank, mlogcnt = replicate_experts(\n            reshaped_mlog_weights, num_physical_experts // num_nodes)\n\n        # Step 3: Pack physical experts to GPUs.\n        # `phy2mlog` maps physical experts (within each node) to middle logical experts.\n        # `phy2mlog` is `[num_layers * num_nodes, num_phy_per_node]`\n        # `phyrank` is `[num_layers * num_nodes, num_phy_per_node]`\n        # `mlogcnt` is `[num_layers * num_nodes, num_middle_experts]`\n\n        # We need to map these back to global physical expert indices.\n        # The `phy2mlog` refers to the *middle* logical experts.\n        # The `replicate_experts` function returns `phy2log` which is the *original* logical expert ID.\n        # So, `phy2mlog` from `replicate_experts` is actually `[num_layers*num_nodes, num_phy_per_node]`,\n        # where each entry is an index into the *middle* logical experts.\n\n        # We need to map these `phy2mlog` indices back to original logical expert IDs.\n        # `reshaped_mlog_to_orig_log_map`: [num_layers * num_nodes, num_middle_experts]\n        # `final_phy2log_per_node`: [num_layers * num_nodes, num_phy_per_node]\n        final_phy2log_per_node = reshaped_mlog_to_orig_log_map.gather(-1, phy2mlog)\n\n        # `phyrank` is the replica rank for the middle experts.\n        # We need to combine this with `mlogcnt` to get the final `logcnt`.\n        # `mlogcnt` is `[num_layers * num_nodes, num_middle_experts]`. It tells us how many replicas each middle expert has.\n        # The `phyrank` is the rank of the replica for a *specific* middle expert.\n\n        # The `logcnt` returned by `replicate_experts` is `[X, num_log]`, which is `[num_layers*num_nodes, num_middle_experts]`.\n        # We need to map this back to `[num_layers, num_logical_experts]`.\n\n        # Let's use the `mlogcnt` directly to get the total count of replicas for each logical expert.\n        # `mlogcnt` is `[num_layers * num_nodes, num_middle_experts]`.\n        # We need to sum/average counts based on the `mlog_to_orig_log_map`.\n\n        # Let's refine the output mapping:\n        # `physical_to_logical_map`: [num_layers, num_replicas]\n        # `logical_to_physical_map`: [num_layers, num_logical_experts, X]\n        # `expert_count`: [num_layers, num_logical_experts]\n\n        # `final_phy2log_per_node`: [num_layers * num_nodes, num_phy_per_node]\n        # This is the logical expert ID for each physical expert *within its node*.\n        # We need to convert this to global physical expert IDs.\n        # Physical experts are grouped by GPU. `num_gpus` total, `num_gpus // num_nodes` per node.\n        # `phy_experts_per_gpu` = `num_physical_experts // num_gpus`.\n        # So, each GPU has `phy_experts_per_gpu` physical experts.\n        # Each Node has `num_gpus // num_nodes` GPUs.\n        # Total physical experts per node = `(num_gpus // num_nodes) * phy_experts_per_gpu`\n        # This should equal `num_physical_experts // num_nodes`.\n\n        # `final_phy2log_per_node`: [num_layers, num_nodes, num_phy_per_node]\n        # `final_rank_per_node`: [num_layers, num_nodes, num_phy_per_node] (this is `phyrank`)\n\n        # We need to flatten this to `[num_layers, num_physical_experts]`.\n        # `num_physical_experts = num_nodes * num_phy_per_node`.\n\n        # `final_phy2log_global`: [num_layers, num_physical_experts]\n        # `final_rank_global`: [num_layers, num_physical_experts]\n\n        # The `mlog_to_orig_log_map` correctly maps middle experts to original logical experts.\n        # `phy2mlog` maps physical experts (within a node) to middle experts.\n        # So, `phy2mlog.gather(-1, final_phy2log_per_node)` gives the logical expert ID.\n        # This is what `final_phy2log_per_node` already represents.\n\n        # Let's rename `final_phy2log_per_node` to `phy2log_per_node` for clarity.\n        phy2log_per_node = final_phy2log_per_node\n        rank_per_node = phyrank # [num_layers * num_nodes, num_phy_per_node]\n\n        # Flatten these to get global mappings for physical experts.\n        phy2log_global = phy2log_per_node.view(num_layers, -1)\n        rank_global = rank_per_node.view(num_layers, -1)\n\n        # Now, let's construct the `logcnt` (expert_count).\n        # `mlogcnt`: [num_layers * num_nodes, num_middle_experts]\n        # `mlog_to_orig_log_map`: [num_layers * num_nodes, num_middle_experts]\n\n        # We need to aggregate `mlogcnt` based on `mlog_to_orig_log_map`.\n        # For each logical expert, its total count is the sum of counts of its constituent middle experts.\n        # This aggregation needs to be done carefully.\n\n        # Let's create a tensor for `logcnt`: [num_layers, num_logical_experts] initialized to zeros.\n        expert_count = torch.zeros(num_layers, num_logical_experts, dtype=torch.int64, device=weight.device)\n\n        # Vectorized aggregation of mlogcnt to expert_count\n        # mlogcnt: [num_layers * num_nodes, num_middle_experts]\n        # mlog_to_orig_log_map: [num_layers, num_nodes, num_middle_experts]\n        \n        # Reshape mlog_to_orig_log_map to [num_layers, num_nodes * num_middle_experts]\n        # and mlogcnt to [num_layers, num_nodes * num_middle_experts]\n        mlog_to_orig_log_map_flat = mlog_to_orig_log_map.view(num_layers, -1)\n        mlogcnt_flat = mlogcnt.view(num_layers, -1)\n        \n        # Use scatter_add_ to efficiently sum counts for each original logical expert\n        expert_count = torch.zeros(num_layers, num_logical_experts, dtype=torch.int64, device=weight.device)\n        expert_count.scatter_add_(1, mlog_to_orig_log_map_flat, mlogcnt_flat)\n\n        return phy2log_global, rank_global, expert_count\n\n    else:\n        # Global balancing strategy: treat all experts as one group, balance across num_gpus.\n        # This is equivalent to calling the hierarchical function with num_nodes=1, num_groups=1.\n        # num_groups = 1 means group_size = num_logical_experts.\n        # num_nodes = 1 means groups_per_node = 1.\n        # The entire logic simplifies.\n\n        # Step 1: Pack logical experts to nodes (here, nodes = GPUs conceptually).\n        # `tokens_per_group` becomes `weight` itself since num_groups=1.\n        # `balanced_packing(weight, num_gpus)`\n        # `group_pack_index`: [num_layers, num_logical_experts] -> GPU assignment for each logical expert.\n        # `group_rank_in_pack`: [num_layers, num_logical_experts] -> rank within GPU for each logical expert.\n        # `num_nodes` becomes `num_gpus`. `groups_per_node` becomes `num_logical_experts // num_gpus`.\n\n        # We need to adapt `balanced_packing` to work with `num_packs = num_gpus`.\n        # The `groups_per_pack` in `balanced_packing` refers to items per pack.\n        # Here, items are logical experts. So, `groups_per_pack` = `num_logical_experts // num_gpus`.\n        # `num_packs` = `num_gpus`.\n\n        pack_index_gpu, rank_in_gpu = balanced_packing(weight, num_gpus)\n\n        # `pack_index_gpu`: [num_layers, num_logical_experts] -> GPU ID for each logical expert.\n        # `rank_in_gpu`: [num_layers, num_logical_experts] -> rank within GPU for each logical expert.\n\n        # Step 2: Replicate experts within GPUs.\n        # We need to create tensors for `replicate_experts` that represent experts *per GPU*.\n        # `num_logical_experts_per_gpu` = `num_logical_experts // num_gpus`.\n        # `num_physical_experts_per_gpu` = `num_physical_experts // num_gpus`.\n\n        # For each GPU, we have a set of logical experts.\n        # We need to gather weights for logical experts assigned to the same GPU.\n        # `gpu_logical_weights`: [num_gpus, num_logical_experts_per_gpu, num_layers] (transposed for replicate_experts)\n        # `gpu_logical_to_orig_map`: [num_gpus, num_logical_experts_per_gpu]\n\n        # Vectorized construction of gpu_logical_weights and gpu_logical_to_orig_map\n        # This replaces the nested Python loops for better performance.\n\n        num_logical_experts_per_gpu = num_logical_experts // num_gpus\n\n        # Calculate the new \"middle expert group\" index for each original logical expert.\n        # This new index combines GPU assignment and rank within the GPU.\n        # Shape: [num_layers, num_logical_experts]\n        new_logical_expert_idx_on_gpu = pack_index_gpu * num_logical_experts_per_gpu + rank_in_gpu\n\n        # Create a tensor that maps new logical expert index back to original logical expert index.\n        # This is a permutation tensor for logical experts within each layer.\n        # Shape: [num_layers, num_gpus * num_logical_experts_per_gpu] (which is num_logical_experts)\n        logical_expert_permutation = torch.empty((num_layers, num_logical_experts),\n                                                 dtype=torch.int64,\n                                                 device=weight.device)\n        logical_expert_permutation.scatter_(1, new_logical_expert_idx_on_gpu,\n                                            torch.arange(num_logical_experts, device=weight.device).expand(num_layers, -1))\n\n        # Gather weights based on the logical_expert_permutation\n        # Shape: [num_layers, num_logical_experts]\n        gpu_logical_weights_ordered = weight.gather(1, logical_expert_permutation)\n        \n        # Reshape to [num_gpus, num_layers, num_logical_experts_per_gpu] for subsequent processing\n        # and ensure contiguous memory layout.\n        gpu_logical_weights = gpu_logical_weights_ordered.view(\n            num_layers, num_gpus, num_logical_experts_per_gpu).permute(1, 0, 2).contiguous()\n\n        # Construct gpu_logical_to_orig_map similarly\n        # Original logical expert IDs, expanded to [num_layers, num_logical_experts]\n        orig_log_ids_expanded = torch.arange(num_logical_experts,\n                                             dtype=torch.int64,\n                                             device=weight.device).unsqueeze(0).expand(num_layers, -1)\n        \n        # Gather original logical expert IDs based on the permutation\n        gpu_logical_to_orig_map_ordered = orig_log_ids_expanded.gather(1, logical_expert_permutation)\n        \n        # Reshape to [num_gpus * num_layers, num_logical_experts_per_gpu] for replicate_experts input\n        gpu_logical_to_orig_map = gpu_logical_to_orig_map_ordered.view(\n            num_layers, num_gpus, num_logical_experts_per_gpu).permute(1, 0, 2).contiguous().view(\n                -1, num_logical_experts_per_gpu)\n\n        # Reshape for `replicate_experts`: [num_gpus * num_layers, num_logical_experts_per_gpu]\n        reshaped_gpu_logical_weights = gpu_logical_weights.view(-1, num_logical_experts_per_gpu)\n        reshaped_gpu_logical_to_orig_map = gpu_logical_to_orig_map.view(-1, num_logical_experts_per_gpu)\n\n        # `replicate_experts` is called with `num_phy = num_physical_experts // num_gpus` (target physical experts per GPU).\n        # `X` becomes `num_gpus * num_layers`. `num_log` becomes `num_logical_experts_per_gpu`.\n        # `phy2log_gpu`: [num_gpus * num_layers, num_phy_per_gpu]\n        # `phyrank_gpu`: [num_gpus * num_layers, num_phy_per_gpu]\n        # `gpu_logcnt`: [num_gpus * num_layers, num_logical_experts_per_gpu]\n        phy2log_gpu, phyrank_gpu, gpu_logcnt = replicate_experts(\n            reshaped_gpu_logical_weights, num_physical_experts // num_gpus)\n\n        # Map `phy2log_gpu` back to original logical expert IDs using `reshaped_gpu_logical_to_orig_map`.\n        # `phy2log_global`: [num_gpus * num_layers, num_phy_per_gpu]\n        phy2log_global = reshaped_gpu_logical_to_orig_map.gather(-1, phy2log_gpu)\n\n        # Flatten to get the final `physical_to_logical_map` and `rank`.\n        # The `rank_global` is `phyrank_gpu`.\n        rank_global = phyrank_gpu\n\n        # Construct `expert_count` ([num_layers, num_logical_experts]).\n        # `gpu_logcnt`: [num_gpus * num_layers, num_logical_experts_per_gpu]\n        expert_count = torch.zeros(num_layers, num_logical_experts, dtype=torch.int64, device=weight.device)\n\n        for gpu_layer_idx in range(num_gpus * num_layers):\n            layer_idx = gpu_layer_idx // num_gpus\n            # Get the original logical expert indices for this gpu_layer combination\n            orig_log_indices = reshaped_gpu_logical_to_orig_map[gpu_layer_idx] # [num_logical_experts_per_gpu]\n            counts_for_orig_logs = gpu_logcnt[gpu_layer_idx] # [num_logical_experts_per_gpu]\n\n            # Add these counts to the correct positions in the expert_count tensor\n            expert_count[layer_idx].index_add_(0, orig_log_indices, counts_for_orig_logs)\n\n        # Construct `logical_to_physical_map` ([num_layers, num_logical_experts, X])\n        max_replicas_per_expert = (num_physical_experts + num_logical_experts - 1) // num_logical_experts\n\n        logical_to_physical_map = torch.full((num_layers, num_logical_experts, max_replicas_per_expert), -1, dtype=torch.int64, device=weight.device)\n\n        # Need to map `phy2log_global` and `rank_global` to the correct positions.\n        # `phy2log_global` are indices into the *original* logical experts.\n        # `rank_global` is the replica rank for that original logical expert.\n\n        # Reshape to get mappings per layer and then iterate through physical experts.\n        phy2log_global_reshaped = phy2log_global.view(num_gpus, num_layers, -1).permute(1, 0, 2).contiguous()\n        rank_global_reshaped = rank_global.view(num_gpus, num_layers, -1).permute(1, 0, 2).contiguous()\n\n        # Iterate through all physical experts\n        for layer_idx in range(num_layers):\n            for gpu_idx in range(num_gpus):\n                for phys_idx_in_gpu in range(num_physical_experts // num_gpus):\n                    # Get the global physical expert index\n                    global_phys_idx = gpu_idx * (num_physical_experts // num_gpus) + phys_idx_in_gpu\n\n                    log_expert_id = phy2log_global_reshaped[layer_idx, gpu_idx, phys_idx_in_gpu]\n                    replica_rank = rank_global_reshaped[layer_idx, gpu_idx, phys_idx_in_gpu]\n\n                    if log_expert_id >= 0 and log_expert_id < num_logical_experts:\n                        if replica_rank < max_replicas_per_expert:\n                            logical_to_physical_map[layer_idx, log_expert_id, replica_rank] = global_phys_idx\n                        else:\n                            pass # Handle error or log\n\n        # The `phy2log_global` needs to be reshaped to `[num_layers, num_replicas]`\n        # where `num_replicas` is `num_physical_experts`.\n        # `phy2log_global` is currently `[num_gpus * num_layers, num_phy_per_gpu]`.\n        # We need to combine these.\n        # The order of physical experts should be consistent.\n        # Let's reconstruct `phy2log_global` to be `[num_layers, num_physical_experts]`.\n\n        final_phy2log_global = torch.empty((num_layers, num_physical_experts), dtype=torch.int64, device=weight.device)\n        current_phys_idx = 0\n        for gpu_idx in range(num_gpus):\n            for layer_idx in range(num_layers):\n                # Calculate the range of physical experts for this GPU and layer combination\n                start_phys_idx = layer_idx * num_gpus * (num_physical_experts // num_gpus) + gpu_idx * (num_physical_experts // num_gpus)\n                end_phys_idx = start_phys_idx + (num_physical_experts // num_gpus)\n\n                # The `phy2log_global` calculated earlier is `[num_gpus * num_layers, num_phy_per_gpu]`\n                # We need to map it correctly.\n                # `phy2log_gpu` was `[num_gpus * num_layers, num_phy_per_gpu]`\n                # `reshaped_gpu_logical_to_orig_map` was `[num_gpus * num_layers, num_phy_per_gpu]`\n                # `phy2log_global = reshaped_gpu_logical_to_orig_map.gather(-1, phy2log_gpu)`\n\n                # The indices for `phy2log_global` should be:\n                # For layer 0, GPU 0: phys experts 0 to num_phy_per_gpu - 1\n                # For layer 0, GPU 1: phys experts num_phy_per_gpu to 2*num_phy_per_gpu - 1\n                # ...\n                # For layer 1, GPU 0: phys experts num_gpus * num_phy_per_gpu to (num_gpus+1)*num_phy_per_gpu - 1\n\n                # Let's re-index the `phy2log_global` and `rank_global` to match `[num_layers, num_physical_experts]`\n                # The current `phy2log_global` is effectively `[num_layers * num_gpus, num_phy_per_gpu]`\n                # We need to rearrange it.\n\n                # Example: num_layers=2, num_gpus=2, num_phy_per_gpu=2. num_physical_experts=4.\n                # phy2log_global:\n                # [layer0_gpu0_phys0, layer0_gpu0_phys1,\n                #  layer0_gpu1_phys0, layer0_gpu1_phys1,\n                #  layer1_gpu0_phys0, layer1_gpu0_phys1,\n                #  layer1_gpu1_phys0, layer1_gpu1_phys1]\n                # Reshaped to [num_gpus*num_layers, num_phy_per_gpu] -> [4, 2]\n                # We want [num_layers, num_physical_experts] -> [2, 4]\n\n                # The current `phy2log_global` is `[num_gpus * num_layers, num_phy_per_gpu]`.\n                # Permute and reshape:\n                # `view(num_gpus, num_layers, -1)` gives `[num_gpus, num_layers, num_phy_per_gpu]`\n                # `permute(1, 0, 2)` gives `[num_layers, num_gpus, num_phy_per_gpu]`\n                # `contiguous().view(num_layers, -1)` gives `[num_layers, num_gpus * num_phy_per_gpu]` = `[num_layers, num_physical_experts]`\n\n                final_phy2log_global = phy2log_global.view(num_gpus, num_layers, -1).permute(1, 0, 2).contiguous().view(num_layers, num_physical_experts)\n                final_rank_global = rank_global.view(num_gpus, num_layers, -1).permute(1, 0, 2).contiguous().view(num_layers, num_physical_experts)\n\n        # Return the results for global balancing.\n        return final_phy2log_global, logical_to_physical_map, expert_count\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float() # Ensure float type, keep on original device\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log_global, rank_global, expert_count = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log_global, rank_global, expert_count = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n\n    # Compute logical_to_physical_map once, using the global mappings\n    num_logical_experts = weight.shape[1]\n    num_physical_experts = num_replicas # Renaming for clarity based on function signature\n\n    # Compute the actual maximum number of replicas any logical expert has\n    # This is more robust than a global average based on num_physical_experts.\n    # Handle cases where expert_count might be empty or all zeros.\n    max_replicas_per_expert = expert_count.max().item() if expert_count.numel() > 0 else 0\n    if num_physical_experts > 0 and max_replicas_per_expert == 0:\n        # If there are physical experts but expert_count somehow indicates zero replicas,\n        # it implies each expert has at least one replica. This is a safeguard.\n        max_replicas_per_expert = 1\n    elif num_physical_experts == 0:\n        # If no physical experts, then max_replicas_per_expert should be 0.\n        max_replicas_per_expert = 0\n\n    logical_to_physical_map = torch.full((num_layers, num_logical_experts, max_replicas_per_expert),\n                                         -1, dtype=torch.int64, device=weight.device)\n\n    # Vectorized computation of replica ranks and population of logical_to_physical_map\n    # 1. Create flat tensors representing (layer_idx, logical_expert_id, physical_expert_id) for each physical expert.\n    layer_indices_flat = torch.arange(num_layers, device=weight.device).unsqueeze(1).expand(-1, num_physical_experts).flatten()\n    phys_expert_ids_flat = torch.arange(num_physical_experts, device=weight.device).unsqueeze(0).expand(num_layers, -1).flatten()\n    log_expert_ids_flat = phy2log_global.flatten()\n\n    # 2. Create a combined key for sorting: (layer_idx, logical_expert_id)\n    #    This ensures that physical experts mapping to the same (layer, logical_expert_id) are grouped together.\n    #    (num_logical_experts + 1) is used as a multiplier to guarantee unique sorting order.\n    sorting_keys = layer_indices_flat * (num_logical_experts + 1) + log_expert_ids_flat\n\n    # 3. Sort by the combined key to group physical experts by (layer, logical_expert_id)\n    sorted_keys, sort_indices = sorting_keys.sort()\n\n    # Apply sort_indices to reorder the flat tensors\n    log_expert_ids_sorted = log_expert_ids_flat[sort_indices]\n    phys_expert_ids_sorted = phys_expert_ids_flat[sort_indices]\n    layer_indices_sorted = layer_indices_flat[sort_indices]\n\n    # 4. Compute the replica rank within each (layer, logical_expert_id) group.\n    #    This is done by identifying where the (layer, logical_expert_id) pair changes.\n    #    `diff` is 1 where a new group starts, 0 otherwise.\n    #    `cumsum` then assigns sequential ranks (0, 1, 2, ...) within each group.\n    \n    # Compare current element with previous element for changes in (layer, log_expert_id)\n    diff = (log_expert_ids_sorted[1:] != log_expert_ids_sorted[:-1]) | \\\n           (layer_indices_sorted[1:] != layer_indices_sorted[:-1])\n    \n    # Prepend `True` (or `1`) to start the first group with rank 0, then compute cumulative sum\n    replica_ranks_sorted = torch.cat((torch.tensor([0], device=weight.device), diff.long())).cumsum(0) - 1\n\n    # 5. Scatter the physical expert IDs into the `logical_to_physical_map`.\n    #    First, filter out any ranks that might exceed `max_replicas_per_expert` (though this should ideally not happen\n    #    if `max_replicas_per_expert` is correctly derived from `expert_count`).\n    valid_mask = (replica_ranks_sorted < max_replicas_per_expert)\n    \n    layer_indices_valid = layer_indices_sorted[valid_mask]\n    log_expert_ids_valid = log_expert_ids_sorted[valid_mask]\n    replica_ranks_valid = replica_ranks_sorted[valid_mask]\n    phys_expert_ids_valid = phys_expert_ids_sorted[valid_mask]\n\n    # Calculate flattened indices for the `logical_to_physical_map` tensor\n    flat_indices = layer_indices_valid * (num_logical_experts * max_replicas_per_expert) + \\\n                   log_expert_ids_valid * max_replicas_per_expert + \\\n                   replica_ranks_valid\n    \n    # Flatten `logical_to_physical_map` for the scatter operation\n    logical_to_physical_map_flat = logical_to_physical_map.flatten()\n    \n    # Perform the scatter operation: assign `phys_expert_ids_valid` to the calculated flat indices.\n    logical_to_physical_map_flat.scatter_(0, flat_indices, phys_expert_ids_valid)\n\n    return phy2log_global, logical_to_physical_map, expert_count\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n", "language": "python", "parent_id": "24391771-7aff-4942-9232-3b6a1c898e81", "generation": 5, "timestamp": 1751052204.038393, "iteration_found": 38, "metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "index -1 is out of bounds for dimension 0 with size 133632"}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 31 lines with 52 lines\nChange 2: Replace 12 lines with 68 lines", "parent_metrics": {"balancedness_score": 0.0, "speed_score": 0.0, "combined_score": 0.0, "error": "index 2 is out of bounds for dimension 2 with size 2"}, "island": 1}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert programmer specializing in optimization algorithms. Your task is to improve the Mixture-of-Expert models Expert Parallelism Load Balancer (MoE EPLB) expert rearrangement algorithm.\nThis algorithm will take the load metrics recorded by the vLLM server, and rearrange the experts to balance the load. It can make replicas of some experts to achieve better load balancing.\nYour goal will be two-fold: 1. Improve the algorithm to achieve better load balancing; while 2. Improve the algorithm to be more efficient, i.e. reduce the execution time of the algorithm itself, since perfect load balancing is NP-hard.\nThe current algorithm is implemented in the `rebalance_experts` function. ", "user": "# Current Program Information\n- Current performance metrics: - balancedness_score: 0.0000\n- speed_score: 0.0000\n- combined_score: 0.0000\n- error: index 2 is out of bounds for dimension 2 with size 2\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: balancedness_score, speed_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0350, combined_score: 0.1667\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0405, combined_score: 0.1694\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: balancedness_score: 0.2983, speed_score: 0.0761, combined_score: 0.1872\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.1872)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0761), Performs well on combined_score (0.1872)\n\n\n### Program 2 (Score: 0.1694)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0405), Performs well on combined_score (0.1694)\n\n\n### Program 3 (Score: 0.1667)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\n# ... (truncated for brevity)\n```\nKey features: Performs well on balancedness_score (0.2983), Performs well on speed_score (0.0350), Performs well on combined_score (0.1667)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.1661)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n\n### Program D2 (Score: 0.1645)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n# ... (truncated)\n```\nKey features: Alternative approach to balancedness_score, Alternative approach to speed_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.1872, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Alternative balancedness_score approach, Alternative speed_score approach, Alternative combined_score approach\n\n\n### Inspiration 2 (Score: 0.0872, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 87 lines with 89 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 3 (Score: 0.0872, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 87 lines with 89 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 4 (Score: 0.0872, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 87 lines with 89 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n### Inspiration 5 (Score: 0.0872, Type: Exploratory)\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n# ... (truncated for brevity)\n```\nUnique approach: Modification: Change 1: Replace 87 lines with 89 lines, Alternative balancedness_score approach, Alternative speed_score approach\n\n\n\n# Current Program\n```python\n# SPDX-License-Identifier: Apache-2.0\n\"\"\"\nExpert parallelism load balancer (EPLB) for vLLM.\n\nThis module implements the core rearrangement algorithm.\n\nThe rearrangement algorithm is adapted from\n[DeepSeek EPLB](https://github.com/deepseek-ai/eplb).\n\nPlease find at [#12](https://github.com/deepseek-ai/EPLB/issues/12) an example\non how the EPLB algorithm works.\n\"\"\"\n\n# EVOLVE-BLOCK-START\n\nimport torch\n\n\ndef balanced_packing(weight: torch.Tensor,\n                     num_packs: int) -> tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Pack n weighted objects to m packs, such that each bin contains exactly\n    n/m objects and the weights of all packs are as balanced as possible.\n\n    Parameters:\n        weight: [X, n], the weight of each item\n        num_packs: number of packs\n\n    Returns:\n        pack_index: [X, n], the pack index of each item\n        rank_in_pack: [X, n], the rank of the item in the pack\n    \"\"\"\n    num_layers, num_groups = weight.shape\n    assert num_groups % num_packs == 0\n    groups_per_pack = num_groups // num_packs\n\n    if groups_per_pack == 1:\n        pack_index = torch.arange(weight.size(-1),\n                                  dtype=torch.int64,\n                                  device=weight.device).expand(weight.shape)\n        rank_in_pack = torch.zeros_like(weight, dtype=torch.int64)\n        return pack_index, rank_in_pack\n\n    # Optimized balanced_packing using torch.min and broadcasting\n    # (The initial `if groups_per_pack == 1` block is already handled above this SEARCH block)\n\n    # Sort weights and get indices\n    # Ensure weight is float for sorting, keep on original device\n    sorted_weights, sorted_indices = weight.float().sort(-1, descending=True)\n\n    # Initialize pack_index and rank_in_pack on the same device as weight\n    pack_index = torch.full((num_layers, num_groups), -1, dtype=torch.int64, device=weight.device)\n    rank_in_pack = torch.full((num_layers, num_groups), -1, dtype=torch.int64, device=weight.device)\n\n    # Initialize pack_loads and pack_counts on the same device as weight\n    pack_loads = torch.zeros(num_layers, num_packs, dtype=torch.float32, device=weight.device)\n    pack_counts = torch.zeros(num_layers, num_packs, dtype=torch.int64, device=weight.device)\n\n    # Vectorized assignment: Iterate through sorted items and assign them to the least loaded pack\n    # This loop processes all layers simultaneously for each item 'g'\n    for g in range(num_groups):\n        # Find the pack with the minimum current load and available slots for all layers\n        # Use a large value for unavailable packs to ensure they are not chosen\n        available_packs_mask = (pack_counts < groups_per_pack)\n        current_pack_loads_masked = pack_loads.masked_fill(~available_packs_mask, float('inf'))\n        \n        # chosen_pack_idx_for_layers will be [num_layers]\n        chosen_pack_idx_for_layers = torch.argmin(current_pack_loads_masked, dim=-1)\n\n        # Get original group index and its weight for current item 'g' across all layers\n        original_group_idx_for_layers = sorted_indices[:, g] # Shape [num_layers]\n        current_item_weights_for_layers = weight[torch.arange(num_layers, device=weight.device), original_group_idx_for_layers] # Shape [num_layers]\n\n        # Update pack_loads: Add current item's weight to the chosen pack for each layer\n        # Use scatter_add_ for efficient update\n        # index: [num_layers, 1], src: [num_layers, 1]\n        pack_loads.scatter_add_(1, chosen_pack_idx_for_layers.unsqueeze(1), current_item_weights_for_layers.unsqueeze(1))\n        \n        # Update pack_counts: Increment count for the chosen pack for each layer\n        # index: [num_layers, 1], src: [num_layers, 1] (ones)\n        pack_counts.scatter_add_(1, chosen_pack_idx_for_layers.unsqueeze(1), torch.ones_like(chosen_pack_idx_for_layers).unsqueeze(1))\n\n        # Update pack_index: Assign the chosen pack ID to the original group index\n        # index: [num_layers, 1], src: [num_layers, 1]\n        pack_index.scatter_(1, original_group_idx_for_layers.unsqueeze(1), chosen_pack_idx_for_layers.unsqueeze(1))\n        \n        # Update rank_in_pack: Assign the rank within the pack.\n        # The rank is the count BEFORE the current item was added.\n        # pack_counts has already been incremented, so subtract 1.\n        # index: [num_layers, 1], src: [num_layers, 1]\n        rank_in_pack.scatter_(1, original_group_idx_for_layers.unsqueeze(1), (pack_counts.gather(1, chosen_pack_idx_for_layers.unsqueeze(1)) - 1))\n\n    return pack_index, rank_in_pack\n\n\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices] - 1 # Adjust to 0-indexed rank\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n\n\ndef rebalance_experts_hierarchical(\n    weight: torch.Tensor,\n    num_physical_experts: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n):\n    \"\"\"\n    Parameters:\n        weight: [num_moe_layers, num_logical_experts]\n        num_physical_experts: number of physical experts after replication\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n        (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [num_moe_layers, num_physical_experts]\n        logical_to_physical_map: [num_moe_layers, num_logical_experts, X]\n        logical_count: [num_moe_layers, num_logical_experts]\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    assert num_logical_experts % num_groups == 0\n    group_size = num_logical_experts // num_groups\n    assert num_groups % num_nodes == 0\n    groups_per_node = num_groups // num_nodes\n    assert num_gpus % num_nodes == 0\n    assert num_physical_experts % num_gpus == 0\n    phy_experts_per_gpu = num_physical_experts // num_gpus\n\n    def inverse(perm: torch.Tensor) -> torch.Tensor:\n        inv = torch.empty_like(perm)\n        inv.scatter_(\n            1,\n            perm,\n            torch.arange(perm.size(1), dtype=torch.int64,\n                         device=perm.device).expand(perm.shape),\n        )\n        return inv\n\n    # Unified rebalancing logic:\n    # The hierarchical approach is used when num_groups is divisible by num_nodes.\n    # Otherwise, it falls back to a global balancing strategy by setting num_nodes=1 and num_groups=1.\n    # We can simplify this by directly implementing the global strategy when needed,\n    # or by ensuring the hierarchical logic correctly handles num_nodes=1.\n\n    # Determine the effective number of groups and nodes for balancing.\n    # If num_groups is not divisible by num_nodes, we treat it as a single group\n    # across all nodes for the first level of balancing.\n    effective_num_groups = num_groups if num_groups % num_nodes == 0 else 1\n    effective_num_nodes = num_nodes if num_groups % num_nodes == 0 else 1\n\n    # If num_groups % num_nodes != 0, we effectively want to balance across all groups as if they were one large group.\n    # And then balance those groups onto nodes.\n    # This is equivalent to setting num_nodes = 1 and num_groups = 1 in the hierarchical logic.\n    # Let's adjust parameters for a unified call to a simplified hierarchical logic.\n\n    # Simplified approach:\n    # First, balance logical experts across groups within layers.\n    # Then, balance these groups across nodes.\n    # Finally, replicate experts within nodes to balance across GPUs.\n\n    # Step 1: Balance logical experts into groups.\n    # If num_groups == 1, this step is trivial and doesn't change anything.\n    group_size = num_logical_experts // num_groups\n    tokens_per_group_layer = weight.unflatten(-1, (num_groups, group_size)).sum(-1) # [num_layers, num_groups]\n\n    # Pack groups onto nodes.\n    # If num_groups % num_nodes != 0, we effectively want to balance all groups onto a single 'node' conceptually,\n    # and then distribute those across the actual num_nodes.\n    # Let's consider the case where num_groups is not divisible by num_nodes.\n    # The original code uses num_nodes for packing groups. If num_groups < num_nodes, this packing might be problematic.\n    # A more robust approach is to balance groups onto num_nodes, and if num_groups < num_nodes, some nodes get 0 groups.\n    # The current `balanced_packing` assumes num_groups is divisible by num_packs (num_nodes here).\n\n    # Let's redefine the packing strategy:\n    # We want to pack 'num_groups' items (groups) into 'num_nodes' packs.\n    # If num_groups is not divisible by num_nodes, balanced_packing needs to handle it.\n    # The current `balanced_packing` asserts `num_groups % num_packs == 0`.\n    # This means if num_groups % num_nodes != 0, the original code calls `rebalance_experts_hierarchical` with num_nodes=1, num_groups=1.\n    # This is a global balancing strategy.\n\n    # Let's ensure the function call correctly reflects the intended strategy.\n    # If num_groups % num_nodes == 0, use hierarchical.\n    # Otherwise, use global (which is hierarchical with num_nodes=1, num_groups=1).\n\n    if num_groups % num_nodes == 0:\n        # Hierarchical balancing: balance groups to nodes, then nodes to GPUs.\n        # Step 1: Pack groups to nodes.\n        group_pack_index, group_rank_in_pack = balanced_packing(tokens_per_group_layer, num_nodes)\n        # Map logical experts to \"middle\" logical experts (logical experts per node)\n        # log2mlog: [num_layers, num_logical_experts] -> maps logical expert to its middle logical expert\n        mlog2log_map = (((group_pack_index * groups_per_node + group_rank_in_pack) * group_size).unsqueeze(-1) +\n                        torch.arange(group_size, dtype=torch.int64, device=group_pack_index.device)).flatten(-2)\n        # mlog2log_map: [num_layers, num_logical_experts] maps each logical expert to its \"middle\" logical expert ID.\n        # We need the inverse mapping for `weight.gather` later.\n        # This inverse mapping is tricky because multiple logical experts can map to the same middle expert.\n        # The `inverse` function is designed for permutations, which isn't directly applicable here.\n\n        # Let's rethink the mapping and replication.\n        # We have `num_layers` of `weight` ([num_layers, num_logical_experts]).\n        # First, we group logical experts: `tokens_per_group_layer` ([num_layers, num_groups]).\n        # Then, we pack these groups onto `num_nodes`: `group_pack_index` ([num_layers, num_groups]) and `group_rank_in_pack` ([num_layers, num_groups]).\n        # This means `num_groups` are assigned to `num_nodes`. `groups_per_node` groups per node.\n        # So, we have `num_layers * num_nodes` \"node-level\" expert weight tensors.\n        # Each node-level tensor has `num_logical_experts // num_nodes` \"middle\" experts.\n\n        # Let's create the \"middle\" logical experts' weights.\n        # `mlog_weights`: [num_layers * num_nodes, num_logical_experts // num_nodes]\n        # This requires carefully gathering weights.\n        # The `mlog2log` mapping needs to be constructed correctly.\n\n        # `mlog2log_map` assigns each logical expert to a conceptual \"middle\" logical expert.\n        # e.g., if num_logical_experts=8, num_groups=2, group_size=4.\n        # Group 0 contains logical experts 0,1,2,3. Group 1 contains 4,5,6,7.\n        # If num_nodes=2, groups_per_node=1.\n        # Group 0 (log experts 0-3) goes to node 0. Group 1 (log experts 4-7) goes to node 1.\n        # Node 0 has 1 middle expert. Node 1 has 1 middle expert.\n        # Middle expert for node 0 is logical experts 0-3. Middle expert for node 1 is 4-7.\n        # The mapping `mlog2log_map` should map:\n        # 0,1,2,3 -> 0 (on node 0)\n        # 4,5,6,7 -> 0 (on node 1)\n        # The current `mlog2log` calculation seems to be constructing the indices of the middle experts.\n        # `log2mlog` is `[num_layers, num_logical_experts]`.\n        # It maps logical expert ID to its index within the middle expert group.\n        # The `mlog2log` is the inverse of this index mapping.\n\n        # Let's reconstruct `mlog2log` and `tokens_per_mlog` more directly.\n        # For each layer, we have `num_groups` of `group_size`.\n        # `group_pack_index`: [num_layers, num_groups] - node assignment for each group.\n        # `group_rank_in_pack`: [num_layers, num_groups] - index of group within the node's assigned groups.\n\n        # We want to create `num_layers * num_nodes` \"node-level\" expert groups.\n        # Each node-level group corresponds to a set of original logical experts.\n        # The `tokens_per_mlog` should be `[num_layers * num_nodes, num_logical_experts // num_nodes]`.\n\n        # Calculate the logical expert index for each \"middle\" expert.\n        # `mlog_expert_indices`: [num_layers, num_nodes, groups_per_node, group_size]\n        # This is becoming complex. Let's simplify the conceptualization.\n\n        # Simpler approach:\n        # 1. Pack groups to nodes. This determines which logical experts are grouped together on each node.\n        # `group_pack_index`: [num_layers, num_groups] -> node ID for each group.\n        # `group_rank_in_pack`: [num_layers, num_groups] -> rank within node for each group.\n\n        # 2. For each node, create a combined weight tensor for the logical experts assigned to it.\n        #    The number of logical experts per node will be `groups_per_node * group_size`.\n        #    We need to gather the weights of logical experts based on `group_pack_index`.\n\n        # Let's create a mapping from (layer, node) to a contiguous block of logical experts.\n        # `node_logical_expert_map`: [num_layers, num_nodes, groups_per_node * group_size]\n\n        # This requires constructing a permutation for each layer and node.\n        # The original `mlog2log` calculation is:\n        # `((group_pack_index * groups_per_node + group_rank_in_pack) * group_size)`\n        # This forms a base index for each logical expert.\n        # `log2mlog` is this base index + `arange(group_size)`.\n        # `mlog2log` is the inverse of `log2mlog`.\n\n        # Let's directly construct the `tokens_per_mlog` and `mlog2log`.\n        # `tokens_per_mlog` is the weight tensor for experts *within* each node, considering the grouped logical experts.\n        # The number of such \"middle\" experts per node is `groups_per_node * group_size`.\n\n        # For each layer:\n        # `group_pack_index` tells us which node each group belongs to.\n        # `group_rank_in_pack` tells us the order within the node.\n\n        # Let's create `num_layers * num_nodes` tensors, each of size `groups_per_node * group_size`.\n        # `mlog_weights`: [num_layers * num_nodes, groups_per_node * group_size]\n        # `mlog_to_orig_log_map`: [num_layers * num_nodes, groups_per_node * group_size]\n\n        # Example: num_layers=1, num_logical_experts=8, num_groups=2, group_size=4, num_nodes=2, groups_per_node=1, num_gpus=2, phy_experts_per_gpu=1.\n        # weight: [1, 8]\n        # tokens_per_group_layer: [1, 2] (sum of weights for group 0 and group 1)\n        # balanced_packing(tokens_per_group_layer, num_nodes=2) ->\n        #   group_pack_index: [1, 2] -> [[0, 1]] (group 0 to node 0, group 1 to node 1)\n        #   group_rank_in_pack: [1, 2] -> [[0, 0]] (rank 0 within node for both groups)\n        # groups_per_node = 1, group_size = 4.\n\n        # Middle expert for node 0 is logical experts 0,1,2,3.\n        # Middle expert for node 1 is logical experts 4,5,6,7.\n        # `mlog_to_orig_log_map` for node 0 should be [0,1,2,3].\n        # `mlog_to_orig_log_map` for node 1 should be [4,5,6,7].\n\n        # The original `mlog2log` calculation:\n        # `base_idx = (group_pack_index * groups_per_node + group_rank_in_pack) * group_size`\n        # `base_idx`: [1, 2] -> [[0*1+0, 1*1+0]] * 4 = [[0, 4]]\n        # `log2mlog`: `base_idx.unsqueeze(-1) + torch.arange(group_size)`\n        # `log2mlog`: [[0, 4]].unsqueeze(-1) + [0,1,2,3] -> [[0,1,2,3], [4,5,6,7]]\n        # This `log2mlog` is `[num_layers, num_logical_experts]`. It maps original logical expert ID to its \"middle\" expert index.\n        # The original logic uses `weight.gather(-1, mlog2log)` which is incorrect here.\n        # `weight.gather(-1, mlog2log)` expects `mlog2log` to be `[num_layers, num_middle_experts]` where `num_middle_experts` is the number of columns in `weight`.\n        # The shape should be `[num_layers, num_logical_experts]` if we are gathering from `weight` which is `[num_layers, num_logical_experts]`.\n        # The `mlog2log` calculated here has shape `[num_layers, num_logical_experts]`.\n        # It maps `original_logical_expert_id` to `middle_expert_id`.\n        # We need to gather `weight[layer, original_logical_expert_id]` and group them by `middle_expert_id`.\n\n        # Let's create `mlog_weights` directly.\n        # `mlog_weights`: [num_layers * num_nodes, groups_per_node * group_size]\n        # `mlog_to_orig_log_map`: [num_layers * num_nodes, groups_per_node * group_size]\n\n        # Vectorized construction of mlog_weights and mlog_to_orig_log_map\n        # This replaces the nested Python loops for better performance.\n\n        # Calculate the new \"middle expert group\" index for each original group.\n        # This new index combines node assignment and rank within the node.\n        # Shape: [num_layers, num_groups]\n        new_group_idx = group_pack_index * groups_per_node + group_rank_in_pack\n\n        # Create a tensor that maps new group index back to original group index.\n        # This is a permutation tensor for groups within each layer.\n        # Shape: [num_layers, num_nodes * groups_per_node] (which is num_groups)\n        group_permutation = torch.empty((num_layers, num_groups),\n                                        dtype=torch.int64,\n                                        device=weight.device)\n        group_permutation.scatter_(1, new_group_idx,\n                                   torch.arange(num_groups, device=weight.device).expand(num_layers, -1))\n\n        # Reshape original weights to [num_layers, num_groups, group_size]\n        weight_reshaped = weight.view(num_layers, num_groups, group_size)\n\n        # Gather weights based on the group_permutation\n        # The .gather() operation reorders the groups according to the permutation.\n        # Shape: [num_layers, num_groups, group_size]\n        mlog_weights_ordered = weight_reshaped.gather(1, group_permutation.unsqueeze(-1).expand(-1, -1, group_size))\n        \n        # Reshape to [num_layers, num_nodes, groups_per_node * group_size]\n        # This is the final mlog_weights.\n        mlog_weights = mlog_weights_ordered.view(num_layers, num_nodes, groups_per_node * group_size)\n\n        # Construct mlog_to_orig_log_map similarly\n        # Original logical expert IDs, reshaped to [num_groups, group_size]\n        orig_log_ids_reshaped = torch.arange(num_logical_experts,\n                                             dtype=torch.int64,\n                                             device=weight.device).view(num_groups, group_size)\n        \n        # Expand to [num_layers, num_groups, group_size] and gather\n        mlog_to_orig_log_map_ordered = orig_log_ids_reshaped.unsqueeze(0).expand(num_layers, -1, -1).gather(\n            1, group_permutation.unsqueeze(-1).expand(-1, -1, group_size))\n        \n        # Reshape to [num_layers, num_nodes, groups_per_node * group_size]\n        mlog_to_orig_log_map = mlog_to_orig_log_map_ordered.view(\n            num_layers, num_nodes, groups_per_node * group_size)\n\n        # Now, `mlog_weights`: [num_layers, num_nodes, num_logical_experts // num_nodes]\n        # And `mlog_to_orig_log_map`: [num_layers, num_nodes, num_logical_experts // num_nodes]\n\n        # Step 2: Replicate experts within each node.\n        # `mlog_weights` are the weights for experts within each node.\n        # `num_physical_experts // num_nodes` is the target number of physical experts per node.\n        # `replicate_experts` takes `[X, num_log]` and returns `phy2log`, `rank`, `logcnt`.\n        # Here, X = num_layers * num_nodes, num_log = num_logical_experts // num_nodes.\n        # So, we need to reshape `mlog_weights` and `mlog_to_orig_log_map`.\n\n        num_middle_experts = num_logical_experts // num_nodes\n        reshaped_mlog_weights = mlog_weights.view(-1, num_middle_experts)\n        reshaped_mlog_to_orig_log_map = mlog_to_orig_log_map.view(-1, num_middle_experts)\n\n        # `phy2mlog`: [num_layers * num_nodes, num_physical_experts // num_nodes]\n        # `phyrank`: [num_layers * num_nodes, num_physical_experts // num_nodes]\n        # `mlogcnt`: [num_layers * num_nodes, num_middle_experts]\n        phy2mlog, phyrank, mlogcnt = replicate_experts(\n            reshaped_mlog_weights, num_physical_experts // num_nodes)\n\n        # Step 3: Pack physical experts to GPUs.\n        # `phy2mlog` maps physical experts (within each node) to middle logical experts.\n        # `phy2mlog` is `[num_layers * num_nodes, num_phy_per_node]`\n        # `phyrank` is `[num_layers * num_nodes, num_phy_per_node]`\n        # `mlogcnt` is `[num_layers * num_nodes, num_middle_experts]`\n\n        # We need to map these back to global physical expert indices.\n        # The `phy2mlog` refers to the *middle* logical experts.\n        # The `replicate_experts` function returns `phy2log` which is the *original* logical expert ID.\n        # So, `phy2mlog` from `replicate_experts` is actually `[num_layers*num_nodes, num_phy_per_node]`,\n        # where each entry is an index into the *middle* logical experts.\n\n        # We need to map these `phy2mlog` indices back to original logical expert IDs.\n        # `reshaped_mlog_to_orig_log_map`: [num_layers * num_nodes, num_middle_experts]\n        # `final_phy2log_per_node`: [num_layers * num_nodes, num_phy_per_node]\n        final_phy2log_per_node = reshaped_mlog_to_orig_log_map.gather(-1, phy2mlog)\n\n        # `phyrank` is the replica rank for the middle experts.\n        # We need to combine this with `mlogcnt` to get the final `logcnt`.\n        # `mlogcnt` is `[num_layers * num_nodes, num_middle_experts]`. It tells us how many replicas each middle expert has.\n        # The `phyrank` is the rank of the replica for a *specific* middle expert.\n\n        # The `logcnt` returned by `replicate_experts` is `[X, num_log]`, which is `[num_layers*num_nodes, num_middle_experts]`.\n        # We need to map this back to `[num_layers, num_logical_experts]`.\n\n        # Let's use the `mlogcnt` directly to get the total count of replicas for each logical expert.\n        # `mlogcnt` is `[num_layers * num_nodes, num_middle_experts]`.\n        # We need to sum/average counts based on the `mlog_to_orig_log_map`.\n\n        # Let's refine the output mapping:\n        # `physical_to_logical_map`: [num_layers, num_replicas]\n        # `logical_to_physical_map`: [num_layers, num_logical_experts, X]\n        # `expert_count`: [num_layers, num_logical_experts]\n\n        # `final_phy2log_per_node`: [num_layers * num_nodes, num_phy_per_node]\n        # This is the logical expert ID for each physical expert *within its node*.\n        # We need to convert this to global physical expert IDs.\n        # Physical experts are grouped by GPU. `num_gpus` total, `num_gpus // num_nodes` per node.\n        # `phy_experts_per_gpu` = `num_physical_experts // num_gpus`.\n        # So, each GPU has `phy_experts_per_gpu` physical experts.\n        # Each Node has `num_gpus // num_nodes` GPUs.\n        # Total physical experts per node = `(num_gpus // num_nodes) * phy_experts_per_gpu`\n        # This should equal `num_physical_experts // num_nodes`.\n\n        # `final_phy2log_per_node`: [num_layers, num_nodes, num_phy_per_node]\n        # `final_rank_per_node`: [num_layers, num_nodes, num_phy_per_node] (this is `phyrank`)\n\n        # We need to flatten this to `[num_layers, num_physical_experts]`.\n        # `num_physical_experts = num_nodes * num_phy_per_node`.\n\n        # `final_phy2log_global`: [num_layers, num_physical_experts]\n        # `final_rank_global`: [num_layers, num_physical_experts]\n\n        # The `mlog_to_orig_log_map` correctly maps middle experts to original logical experts.\n        # `phy2mlog` maps physical experts (within a node) to middle experts.\n        # So, `phy2mlog.gather(-1, final_phy2log_per_node)` gives the logical expert ID.\n        # This is what `final_phy2log_per_node` already represents.\n\n        # Let's rename `final_phy2log_per_node` to `phy2log_per_node` for clarity.\n        phy2log_per_node = final_phy2log_per_node\n        rank_per_node = phyrank # [num_layers * num_nodes, num_phy_per_node]\n\n        # Flatten these to get global mappings for physical experts.\n        phy2log_global = phy2log_per_node.view(num_layers, -1)\n        rank_global = rank_per_node.view(num_layers, -1)\n\n        # Now, let's construct the `logcnt` (expert_count).\n        # `mlogcnt`: [num_layers * num_nodes, num_middle_experts]\n        # `mlog_to_orig_log_map`: [num_layers * num_nodes, num_middle_experts]\n\n        # We need to aggregate `mlogcnt` based on `mlog_to_orig_log_map`.\n        # For each logical expert, its total count is the sum of counts of its constituent middle experts.\n        # This aggregation needs to be done carefully.\n\n        # Let's create a tensor for `logcnt`: [num_layers, num_logical_experts] initialized to zeros.\n        expert_count = torch.zeros(num_layers, num_logical_experts, dtype=torch.int64, device=weight.device)\n\n        # Vectorized aggregation of mlogcnt to expert_count\n        # mlogcnt: [num_layers * num_nodes, num_middle_experts]\n        # mlog_to_orig_log_map: [num_layers, num_nodes, num_middle_experts]\n        \n        # Reshape mlog_to_orig_log_map to [num_layers, num_nodes * num_middle_experts]\n        # and mlogcnt to [num_layers, num_nodes * num_middle_experts]\n        mlog_to_orig_log_map_flat = mlog_to_orig_log_map.view(num_layers, -1)\n        mlogcnt_flat = mlogcnt.view(num_layers, -1)\n        \n        # Use scatter_add_ to efficiently sum counts for each original logical expert\n        expert_count = torch.zeros(num_layers, num_logical_experts, dtype=torch.int64, device=weight.device)\n        expert_count.scatter_add_(1, mlog_to_orig_log_map_flat, mlogcnt_flat)\n\n        return phy2log_global, rank_global, expert_count\n\n    else:\n        # Global balancing strategy: treat all experts as one group, balance across num_gpus.\n        # This is equivalent to calling the hierarchical function with num_nodes=1, num_groups=1.\n        # num_groups = 1 means group_size = num_logical_experts.\n        # num_nodes = 1 means groups_per_node = 1.\n        # The entire logic simplifies.\n\n        # Step 1: Pack logical experts to nodes (here, nodes = GPUs conceptually).\n        # `tokens_per_group` becomes `weight` itself since num_groups=1.\n        # `balanced_packing(weight, num_gpus)`\n        # `group_pack_index`: [num_layers, num_logical_experts] -> GPU assignment for each logical expert.\n        # `group_rank_in_pack`: [num_layers, num_logical_experts] -> rank within GPU for each logical expert.\n        # `num_nodes` becomes `num_gpus`. `groups_per_node` becomes `num_logical_experts // num_gpus`.\n\n        # We need to adapt `balanced_packing` to work with `num_packs = num_gpus`.\n        # The `groups_per_pack` in `balanced_packing` refers to items per pack.\n        # Here, items are logical experts. So, `groups_per_pack` = `num_logical_experts // num_gpus`.\n        # `num_packs` = `num_gpus`.\n\n        pack_index_gpu, rank_in_gpu = balanced_packing(weight, num_gpus)\n\n        # `pack_index_gpu`: [num_layers, num_logical_experts] -> GPU ID for each logical expert.\n        # `rank_in_gpu`: [num_layers, num_logical_experts] -> rank within GPU for each logical expert.\n\n        # Step 2: Replicate experts within GPUs.\n        # We need to create tensors for `replicate_experts` that represent experts *per GPU*.\n        # `num_logical_experts_per_gpu` = `num_logical_experts // num_gpus`.\n        # `num_physical_experts_per_gpu` = `num_physical_experts // num_gpus`.\n\n        # For each GPU, we have a set of logical experts.\n        # We need to gather weights for logical experts assigned to the same GPU.\n        # `gpu_logical_weights`: [num_gpus, num_logical_experts_per_gpu, num_layers] (transposed for replicate_experts)\n        # `gpu_logical_to_orig_map`: [num_gpus, num_logical_experts_per_gpu]\n\n        # Vectorized construction of gpu_logical_weights and gpu_logical_to_orig_map\n        # This replaces the nested Python loops for better performance.\n\n        num_logical_experts_per_gpu = num_logical_experts // num_gpus\n\n        # Calculate the new \"middle expert group\" index for each original logical expert.\n        # This new index combines GPU assignment and rank within the GPU.\n        # Shape: [num_layers, num_logical_experts]\n        new_logical_expert_idx_on_gpu = pack_index_gpu * num_logical_experts_per_gpu + rank_in_gpu\n\n        # Create a tensor that maps new logical expert index back to original logical expert index.\n        # This is a permutation tensor for logical experts within each layer.\n        # Shape: [num_layers, num_gpus * num_logical_experts_per_gpu] (which is num_logical_experts)\n        logical_expert_permutation = torch.empty((num_layers, num_logical_experts),\n                                                 dtype=torch.int64,\n                                                 device=weight.device)\n        logical_expert_permutation.scatter_(1, new_logical_expert_idx_on_gpu,\n                                            torch.arange(num_logical_experts, device=weight.device).expand(num_layers, -1))\n\n        # Gather weights based on the logical_expert_permutation\n        # Shape: [num_layers, num_logical_experts]\n        gpu_logical_weights_ordered = weight.gather(1, logical_expert_permutation)\n        \n        # Reshape to [num_gpus, num_layers, num_logical_experts_per_gpu] for subsequent processing\n        # and ensure contiguous memory layout.\n        gpu_logical_weights = gpu_logical_weights_ordered.view(\n            num_layers, num_gpus, num_logical_experts_per_gpu).permute(1, 0, 2).contiguous()\n\n        # Construct gpu_logical_to_orig_map similarly\n        # Original logical expert IDs, expanded to [num_layers, num_logical_experts]\n        orig_log_ids_expanded = torch.arange(num_logical_experts,\n                                             dtype=torch.int64,\n                                             device=weight.device).unsqueeze(0).expand(num_layers, -1)\n        \n        # Gather original logical expert IDs based on the permutation\n        gpu_logical_to_orig_map_ordered = orig_log_ids_expanded.gather(1, logical_expert_permutation)\n        \n        # Reshape to [num_gpus * num_layers, num_logical_experts_per_gpu] for replicate_experts input\n        gpu_logical_to_orig_map = gpu_logical_to_orig_map_ordered.view(\n            num_layers, num_gpus, num_logical_experts_per_gpu).permute(1, 0, 2).contiguous().view(\n                -1, num_logical_experts_per_gpu)\n\n        # Reshape for `replicate_experts`: [num_gpus * num_layers, num_logical_experts_per_gpu]\n        reshaped_gpu_logical_weights = gpu_logical_weights.view(-1, num_logical_experts_per_gpu)\n        reshaped_gpu_logical_to_orig_map = gpu_logical_to_orig_map.view(-1, num_logical_experts_per_gpu)\n\n        # `replicate_experts` is called with `num_phy = num_physical_experts // num_gpus` (target physical experts per GPU).\n        # `X` becomes `num_gpus * num_layers`. `num_log` becomes `num_logical_experts_per_gpu`.\n        # `phy2log_gpu`: [num_gpus * num_layers, num_phy_per_gpu]\n        # `phyrank_gpu`: [num_gpus * num_layers, num_phy_per_gpu]\n        # `gpu_logcnt`: [num_gpus * num_layers, num_logical_experts_per_gpu]\n        phy2log_gpu, phyrank_gpu, gpu_logcnt = replicate_experts(\n            reshaped_gpu_logical_weights, num_physical_experts // num_gpus)\n\n        # Map `phy2log_gpu` back to original logical expert IDs using `reshaped_gpu_logical_to_orig_map`.\n        # `phy2log_global`: [num_gpus * num_layers, num_phy_per_gpu]\n        phy2log_global = reshaped_gpu_logical_to_orig_map.gather(-1, phy2log_gpu)\n\n        # Flatten to get the final `physical_to_logical_map` and `rank`.\n        # The `rank_global` is `phyrank_gpu`.\n        rank_global = phyrank_gpu\n\n        # Construct `expert_count` ([num_layers, num_logical_experts]).\n        # `gpu_logcnt`: [num_gpus * num_layers, num_logical_experts_per_gpu]\n        expert_count = torch.zeros(num_layers, num_logical_experts, dtype=torch.int64, device=weight.device)\n\n        for gpu_layer_idx in range(num_gpus * num_layers):\n            layer_idx = gpu_layer_idx // num_gpus\n            # Get the original logical expert indices for this gpu_layer combination\n            orig_log_indices = reshaped_gpu_logical_to_orig_map[gpu_layer_idx] # [num_logical_experts_per_gpu]\n            counts_for_orig_logs = gpu_logcnt[gpu_layer_idx] # [num_logical_experts_per_gpu]\n\n            # Add these counts to the correct positions in the expert_count tensor\n            expert_count[layer_idx].index_add_(0, orig_log_indices, counts_for_orig_logs)\n\n        # Construct `logical_to_physical_map` ([num_layers, num_logical_experts, X])\n        max_replicas_per_expert = (num_physical_experts + num_logical_experts - 1) // num_logical_experts\n\n        logical_to_physical_map = torch.full((num_layers, num_logical_experts, max_replicas_per_expert), -1, dtype=torch.int64, device=weight.device)\n\n        # Need to map `phy2log_global` and `rank_global` to the correct positions.\n        # `phy2log_global` are indices into the *original* logical experts.\n        # `rank_global` is the replica rank for that original logical expert.\n\n        # Reshape to get mappings per layer and then iterate through physical experts.\n        phy2log_global_reshaped = phy2log_global.view(num_gpus, num_layers, -1).permute(1, 0, 2).contiguous()\n        rank_global_reshaped = rank_global.view(num_gpus, num_layers, -1).permute(1, 0, 2).contiguous()\n\n        # Iterate through all physical experts\n        for layer_idx in range(num_layers):\n            for gpu_idx in range(num_gpus):\n                for phys_idx_in_gpu in range(num_physical_experts // num_gpus):\n                    # Get the global physical expert index\n                    global_phys_idx = gpu_idx * (num_physical_experts // num_gpus) + phys_idx_in_gpu\n\n                    log_expert_id = phy2log_global_reshaped[layer_idx, gpu_idx, phys_idx_in_gpu]\n                    replica_rank = rank_global_reshaped[layer_idx, gpu_idx, phys_idx_in_gpu]\n\n                    if log_expert_id >= 0 and log_expert_id < num_logical_experts:\n                        if replica_rank < max_replicas_per_expert:\n                            logical_to_physical_map[layer_idx, log_expert_id, replica_rank] = global_phys_idx\n                        else:\n                            pass # Handle error or log\n\n        # The `phy2log_global` needs to be reshaped to `[num_layers, num_replicas]`\n        # where `num_replicas` is `num_physical_experts`.\n        # `phy2log_global` is currently `[num_gpus * num_layers, num_phy_per_gpu]`.\n        # We need to combine these.\n        # The order of physical experts should be consistent.\n        # Let's reconstruct `phy2log_global` to be `[num_layers, num_physical_experts]`.\n\n        final_phy2log_global = torch.empty((num_layers, num_physical_experts), dtype=torch.int64, device=weight.device)\n        current_phys_idx = 0\n        for gpu_idx in range(num_gpus):\n            for layer_idx in range(num_layers):\n                # Calculate the range of physical experts for this GPU and layer combination\n                start_phys_idx = layer_idx * num_gpus * (num_physical_experts // num_gpus) + gpu_idx * (num_physical_experts // num_gpus)\n                end_phys_idx = start_phys_idx + (num_physical_experts // num_gpus)\n\n                # The `phy2log_global` calculated earlier is `[num_gpus * num_layers, num_phy_per_gpu]`\n                # We need to map it correctly.\n                # `phy2log_gpu` was `[num_gpus * num_layers, num_phy_per_gpu]`\n                # `reshaped_gpu_logical_to_orig_map` was `[num_gpus * num_layers, num_phy_per_gpu]`\n                # `phy2log_global = reshaped_gpu_logical_to_orig_map.gather(-1, phy2log_gpu)`\n\n                # The indices for `phy2log_global` should be:\n                # For layer 0, GPU 0: phys experts 0 to num_phy_per_gpu - 1\n                # For layer 0, GPU 1: phys experts num_phy_per_gpu to 2*num_phy_per_gpu - 1\n                # ...\n                # For layer 1, GPU 0: phys experts num_gpus * num_phy_per_gpu to (num_gpus+1)*num_phy_per_gpu - 1\n\n                # Let's re-index the `phy2log_global` and `rank_global` to match `[num_layers, num_physical_experts]`\n                # The current `phy2log_global` is effectively `[num_layers * num_gpus, num_phy_per_gpu]`\n                # We need to rearrange it.\n\n                # Example: num_layers=2, num_gpus=2, num_phy_per_gpu=2. num_physical_experts=4.\n                # phy2log_global:\n                # [layer0_gpu0_phys0, layer0_gpu0_phys1,\n                #  layer0_gpu1_phys0, layer0_gpu1_phys1,\n                #  layer1_gpu0_phys0, layer1_gpu0_phys1,\n                #  layer1_gpu1_phys0, layer1_gpu1_phys1]\n                # Reshaped to [num_gpus*num_layers, num_phy_per_gpu] -> [4, 2]\n                # We want [num_layers, num_physical_experts] -> [2, 4]\n\n                # The current `phy2log_global` is `[num_gpus * num_layers, num_phy_per_gpu]`.\n                # Permute and reshape:\n                # `view(num_gpus, num_layers, -1)` gives `[num_gpus, num_layers, num_phy_per_gpu]`\n                # `permute(1, 0, 2)` gives `[num_layers, num_gpus, num_phy_per_gpu]`\n                # `contiguous().view(num_layers, -1)` gives `[num_layers, num_gpus * num_phy_per_gpu]` = `[num_layers, num_physical_experts]`\n\n                final_phy2log_global = phy2log_global.view(num_gpus, num_layers, -1).permute(1, 0, 2).contiguous().view(num_layers, num_physical_experts)\n                final_rank_global = rank_global.view(num_gpus, num_layers, -1).permute(1, 0, 2).contiguous().view(num_layers, num_physical_experts)\n\n        # Return the results for global balancing.\n        return final_phy2log_global, logical_to_physical_map, expert_count\n\n\ndef rebalance_experts(\n    weight: torch.Tensor,\n    num_replicas: int,\n    num_groups: int,\n    num_nodes: int,\n    num_gpus: int,\n) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Entry point for expert-parallelism load balancer.\n\n    Parameters:\n        weight: [layers, num_logical_experts], the load statistics for all\n            logical experts\n        num_replicas: number of physical experts, must be a multiple of\n            `num_gpus`\n        num_groups: number of expert groups\n        num_nodes: number of server nodes, where the intra-node network\n            (e.g, NVLink) is faster\n        num_gpus: number of GPUs, must be a multiple of `num_nodes`\n\n    Returns:\n        physical_to_logical_map: [layers, num_replicas], the expert index of\n            each replica\n        logical_to_physical_map: [layers, num_logical_experts, X], the replica\n            indices for each expert\n        expert_count: [layers, num_logical_experts], number of physical\n            replicas for each logical expert\n    \"\"\"\n    num_layers, num_logical_experts = weight.shape\n    weight = weight.float() # Ensure float type, keep on original device\n    if num_groups % num_nodes == 0:\n        # use hierarchical load-balance policy\n        phy2log_global, rank_global, expert_count = rebalance_experts_hierarchical(\n            weight, num_replicas, num_groups, num_nodes, num_gpus)\n    else:\n        # use global load-balance policy\n        phy2log_global, rank_global, expert_count = rebalance_experts_hierarchical(\n            weight, num_replicas, 1, 1, num_gpus)\n\n    # Compute logical_to_physical_map once, using the global mappings\n    num_logical_experts = weight.shape[1]\n    num_physical_experts = num_replicas # Renaming for clarity based on function signature\n\n    max_replicas_per_expert = (num_physical_experts + num_logical_experts - 1) // num_logical_experts\n\n    logical_to_physical_map = torch.full((num_layers, num_logical_experts, max_replicas_per_expert),\n                                         -1, dtype=torch.int64, device=weight.device)\n\n    physical_expert_ids = torch.arange(num_physical_experts, dtype=torch.int64, device=weight.device)\n    physical_expert_ids_expanded = physical_expert_ids.unsqueeze(0).expand(num_layers, num_physical_experts)\n    layer_indices = torch.arange(num_layers, dtype=torch.int64, device=weight.device).unsqueeze(1)\n    \n    logical_to_physical_map[layer_indices, phy2log_global, rank_global] = physical_expert_ids_expanded\n\n    return phy2log_global, logical_to_physical_map, expert_count\n\n\n# EVOLVE-BLOCK-END\n\n__all__ = [\"rebalance_experts\"]\n\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["The current program has a critical error: `index 2 is out of bounds for dimension 2 with size 2`. This error indicates an issue when populating the `logical_to_physical_map`, specifically with the `rank_global` index exceeding the allocated size for replica ranks. This occurs because the `max_replicas_per_expert` is calculated as a general average, while the `replicate_experts` function might assign more replicas to a highly loaded expert than this average, leading to higher ranks. Additionally, the `rank_global` produced by `replicate_experts` does not uniquely identify the replica slot for a given logical expert, leading to overwrites in `logical_to_physical_map`.\n\nFurthermore, the initialization of `phy2log` in `replicate_experts` is incorrect, as it assigns sequential logical expert IDs to physical experts beyond the actual number of logical experts.\n\nThe proposed improvements address these issues:\n\n1.  **Correct `replicate_experts` Initialization**: The `phy2log` tensor in `replicate_experts` is initialized to map physical experts `0` to `num_log-1` directly to logical experts `0` to `num_log-1`. The remaining physical experts are filled in the loop. This fixes a logical error in how initial physical experts are mapped.\n\n2.  **Robust `logical_to_physical_map` Population**:\n    *   **Dynamic `max_replicas_per_expert`**: The `max_replicas_per_expert` is now determined from the actual maximum replica count observed in `expert_count` (which is correctly computed by `replicate_experts`). This ensures `logical_to_physical_map` is sized correctly to accommodate all replicas.\n    *   **Vectorized `logical_to_physical_map` Construction**: Instead of a nested Python loop, a vectorized approach is used. This involves:\n        1.  Flattening the `phy2log_global` and physical expert IDs.\n        2.  Creating a combined sorting key based on layer and logical expert ID.\n        3.  Sorting these flattened tensors.\n        4.  Computing sequential replica ranks for each `(layer, logical_expert_id)` group using `torch.cumsum`.\n        5.  Scattering the original physical expert IDs into the `logical_to_physical_map` using these computed ranks.\n        This approach guarantees that each `(layer, logical_expert_id, replica_rank)` tuple is unique and correctly points to a physical expert, preventing overwrites and ensuring all physical experts are accounted for. This also significantly improves the `speed_score` for larger problem sizes by replacing Python loops with highly optimized PyTorch operations.\n\nThese changes are expected to resolve the runtime error, improve the correctness of the expert mapping, and enhance the overall execution speed of the rebalancing algorithm. The `balancedness_score` should also improve as the mapping is now accurately reflecting the load distribution.\n\n```diff\n<<<<<<< SEARCH\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n    phy2log = torch.arange(num_phy, dtype=torch.int64,\n                           device=device).repeat(n, 1)\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n    for i in range(num_log, num_phy):\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        phy2log[:, i] = redundant_indices\n        rank[:, i] = logcnt[arangen, redundant_indices] - 1 # Adjust to 0-indexed rank\n        logcnt[arangen, redundant_indices] += 1\n    return phy2log, rank, logcnt\n=======\ndef replicate_experts(\n        weight: torch.Tensor,\n        num_phy: int) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"\n    Replicate `num_log` experts to `num_phy` replicas, such that the maximum\n    load of all replicas is minimized.\n\n    Parameters:\n        weight: [X, num_log]\n        num_phy: total number of experts after replication\n\n    Returns:\n        phy2log: [X, num_phy], logical expert id of each physical expert\n        rank: [X, num_phy], the replica rank\n        logcnt: [X, num_log], number of replicas for each logical expert\n    \"\"\"\n    n, num_log = weight.shape\n    num_redundant = num_phy - num_log\n    assert num_redundant >= 0\n    device = weight.device\n\n    # Initialize phy2log: First num_log physical experts map to logical experts 0 to num_log-1.\n    # The remaining physical experts (num_redundant) will be assigned in the loop.\n    phy2log = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    phy2log[:, :num_log] = torch.arange(num_log, dtype=torch.int64, device=device).unsqueeze(0).expand(n, -1)\n    \n    # Initialize rank: The first num_log physical experts are rank 0 for their respective logical experts.\n    # Ranks for redundant experts will be assigned in the loop.\n    rank = torch.zeros(n, num_phy, dtype=torch.int64, device=device)\n    \n    # logcnt tracks the number of replicas *already assigned* for each logical expert.\n    # Initially, each logical expert has 1 replica (the first num_log physical experts).\n    logcnt = torch.ones(n, num_log, dtype=torch.int64, device=device)\n    \n    arangen = torch.arange(n, dtype=torch.int64, device=device)\n\n    # Assign redundant physical experts\n    for i in range(num_log, num_phy):\n        # Find the logical expert that currently has the minimum average load (weight / #replicas)\n        redundant_indices = (weight / logcnt).max(dim=-1).indices\n        \n        # Assign this physical expert (index i) to the chosen logical expert\n        phy2log[:, i] = redundant_indices\n        \n        # Assign the replica rank for this physical expert.\n        # This rank is the current count of replicas for the chosen logical expert (0-indexed).\n        rank[:, i] = logcnt[arangen, redundant_indices] - 1\n        \n        # Increment the count of replicas for the chosen logical expert\n        logcnt[arangen, redundant_indices] += 1\n        \n    return phy2log, rank, logcnt\n>>>>>>> REPLACE\n<<<<<<< SEARCH\n    max_replicas_per_expert = (num_physical_experts + num_logical_experts - 1) // num_logical_experts\n\n    logical_to_physical_map = torch.full((num_layers, num_logical_experts, max_replicas_per_expert),\n                                         -1, dtype=torch.int64, device=weight.device)\n\n    physical_expert_ids = torch.arange(num_physical_experts, dtype=torch.int64, device=weight.device)\n    physical_expert_ids_expanded = physical_expert_ids.unsqueeze(0).expand(num_layers, num_physical_experts)\n    layer_indices = torch.arange(num_layers, dtype=torch.int64, device=weight.device).unsqueeze(1)\n    \n    logical_to_physical_map[layer_indices, phy2log_global, rank_global] = physical_expert_ids_expanded\n\n    return phy2log_global, logical_to_physical_map, expert_count\n=======\n    # Compute the actual maximum number of replicas any logical expert has\n    # This is more robust than a global average based on num_physical_experts.\n    # Handle cases where expert_count might be empty or all zeros.\n    max_replicas_per_expert = expert_count.max().item() if expert_count.numel() > 0 else 0\n    if num_physical_experts > 0 and max_replicas_per_expert == 0:\n        # If there are physical experts but expert_count somehow indicates zero replicas,\n        # it implies each expert has at least one replica. This is a safeguard.\n        max_replicas_per_expert = 1\n    elif num_physical_experts == 0:\n        # If no physical experts, then max_replicas_per_expert should be 0.\n        max_replicas_per_expert = 0\n\n    logical_to_physical_map = torch.full((num_layers, num_logical_experts, max_replicas_per_expert),\n                                         -1, dtype=torch.int64, device=weight.device)\n\n    # Vectorized computation of replica ranks and population of logical_to_physical_map\n    # 1. Create flat tensors representing (layer_idx, logical_expert_id, physical_expert_id) for each physical expert.\n    layer_indices_flat = torch.arange(num_layers, device=weight.device).unsqueeze(1).expand(-1, num_physical_experts).flatten()\n    phys_expert_ids_flat = torch.arange(num_physical_experts, device=weight.device).unsqueeze(0).expand(num_layers, -1).flatten()\n    log_expert_ids_flat = phy2log_global.flatten()\n\n    # 2. Create a combined key for sorting: (layer_idx, logical_expert_id)\n    #    This ensures that physical experts mapping to the same (layer, logical_expert_id) are grouped together.\n    #    (num_logical_experts + 1) is used as a multiplier to guarantee unique sorting order.\n    sorting_keys = layer_indices_flat * (num_logical_experts + 1) + log_expert_ids_flat\n\n    # 3. Sort by the combined key to group physical experts by (layer, logical_expert_id)\n    sorted_keys, sort_indices = sorting_keys.sort()\n\n    # Apply sort_indices to reorder the flat tensors\n    log_expert_ids_sorted = log_expert_ids_flat[sort_indices]\n    phys_expert_ids_sorted = phys_expert_ids_flat[sort_indices]\n    layer_indices_sorted = layer_indices_flat[sort_indices]\n\n    # 4. Compute the replica rank within each (layer, logical_expert_id) group.\n    #    This is done by identifying where the (layer, logical_expert_id) pair changes.\n    #    `diff` is 1 where a new group starts, 0 otherwise.\n    #    `cumsum` then assigns sequential ranks (0, 1, 2, ...) within each group.\n    \n    # Compare current element with previous element for changes in (layer, log_expert_id)\n    diff = (log_expert_ids_sorted[1:] != log_expert_ids_sorted[:-1]) | \\\n           (layer_indices_sorted[1:] != layer_indices_sorted[:-1])\n    \n    # Prepend `True` (or `1`) to start the first group with rank 0, then compute cumulative sum\n    replica_ranks_sorted = torch.cat((torch.tensor([0], device=weight.device), diff.long())).cumsum(0) - 1\n\n    # 5. Scatter the physical expert IDs into the `logical_to_physical_map`.\n    #    First, filter out any ranks that might exceed `max_replicas_per_expert` (though this should ideally not happen\n    #    if `max_replicas_per_expert` is correctly derived from `expert_count`).\n    valid_mask = (replica_ranks_sorted < max_replicas_per_expert)\n    \n    layer_indices_valid = layer_indices_sorted[valid_mask]\n    log_expert_ids_valid = log_expert_ids_sorted[valid_mask]\n    replica_ranks_valid = replica_ranks_sorted[valid_mask]\n    phys_expert_ids_valid = phys_expert_ids_sorted[valid_mask]\n\n    # Calculate flattened indices for the `logical_to_physical_map` tensor\n    flat_indices = layer_indices_valid * (num_logical_experts * max_replicas_per_expert) + \\\n                   log_expert_ids_valid * max_replicas_per_expert + \\\n                   replica_ranks_valid\n    \n    # Flatten `logical_to_physical_map` for the scatter operation\n    logical_to_physical_map_flat = logical_to_physical_map.flatten()\n    \n    # Perform the scatter operation: assign `phys_expert_ids_valid` to the calculated flat indices.\n    logical_to_physical_map_flat.scatter_(0, flat_indices, phys_expert_ids_valid)\n\n    return phy2log_global, logical_to_physical_map, expert_count\n>>>>>>> REPLACE\n```"]}}}