# Configuration for function minimization example
max_iterations: 100
checkpoint_interval: 10
log_level: "INFO"

# LLM configuration
llm:
  models:
    - name: "gemini-2.5-pro"
      weight: 0.2 # Lower weight for the conservative model
      api_base: "https://generativelanguage.googleapis.com/v1beta/openai/"
      api_key: ${GEMINI_API_KEY}
    - name: "o3"
      weight: 0.8 # Higher weight for the creative/exploratory model
      api_base: "https://api.openai.com/v1"
      api_key: ${OPENAI_API_KEY}
  temperature: 0.7 # Reduced from 0.95 for more focused generation
  top_p: 0.95
  max_tokens: 32000
  timeout: 600

# Prompt configuration
prompt:
  system_message: |
    You are an expert in cloud infrastructure optimization. Your task is to evolve the 
    search_algorithm(src, dsts, G, num_partitions) function to minimize overall 
    data transfer cost while meeting strict time constraints across multiple clouds. 
    Focus on efficiently broadcasting input data to multiple destination nodes by leveraging 
    parallel paths and overlapping transfers across networks. Use the BroadCastTopology 
    class and make_nx_graph function to identify low-cost, high-throughput routes. 
    Prioritize strategies that reduce redundant transfers, balance load across networks, 
    and exploit multi-network topologies to minimize both latency and cost.
  num_top_programs: 3
  use_template_stochasticity: true

# Database configuration
database:
  population_size: 50
  archive_size: 20
  num_islands: 3
  elite_selection_ratio: 0.2
  exploitation_ratio: 0.7

# Evaluator configuration
evaluator:
  timeout: 60
  cascade_evaluation: false
  cascade_thresholds: [0.5, 0.75]
  parallel_evaluations: 4
  use_llm_feedback: false

# Evolution settings
diff_based_evolution: true
allow_full_rewrites: false
